---
audiourl: https://anchor.fm/s/822ba20/podcast/play/83671231/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-2-6%2F2604ad7e-4c59-03ab-f0e5-ef15f18097ea.m4a
draft: false
excerpt: 'Dr. Paul Thagard is Distinguished Professor Emeritus of Philosophy at the
  University of Waterloo and a Fellow of the Royal Society of Canada, the Cognitive
  Science Society, and the Association for Psychological Science. The Canada Council
  awarded him a Molson Prize (2007) and a Killam Prize (2013). He is a philosopher,
  cognitive scientist, and author of many interdisciplinary books, the latest one
  being Falsehoods Fly: Why Misinformation Spreads and How to Stop It.'
id: '927'
image: https://i.ytimg.com/vi/eg_qgbxTqjY/maxresdefault.jpg
itunesEpisodeUrl: https://podcasts.apple.com/us/podcast/927-paul-thagard-falsehoods-fly-why-misinformation/id1451347236?i=1000652287225&uo=4
publishDate: 2024-04-12
spotifyEpisodeUrl: https://podcasters.spotify.com/pod/show/thedissenter/episodes/927-Paul-Thagard---Falsehoods-Fly-Why-Misinformation-Spreads-and-How-to-Stop-It-e2gnunv
tags:
- Cognitive Science
- Philosophy
- Psychology
title: '#927 Paul Thagard - Falsehoods Fly: Why Misinformation Spreads and How to
  Stop It'
youtubeid: eg_qgbxTqjY
---
<a name="top"></a>[Jump to transcript](#transcript)
## Show notes
<div class="timelinks">

RECORDED ON MARCH 6th 2024.  
Dr. Paul Thagard is Distinguished Professor Emeritus of Philosophy at the University of Waterloo and a Fellow of the Royal Society of Canada, the Cognitive Science Society, and the Association for Psychological Science. The Canada Council awarded him a Molson Prize (2007) and a Killam Prize (2013). He is a philosopher, cognitive scientist, and author of many interdisciplinary books, the latest one being Falsehoods Fly: Why Misinformation Spreads and How to Stop It.

In this episode, we focus on Falsehoods Fly. We start by distinguishing information from misinformation, and we discuss why we should worry about misinformation. We talk about the AIMS Theory of Information and Misinformation. We discuss cognitive errors and motivated cognition. We talk about the reliability of news sources, and go through several examples of misinformation, namely medical misinformation and the COVID-19 pandemic; scientific misinformation and climate change; conspiracy theories; political misinformation, and misinformation about inequality; and misinformation on the Russia-Ukraine conflict. Finally, we discuss how we can prevent misinformation, and how this book connects to Dr. Thagard’s The Cognitive Science of Science.

Time Links:  
<time>00:00</time> Intro  
<time>00:28</time> Information and misinformation  
<time>05:02</time> Why should we worry about misinformation?  
<time>09:33</time> The AIMS Theory of Information and Misinformation  
<time>24:34</time> Cognitive errors, and motivated cognition  
<time>29:13</time> The reliability of news sources  
<time>34:47</time> Medical misinformation and the COVID-19 pandemic  
<time>43:00</time> Scientific misinformation and climate change  
<time>46:43</time> Conspiracy theories  
<time>51:58</time> Political misinformation, and misinformation about inequality  
<time>56:07</time> Misinformation on the Russia-Ukraine conflict  
<time>59:12</time> Preventing misinformation  
<time>1:06:34</time> How this book connects to The Cognitive Science of Science  
<time>1:07:20</time> Follow Dr. Thagard’s work!

---

Follow Dr. Thagard’s work:  
Faculty page: https://bit.ly/47FJoDX  
Website: https://bit.ly/47BtnyT  
ResearchGate profile: https://bit.ly/3R6h1JC  
Falsehoods Fly: https://bit.ly/3sIyG0M
</div>

[Back to top](#top)
<a name="transcript"></a>
## Transcript
<div class="timelinks">

<p class="text-muted text-sm bg-slate-200 rounded p-1 text-center">Transcripts are automatically generated and may contain errors</p>
<time>0:00:00</time> Ricardo Lopes: Hello, everybody. Welcome to a new episode of the Decent. I'm your host, Richard Lobs. And today I'm Jen by Doctor Paul Fert. He is distinguished Professor Emeritus of Philosophy at the University of Waterloo. And today we're talking about his latest book, Falsehoods Fly. Why Misinformation Spreads and How to stop it. So, Doctor FEG, welcome to the show. It's a pleasure to everyone.

<time>0:00:25</time> Paul Thagard: Thank you very much for having me.

<time>0:00:28</time> Ricardo Lopes: So we're going to talk a lot about misinformation here today. But I guess that before we get into misinformation itself, it would be important for people to understand a little bit better what we're talking about when we talk about information itself. So what do you think? I it's are the most important aspects of information that people should know to then have a better understanding of what misinformation is?

<time>0:01:00</time> Paul Thagard: Yeah, that's exactly the right place to start because you can't have account of misinformation or disinformation unless you have an account of what information is. That's a surprisingly hard problem. There's an old mathematical field called information theory that was developed by telecommunication scientists to describe signals going through. But it's not useful for our purposes, our purposes are to figure out what's information for people, not just sort of abstract probabilities, we need to have something that can be true or false. So how does it go? Well, one key word to go into it is representation. A representation is something that stands for something in the world. So when you get a representation, it could be a sentence or it could be a picture or it could be a song. These are all things that can stand for things in the world. So that's what a representation is. So information should be meaningful, it should be representational should stand for stuff. And now of course, if you can do that, if it can represent the world, it can also misrepresent the world. And that's where you get misinformation, you end up with something that's false. So if something can be true or false of the world or accurate or useful, those are all things that go under the head of, of of good information of real information, then you've got something that can really make a difference in human communication.

<time>0:02:13</time> Ricardo Lopes: But how exactly do we go about distinguishing information from misinformation? I guess that's a very important question to tackle here because many times if people make claims, usually based on conspiracy theories about how what the experts, the media, the classifier as misinformation, it's just what some people, some elite out there establishes as misinformation or decides is information or misinformation, right? So how do we do it properly?

<time>0:02:53</time> Paul Thagard: OK. The key question then is what's the difference between information that's real and information, which is misinformation, which is one of three things here. I actually got this from the US surgeon general who gave a good account of it. The surgeon general in the US, the top health official is really worried because he knows that there's vast amounts of misinformation about health out there thinking about COVID about vaccines and constant other things. But he came up with a nice one. He said, misinformation is information which is false, inaccurate or misleading. So the key question there is accuracy, does it actually reflect what goes on in the world? So my, my account of information is correctly representing what's in the world. Assume there's a world, this is already something that people disagree about. But I think there's lots of reasons to believe. Yes, there is a real world out there and we can either get it right or get it wrong information that's done properly. Real information gets it right. Misinformation gets it wrong. It can be because it's got sentences that are false or pictures that are, are inaccurate or just things that are misleading because they're a little bit off and they give the wrong sense of what, what's important. So, misinformation is information which is false, inaccurate or misleading or often all three and we find loads of it in all the different fields that I talk about in my book, you find it in medical domains, you find in science, you find lots of it in politics, lots of it in arguments about equality. And the example that I used to sum it all up about is in the Ukraine war where the Russians in particular use a lot of propaganda to tell lies about Ukraine to try to justify it. So real information about the Ukraine War is what actually happened, who attacked who, what kinds of governments do the different places have? That's real information because it corresponds to reality. But when Vladimir Putin says that their, their invasion is justified because the Ukrainian government is run by Nazis. Well, that's false and it's inaccurate and it's extremely misleading because it's being used to justify an invasion for which there is no justification.

<time>0:05:02</time> Ricardo Lopes: And why should we worry about misinformation? Exactly. Because for example, I've already talked with people on my show who have been doing work on misinformation, how it spreads on the internet, for example. And over the course of almost all of those interviews, people have told me, for example, that it's usually just a small minority of people basically putting information out on the internet and spreading it. And most people do not fall for misinformation and even the ones who fall for it, we have probably to look a little bit into their political and social affiliations to understand why they, I mean, tend to believe in specific kinds of misinformation and so on. So, I, I mean, there, there are arguments, I guess for saying that perhaps sometimes we exaggerate a little bit the social impact, the political and social impact of misinformation. But, I mean, why should we worry about it? Exactly.

<time>0:06:17</time> Paul Thagard: Well, I don't know where the people were saying this but they're obviously not aware of what's happening in the United States right now. There's a high probability that the next president of the United States is going to be Donald Trump who is a massive purveyor of misinformation. So he's still saying that Biden stole the last election. He's still saying that the economy is doing horrible. He's saying everything is Biden's fault and that he was perfect leader. So there's massive amounts of misinformation and everything he says. Well, even while he was president, one of the presses, I think it was the Washington Post tracked his statements and they found 15,000 lies and these lies are enabling him to take control of the world's most powerful country. Now, maybe he'll get beaten and that would be good. But right now he's leading in the polls and he's definitely going to be the Republican candidate. So anyone who thinks that misinformation is a problem is not a problem, hasn't been paying attention to that or consider health right now. Measles is spreading in Europe and in Canada Canada hasn't had cases of measles for decades because there is general vaccination starting in the sixties. But because of misinformation about vaccines in general and about the measles vaccine in particular, people are starting to get sick again. There are still people dying of COVID despite the fact that there are excellent vaccines available. So the problem, the reason we have to worry about misinformation is that people get harmed, severely harmed by having fascist leaders in power or by having diseases spread when they don't need to when there are good medical treatments available. So, misinformation is just very, very, very harmful. Even most recent I mean, Putin is still justifying his invasion of the Ukraine. What's the harm there? Well, 30,000 Ukrainian soldiers, countless Ukrainian civilians have been killed as a result of this invasion, which he justifies by layers of misinformation. Not only the claim that Ukraine is run by Nazis, but also of false historical theories about Ukraine is really part of Russia. And so these false beliefs, this misinformation is justifying the causation of immense amounts of harm to human beings. So it's not just the fact that there's a bunch of people talking nonsense on tiktok, I mean that that's not so important unless, but when they start saying what are the causes of diseases, what's the political way to deal with the current problems in society? Then misinformation is causing real harms. And that's why the first sense of my book is Misinformation Kills. And it clearly does. I give also examples from climate change. There are already people who died because of climate change because of heatwaves and wildfires and things like that. And all the information, the real information that we get from government bodies is that this problem is going to get worse and worse and worse that there were a few million people died from the COVID epidemic, but it's going to be many more million people are gonna die as climate change gets worse. In accord with the best scientific information. So it's not just that there's these little harms and these little unfortunate things that happen because people gossip on Twitter or tiktok or Instagram, people die as a result of misinformation.

<time>0:09:32</time> Ricardo Lopes: So let's get now a little bit into before we get into some of the examples you mentioned there and explore them a little bit more like the Ukraine War, scientific misinformation, medical misinformation and so on. In the book, you bring into the book, a particular framework that you call the A theory of information and misinformation or the A I MS because it stands for acquisition, influence memory and spread. Could you tell us a little bit about these for general processes? What do they correspond to how and how they work?

<time>0:10:10</time> Paul Thagard: Sure, it was about five years ago, I realized I needed a theory of information. It was because of another project. I was doing about energy and the philosophy of mind. But I kept running across information. And so I went to look and see what are the current theories of information. And there's still the old theory that I mentioned coming out of telecommunications theory is around. But there wasn't a good theory that would actually cover information here. My background in philosophy of science was relevant along with other philosophies of science. I've been arguing that scientific theories by and large, at least a lot of the most important ones are descriptions of mechanisms. So if you want to explain how the body works, how life works, you look for mechanisms, you've got the heart and the veins for as part of the cardiovascular system, you've got the breathing system, you've got cell division. So you can explain all of life by having a bunch of mechanisms in mind. So what's a mechanism? Well, if you know what a bicycle is, you've got a good example because with a bicycle, you've got the different parts, you've got the handlebars and the frame and the wheels and the crank and all those things. So if you want to explain how a bicycle works, it's the same as how you explain how the body works, you identify mechanisms. So the question I asked myself, what are the mechanisms of information as far as I know? No one's ever asked that question because they were just sort of using it informally as a kind of story or they were relying on Claude Shannon's old mathematical definition. But this turned out to be really interesting because I started to think about what makes information work in the real world and these high level problems that deal that matter to human beings. And I came up with a total of eight mechanisms that fit very nicely under these four headings because it too hard to remember at once. So I boil it down to A I MS. So A is acquisition. So acquisition is not just what you get from other people like. That's what I mean called mean by spread. It's acquisition from the world. So how do we acquire information from the world? And that divides into two parts collecting and representing. So how do we collect information from the world? Well, for a start, we use our senses, we use our eyes and our ears and our touch and so on or smell. And so that's collecting, which is the key part of acquisition. So that's the way to do it, right? And obviously, we know how to do it better now than people did 100,000 years ago. Because we not only use observation, we've also developed great techniques in science to do systematic observations with lots of people to use instruments. Instruments are wonderful because you can measure things, you use telescopes, microscopes, rulers, x ray machines. So we've got all these instruments and one of the most important things that we've learned how to acquire information is experiments. You don't just observe, you change the world and see what happens. You do a manipulation. So he said, well, if I change this a little bit, what's gonna happen and that's really great because that gets us causal information. So acquisition is really the first part of getting real information if you do it right. Unfortunately, we often don't do it right. The opposite of, of this kind of acquisition, sometimes it could be sloppy experiments. But what it is in a lot of cases of what I talked about, including people like Vladimir Putin and Donald Trump, it's making stuff up and people don't understand the difference between observing the world experimenting on it, using instruments, on the one hand that actually works and making stuff up, which doesn't work at all. I mean, because that can be whatever you want to believe. So that's the acquisition part. The second part is inference because you want to just rely on what you observe, you want to make inferences and go beyond that. We want scientific theories, we want to know the causes of stuff. And science again has, and philosophy have found really good ways to do this. We can make inference to theories that are the best explanations of the evidence. That's great. It's not always guaranteed. Sometimes we get it wrong, but that's just a terrific way of going. Well, what goes on with misinformation, it's very different. It's not this kind of inference to the best explanation of the best theory. It's very often there's a bunch of things that go wrong. But the most, the often thing that goes awful thing that goes wrong is called motivated reasoning. This is an idea that psychologists have developed that. It covers cases where you believe something, not because you have evidence for it, but because you want it to be true. And we all do this and you don't have to be the, the, the awful leaders I mentioned to do this. We all do it. We all have things that we want to believe. We all want to believe that we're healthy and we're going to be successful and our, and our, and our Children are great and we've got all these beliefs that we want to believe, well, they may have evidence for them. But if we just do it on the basis of motivated reasoning, we can get into real trouble because that just becomes a very sophisticated kind of wishful thinking. And so most of the views that you find in conspiracy theories in this, he lies about science and medicine and these political lies. They're just, it's just motivated reasoning. People believe it not because there's any evidence for it, but because they want to believe it because it fits with their desires for power or financial gain. So that's, that's the difference at the inference part. OK. So that's two, that's acquisition and inference. The next one is memory. Memory is really important because we can't just make things up all along. We just can't keep rediscovering things. We need to remember what we learned. And so human memory is quite powerful and so we store the things that are important to us, but memory is fallible and we can do something that's called motivated memory. And so instead of memory, we're learning what's actually true of the world, we can actually just sort of again make it up. And so it goes into our memory, not because it's warranted, but because it's it just suits our goals. The fourth is spread, spread is what happens in between people. So most of what we learn, we learn not from directly interacting with the world, it comes from other people could come from the media, come from social media, come from talking to other people and media can be incredibly important. If you get it, your information from reliable sources. I have a set of TV, news shows and, and newspapers that I trust because I know they've got a good track record. But where do people get their spread of information today? Increasingly, it's from social media. I was shocked the other day to read that lots of young people, people in their teens and early twenties get their news from tiktok. Tik Tok is an astonishingly unreliable source of information because anybody can do it. They create these little catchy videos and it's not curated at all. The people who own tiktok don't care about truth, they just care about highballs, they want people to be engaged because then they can sell ads. And that's true also for Instagram and Twitter now called X. And so the social media and it's true for Facebook. So this was actually a drastic change in the spread of information. It started only about 20 years ago when these became available because there used to be at least some kind of gatekeeping that went on at the mostly respectable newspapers and television programs because they thought they had an obligation, a journalistic obligation to tell the truth. And so they would screen information. But with social media, somebody has a crazy idea and boom, they can get it out to millions of other people. And this actually has been the single busy biggest cause for the dramatic increase of misinformation that's available. It's because social media has changed spread. That's my fourth category of of mechanism, social spread from something where there's at least some constraints on it to totally unconstrained where people who are working just with making stuff up and motivated reasoning and biased memories can then send it out to not just thousands of other people but literally millions of other people. So that's why we've got this huge amounts of misinformation about political conspiracies and vaccines and and so on. So that's why spread is the real the fourth one. So we need acquisition inference memory and spread and when those things are done, right? And in some areas they are done right by responsible journalists or by or by scientific research. Well, that's great. We get real information but when they're done badly as they are are increasingly today, then we get misinformation.

<time>0:18:27</time> Ricardo Lopes: And what can we do exactly with this framework? If I understand it correctly, we can both understand how each specific type of misinformation. Like for example, scientific misinformation, political misinformation works. Looking back at different kinds of misinformation out there. And how each of these different processes played out and understand how that particular kind of misinformation spread over time. But we can also use it to tackle each specific kind of misinformation and try to counter it.

<time>0:19:05</time> Paul Thagard: OK. Let, let me give you an analogy. I think there's an analogy between this problem which is huge and what goes on in medicine. So what's good health, good health basic basically means that all the mechanisms in your body are working. What's disease, disease is when they break down your heart stops beating, or your cells start dividing and become cancer. And so good health is the mechanisms are working. Disease is when the mechanisms break down. But of course, we have medicine. What does medicine do? It has cures well, how does it do that? It intervenes with the mechanisms to make things work. It fixes your heart or it fixes your lungs or it stops the cell division. So what we need for misinformation is something that's analogous. We need something that's like a cure to fix the broken mechanisms. And what I do is I in the book is identify a whole set of these, not ones that I've invented myself, but I compiled them and formulated them and fit in a way that fits with the mechanism account. So I can give you a bunch of different examples. Well, the first one is have a willingness to identify the difference between truth and falsity. When Rudy Giuliani was defending Donald Trump. He said, well, truth is not truth. First of all, if you throw truth out, if you don't think there's a reality that you're trying to get right? Then you're in big problems. But the first thing is to recognize that yes, there's a world out there for medicine and for science and for politics and we're trying to get it right. And you have to be aware then that people are often saying things that are false. So you have to have falsehood detectors going. You also have a way of scrutinizing your sources, who's saying it? Do they have good sources? So anything that Donald Trump says is likely to be false because he just says whatever he wants to suit his own needs. On the other hand, there are some good sources like the newspapers or the TV sources that I mentioned. But then for deeper purposes, there's other things we can bring in. For many years. I taught critical thinking. Critical thinking is a process where first of all, you identify the thinking errors that people are making things like motivated reasoning, which everyone succumbs to. But then you try to counter that with good ways of reasoning such as evaluating theories based on the evidence. So, critical thinking is this two steps. First of all, what errors are people making in their thinking? And secondly, how can we fix it? Another way of doing this that other people have thought up in a quite different role that I that I just became to appreciate is called motivational interviewing. It actually makes belief change less like critical thinking and more like therapy. This was invented originally for people who were being helped with addiction. So if somebody is addicted to alcohol or to or to heroin or to some other drug, it's hard to give just reason with them because they've got an addiction. But motivational interviewing was invented as a sort of therapeutic way of actually trying to understand people have empathy with them, understand what's going on. Well, why are you drinking so much or why is heroin so important to you? And it actually has been found to be effective. It's, it's sort of, it's much nicer than critical thinking which sounds kind of like cold hearted logic. This is being empathic and understanding and helping. And actually one of the most interesting applications is it works with people who are vaccine deniers, people who don't want to vaccinate their Children. And so trying to give the pure scientific argument doesn't work. But if you can talk to these people, a lot of the people who are vaccine deniers are actually really nice people, Their parents are just caring about their Children. And they want to do what's best for the Children. Unfortunately, through social media or, or lying politicians, they've gotten misinformation. But if you empathize with them and understand their worries about their Children, how they want to do the best thing you can gradually nudge them over. So they realize that vaccines is worthwhile. So that's a technique called motivational interviewing. So there's a whole battery of, of things many of which have been tested out by psychologists that can help you do this. I made up the word preform information by analogy to preventive medicine. So in medicine, it's well known that it's hard to cure people once they've got a disease. But if you can prevent the disease, that's really great. So curing cancer is hard but preventing cancer by making sure people don't smoke or live in bad environments or eat rotten food and that, that's much more effective. So I made up the term preform information to cover a whole set of ideas that psychologists have introduced, that are ways of keeping people from getting bad information in the first place. One of them is called pre bunking. So, debunking is correcting misinformation. Pre bunking means get in there and make sure people don't get it in the first place. And so I think that's a really nice technique that psychologists have, have invented. Another one they call is inoculation. So you try to warn people, it's not working with respect to Donald Trump if, if, especially if he's gonna be the next president, but there are millions and millions of people who haven't been warned that you can't believe what he says because he's just concerned with his own power and his own fortune. But that's the kind of pre bunking or inoculation that might operate in some cases to help people to get taken in. So there's a whole set of different ways in which we can try to correct misinformation or even more effectively in some cases, prevent it from arising in the first place. So that's why this isn't hopeless. It's not just, oh my God, we can throw up our hands and realize there's just so much misinformation that it can't work well. No, there are some things we can do.

<time>0:24:34</time> Ricardo Lopes: So you use the term cognitive error at a certain point there, what counts as a cognitive error. And also in the book, at a certain point, you distinguish between psychological and social mechanisms be that drive cognitive error. So what is the distinction and why is it important to establish the distinction?

<time>0:24:58</time> Paul Thagard: OK. So a cognitive error is a pattern of thinking that leads to falsehoods. And here we can really draw on in the case of psychology, decades of research in the case of philosophy, hundreds of years of research really going back to Aristotle. So psychologist, psychologists call these biases cognitive biases. There's a large literature that began with Conon Tasy and it's really well documented mistakes that people commonly make in their inferences. So there's these biases, but even older is a tradition in philosophy called fallacies. And so we know that there are patterns of reasoning. But going back to Aristotle, people realize no, they're all fallacies that people make all the time. And so there are lists of literally hundreds of these, maybe probably 50 biases, 50 fallacies and they're all well understood. So our cognitive error come from these fallacies. Let me just give you one philosophical example. Post Hawk, Ergo hater, Ergo Proctor Hawk is the Latin for after this. Therefore, because of this, sometimes one thing happens and another big thing happens and people think they're causally related, well, sometimes they are, but often they're not, that's a mistake that people naturally make. So psychology and philosophy have documented people's tendency to fall into these kinds of errors which are kinds of thinking that leads to mistakes. You might wonder. Well, how could people be prone to this when we're managing to survive in the world? Well, surviving in the world doesn't take that much thinking. You have to be able to survive and reproduce and it really doesn't take that sophisticated thinking just to survive and reproduce. But now we're really leaving this rich, complicated world and having to deal with complicated situations and the cognitive errors really tend to draw us in that list from cognitive biases and, and you and fallacies, philosophical fallacies misses out on what I've already mentioned. What I think is the most important one which is motivated reasoning. This is where people believe something because it suits their goals, it makes them happy, it's not just wishful thinking, it means you there's something you want and so you find reasons for it. So this research was done by initially by a psychologist named Ziva Kunda who actually was my late wife and which is brilliant work. It's been cited out 10,000 times and the citation rate even though this work was done 30 years ago is is just zooming 1000 times in the last year or so because people realize that this is the basis. So you have to realize that everybody is prone to motivated reasoning thinking, they're healthier than they are or prone to be richer than they are. And so I think that belongs as one of the, the, the thinking errors that we have to watch out for, your other part of your question was about social errors. Now the social error part connects up with the fact that most of the information, as I said, we get from other people. That's the spread part. And the problem here is you have to worry about who you trust. You shouldn't trust anybody on Tik Tok because they're not screened any, any, any 16 year old can set up a Tik Tok account and declare themselves a new source and who knows where they get their news. So tiktok's utterly, unreliable source and that's gonna be true for a lot of other social media. On the other hand, I've got a list of newspapers that I think are really pretty good, and, not perfect but really pretty good in a number of TV programs TV, news shows like the Canadian Broadcasting Corporation, that I, I think is, they're usually right. There are people certainly who really care about getting things right. They're not just caring about pushing a particular political agenda. Whereas you have other news sources in the US. You've got Fox News, you can't believe anything on Fox News. They're just pushing their Pro Trump agenda and, and so they're as bad as social media or, or religious texts. So you've got to be able to distinguish these ways and figure out who you can trust. So I've got a bunch of people who I know have, are well informed, care about the truth. If they tell me something, I'm gonna believe it most of the time because they're, I think they're reliable sources. So that's the social part, the social part is acquire your information from sources, you know, to be reliable rather than from ones, you've got good reason to believe are highly unreliable.

<time>0:29:14</time> Ricardo Lopes: And by the way, since you, you mentioned new sources there, how do we go about establishing the credibility of different news sources? What, factors do we look into? Exactly?

<time>0:29:28</time> Paul Thagard: That's really good question. It, it takes a lot of time. Actually, you've got to follow these sources for a while. Occasionally I'll encounter a new news source and, I wonder, are they reliable? So when I was doing the research, for example, on the, conspiracies and, and the Russia Ukraine, suddenly I was running across news sources like Russia dot TV. And, well, first of all I knew that Russia was unreliable and so I had a hunch that Russia dot TV. But then I looked at some of their content and you could see they're just making things up that are, that are announced by the Russian government. So it's probably by association with good or bad people, but sometimes you just have to follow it for a long time. So I've got some of these newspaper sources. One of my favorites is the British newspaper called The Guardian that I've been reading for many, many years and occasionally they do things that I think are not quite right, but by and large, I've been tracking what they say, what I get from other sources that I think are reliable. And so you, you have to track places for, for a long period of time and see the extent to which they turn out to be right or turn out to be wrong.

<time>0:30:33</time> Ricardo Lopes: So just before we dive into some of the examples of misinformation where you explore in the book, we illustrate all of what we've been talking about here. Just tell us a little bit more about a motivated reasoning because I would like to understand here what's behind it, what drives motivated reasoning, cognitively, emotionally and otherwise. Yeah,

<time>0:30:58</time> Paul Thagard: that's a, that's a really deep question because people used to think that the brain was sort of divided up neatly that you've got intelligence on the one hand and emotion on the other part. And you should be able to distinguish that it goes back to Plato. He said we should ana analyze the human as being like you've got a a charier and three horses and you got to kind of keep them under control and keep cognition and emotion. So, but, but, but that now, now that we have neuroscience, we know this isn't right at all. If you look at the brain, you've got cognitive areas and emotional areas, but they're intensely interconnected. So our intelligence isn't just our raw cognitive thinking ability. That's, that's an old view that doesn't hold up now. But it's, in fact, depends on a really sophisticated interaction between cognition and motion between our, our cortex and our, our limbic system, which concludes areas like the Amygdala. And the emotion is actually really important because emotions tell us what's important. It's not just a question of what's true, it's what's important, what's gonna enable us to survive and operate in the world. And so the view of, of thinking, I get this mostly from Antonio Damasio, but there's loads of subsequent support for. It depends on this really tight interaction between our cognitions and our emotions. The problem is there's no firewall, there's no sharp division between cognition and emotion or to put it in the terms that economic economists might know, there's no sharp division between probabilities and utilities. These things should be completely separate, but they're not, they're all interactive in our brain. And often this does it well because we're figuring out what's in the world and we're figuring out what we need to do. We have to avoid predators, we have to find food. And so our emotions and cognitions work well together, but they interact constantly and sometimes this gets us into trouble. So it gets into trouble where instead of our cognitions, depending on how we're observing the world and what getting good information sources, it gets tied in with our emotions. And so you think? Oh, I know what I want. So to take an extreme example. This happened to a friend of mine, he discovered a, a lump in his armpit. Oh, that's nothing. I'm young. I'm healthy. This can't possibly be a problem. Well, a year later it finally got bad enough that he got it checked out and turned out to be Melanoma, which obviously is serious. But all of us have a tendency to be somewhat at least, at least I do and lots of other people do think, oh, that's nothing. That little bump is nothing. But that's a motivated reason because that's what you want to believe. So this is something that happens because our cognitions and our emotions are basically all tied together in the brain. So that's that's, that's so that's why it's such a serious problem and it means that people who not only do it themselves but realize that they can manipulate other people can do the same thing. So Donald Trump is always tying into people's emotions. He's getting people afraid of immigrants concerned about their cost of living, afraid of the so called the liberal elites who he claims are running their lives. And so he's just absolutely fiendish about manipulating people's emotions tapping into something which is part of all of our thinking because our cognitions and our emotions are so tightly interconnected. So that's why motivated reasoning is so natural to all of us because we don't have cognition in one part of our brain and emotion in the other. They're all interconnected with lots of going back and forth. And so we all can be misled into motivated reasoning as opposed to considering the evidence that's important if we really care about our health or about our political well being.

<time>0:34:47</time> Ricardo Lopes: So in your book, you go through different kinds of misinformation and the first one you tackle is medical misinformation and a concrete example. And a very recent example of that is the COVID-19 pandemic. So in what ways does the framework we we talked about before the A S or the A A I MS framework apply here? Exactly.

<time>0:35:12</time> Paul Thagard: Yeah, I think it provides a good account both of why there's so much terrific real information about COVID-19 and other diseases and also why there's so much misinformation. So let's do real information first. I think that COVID-19 is one of the great medical success stories. If you think of the fact that the disease only showed up about a little over four years ago and almost immediately the cause was discovered, they found the virus and then within a year, they found a vaccine that could really diminish a lot. People either getting the disease or the severity of the disease. Just a fabulous success. So the amounts of real information that came about from observation and experiment and theorizing is just fabulous. So that's a great success story of real information coming up in COVID-19 and there's lots of other diseases for which we've done that as well. But what got me interested in misinformation actually in the first place is that four years ago, at the same time as these wonderful advances were being made, the amount of garbage being spread about. It was just enormous. People were making up possible cures. They were saying, oh, we can just use bleach. That's one that Donald Trump did on television or they came up with different theories about the causation. Also, this was just created in a in a Chinese lab. Well, it might have been, but other people said it was no, it was created an American lab. And other people said no, the causes are actually cell phone towers. And so people generated all sorts of just completely Bonkers theories about the origin as well as all sorts of completely Bonkers theories about which kinds of medicine could treat it. There's also early experiments within the next year or two that show that the vaccines work really pretty well with very minimal side effects. But other people started telling stories about how they cause other problems or how they don't really work. And so COVID-19 was just a great case where we get terrific real information by reliable methods at the same time as various amounts of misinformation is being spread. So one question is, well what are the, what are, what are the motivations? Well, if you look at a lot of the COVID-19 misinformation, it comes from websites where people sell nutritional things. If they basically say, just listen to us, we'll tell you all the things that's wrong and they're selling pe, they're trying to get people to buy drugs or nutritional supplements that don't work at all. So there's a lot of lies being told just to sell sorts of things and some of the lies are also being told for political purposes because people didn't want to have the government require that people get vaccinated, they just wanted absolute freedom. And so they would make up stuff to, to people. So it was just a really great study of both real information coming by scientific means, but also misinformation coming from lies and motivated reasoning and social media being used as a source of information rather than good journalistic sources or scientific journals.

<time>0:38:20</time> Ricardo Lopes: So, using your framework, is it possible for us to identify what we could have done better in order in order to prevent the spread of misinformation during the pandemic?

<time>0:38:35</time> Paul Thagard: Well, it's hard to put it to work in something quite that specific, but there's certainly lots of more general things that needed to be done. I mean, part of this, in the sense of preform information has to start much earlier, critical thinking isn't something you can just sort of pull out of the hat when you've got a real problem. It's something that people should be taught. I mean, I taught at the university level but there are countries like Finland that teach it at the high school level. I think every high school student and possibly even some elementary school should be taught. Here's the difference between good ways of getting information and the kinds of mistakes that people naturally make and ways to correct it. So I don't see any reason why critical thinking shouldn't be taught in the high schools and quite pro quite possibly in the upper levels of grade schools as, as happens in Finland. So I think you need education going way, way down to a lower level. So it's not just the few university students who take courses in critical thinking, you get exposed to this. So that's one thing that should be there. But once you're in the throes, then you can start to, as lots of people have tried to make the distinction. What's the difference between a scientific journal article and a post on Twitter or X? Well, there's a huge difference but people don't understand that. They think that if Elon Musk post something on, well, he's, he's pretty, he's pretty reputable. He's, he's, he's got $200 billion he must know something. But of course, he's just getting his views from other people on Twitter and on, on X and so you got to know the difference between reliable sources and not. So that's a big part of it. Then once you're in the throes of it, you can start to juxtapose, hey, those people are saying things with no evidence, with no good inferences, they're just making it up. And so that's the battle you have to fight.

<time>0:40:18</time> Ricardo Lopes: So do you think that what we can learn about how misinformation originated and, and spread during the COVID-19 pandemic could serve as an illustrative example of how medical misinformation more generally gets generated and spread.

<time>0:40:39</time> Paul Thagard: Sure. The problem is universal. People take all sorts of bogus cures. They read somewhere and they, oh that supplement works, it says and so they, they try it. I mean, there are obviously lots of drugs that are effective, but there are lots of things that are just a complete waste of time. So all across medicine, there are kinds of treatments that are bogus. There are kinds of drugs that don't actually work. How do we know what's good or what's not? But the answer is actually well established in medicine. You use clinical trials, clinical trials are very sophisticated kinds of experiments where if you want to know whether a drug works, you take one group of people who get the drug and another group of people who get something else, a placebo, but you don't just sort of pick them or let them choose themselves. You'd use random assignment. You randomly divide people into two different conditions and then if you want to do it really carefully, you make them blind and you blind to who's getting what. So people don't know whether they're getting the drug or the control condition. And then once you've done this and you've controlled for all the different possible ways of confusion, then you will figure out does it work or does it not work? Well, the clinical trials have only been around since about the 19 forties. But it's a really solid well-established way to figure out whether a drug actually causes people to get better. So medicine's got this very good way of proceeding, namely controlled clinical trials, sometimes other kinds of studies are useful too. So we got a great way of doing this in medicine. So that's how we do it. What we don't do is oh, Joe took that drug that he got off a mail order and it made him happier. Well, that's not, that's not science. That's not evidence. That's just an anecdote. People often say, well, the plural of anecdote is not, is it's not data. That data means you do an experiment, you do a controlled experiment. So medicine knows how to do this well, and that's how we get our information if we're doing it right. And unfortunately people are getting their information about measles and vaccines and various drugs from social media or they're getting it from websites or just trying to sell stuff. And so it's motivated reasoning and misinformation. So we know how to do this right? Medicine, contemporary medicine is very sophisticated. But if we do it wrong, then we're gonna make people less healthy rather than more healthy, which is what medicine is supposed to do.

<time>0:43:00</time> Ricardo Lopes: Another kind of misinformation that you cover in the book is Scientific misinformation and you go through the example of climate change. So I I think this is a very good example for us to understand a little bit better. What might, what could be the consequences of people being exposed to misinformation? So what would you say are perhaps some of the biggest misconceptions surrounding climate change and what are the worst consequences we're having to deal with and we have to deal with in the future?

<time>0:43:35</time> Paul Thagard: Yeah, I think climate change illustrates information, information just as well as COVID-19 does. So is there real information about climate change? Sure, that's what the legions of scientists in the IPCC produced by the United Nations Intergovernmental Panel on climate change has been doing for decades now. So we've got huge amounts of good information. How's it done? It's done by measurements, it's done by observations, it's done by instruments. So we've got huge amounts of information that's also led to inferences. And so people have built these climate models that allow us to make inferences about what's likely to happen if global warming continues. So there are these 1000 page documents produced by the IPCC that are very closely reasoned, full of, of empirical information that tell us what we should expect and what we should worry about. So there real information is, is all available, but we just need to put it to work in making our decisions about how to run our society. But what's the difference? Well, on the other side, you've got lies and huge amounts of motivated reasoning. Why is it motivated reasoning? What's the motivation of people who are climate change deniers? Well, it varies. A lot of it though, comes from the oil companies, the oil companies have been producing huge amounts of fossil fuels. They, they get lots, they get billions of dollars of profits out of it. They don't want to be reined in because if there's less oil being sold, less gasoline being used, their profits will be hurt and so that will make their companies less profitable for the executives, it will make their powerless, it will make their, their salaries less. And so you'd have the, the, these companies that would be hurt by control on the use of fossil fuels because obviously the, the one way to get climate change under control is to reduce the amount of fossil fuels that are being used. So that's why the companies are, are biased. What about the politicians? Well, there are a lot of politicians that are basically in bed with the companies because that's where they get their funding. So that's major oil companies and the owners of the oil companies fund politicians to say what they want. And so the politicians will say, oh, we don't want to restrict fossil fuels. And there's so they make up stories about what's going on. What are the stories that make up? Well, I say all this is just to try to get control over people and affect people's freedom. Well, freedom is definitely an issue here because if you tell people no, you can't have a gas guzzling car and, and you have to pay taxes for on your use of carbon. Yeah, that does limit people's freedom. I think it's a justified one because it, it's in people's good. But there's some politicians, the conservative politicians both tend to be in bed with the fossil fuel companies. But also they like the idea of freedom as a sort of abstraction, irrespective of whether it's in people's good, good or not. So you have motivated reasoning on the side of the oil companies and motivated reasoning on the side of some politicians and then they're convinced that climate change isn't the problem. And so they tell the lies and other people believe them.

<time>0:46:43</time> Ricardo Lopes: So I wanted to ask you now and I guess that this would apply to a certain extent to some of the misinformation going on in social media and elsewhere surrounding climate change and also anti some anti vaccine or anti-vaxxer attitudes that people have. How do you approach conspiracy theories through the framework that you present in the book and how do they relate to misinformation more generally?

<time>0:47:13</time> Paul Thagard: OK. I mean, first of all, there are real conspiracies. So the information part is, yes, I mean, there actually are conspiracies in the world. I give two examples. One is the conspiracies that the Roman senators used to kill Julius Caesar. They got together and said, let's kill Caesar and they did. So that's a real conspiracy much more recently. It's well documented now that there were conspiracies around the attempt to have an insurrection in the United States after the last election. The huge up up roar that took place in the invasion of the US Capitol. That was a conspiracy, the Oath Keepers and the Proud Boys, they planned it and they led a big attack that killed people and and was an attempt to overthrow the government. So that's a real conspiracy that's well documented. But what you find a lot, especially among right wing commentators is conspiracies that are just made up. So I use two examples. I used the Qanon conspiracy. There's never any evidence for that for a real conspiracy. There's evidence we have documents that indicated what the Proud Boys were up to. We got emails we can know, see in fact they were getting together to plan the interaction so we can use observations and and things like emails, letters to indicate that something is a real conspiracy. But for the fake conspiracies, there's no evidence, there's no evidence that Q and on was any kind of reliable source and that the things that were being said about a supposed conspiracy among democratic politicians who are pedophiles to do all sorts of horrible things that's just all made up. And so we can use the difference between real information and good observations versus making stuff up to distinguish the difference between real conspiracies and fake conspiracies. Probably the most nasty ongoing conspiracy is called the Great Replacement theory. It's popular in, in some parts of Europe as well as in the United States. This is the idea that there's a kind of left wing plot to bring in nonwhite people to take over to take over the country. That's no, there's lots of good reasons for immigration, but this is saying, oh no, this is happening because there's because there's just a conspiracy, but they've never been able to document who's involved with conspiracy. How are they talking to each other? What's the paper trail? What's the email trail? It's just made up? And people believe it, why do they make, why do they believe it? It's motivated reasoning. People are afraid of immigrants, they get afraid, they think, oh we got to do something to stop this. And so we've got to get really good leaders, people like Donald Trump or the right wing leaders in Europe and they're the ones that will help us because they've got to stop the Great Replacement, but great replacement was just made up. It was a completely fictional conspiracy. So it fits perfectly under the account of misinformation that I gave because how is it made up? Well, again, it's motivated reasoning. People wanted power. People wanted to get lots of followers. People were trying to convince people that there were threats that weren't really there because that enabled them to get more power. So that's really greed for power as much as it is greed for money. So greed fuels motivated reasoning which fuels bad communication, which follow which fuels misinformation and that flies in the face of real information that we can have about real conspiracies that do sometimes occur. So the aims theory fits just as perfectly with conspiracy theories as it did with COVID and with climate change.

<time>0:50:54</time> Ricardo Lopes: A and you give the example of the grid replacement conspiracy theory there. And I guess another interesting aspect here and please correct me if I'm wrong. But I would imagine that one interesting aspect of some of these conspiracy theories is that they seem to be recurrent there is they, they come and go, they come into fashion, they go out of fashion because the great Replacement theory, if I remember correctly is much older than the past. I don't know, 1015 years, I guess it's more than 100 years old, at least it's from the time of eugenics in the 20th century, Nazism and all of that.

<time>0:51:37</time> Paul Thagard: Yeah. So it's an old one but they're even older ones take any semi, which has been around for at least 1000 years. The view that Jews are in a conspiracy to take over the world, still, still very popular, but entirely made up. So the, but it's been around for, as I said, more than 1000 years.

<time>0:51:58</time> Ricardo Lopes: So could you give us then an example of political misinformation and what counts as political misinformation or that you would classify as such?

<time>0:52:10</time> Paul Thagard: Well, I've given some examples already such as that the 19, the 2020 American election was stolen. So Trump is always talking about elections being stolen. So that's one way that it could be done. But there are other things that can be done to people that are, that are more subtle. Their lies told for example, about the economy. So after COVID Western economies went through big problems of inflation and it was really bad. Inflation was hitting a 10% a year and that was really causing problems because people who live pay paycheck to paycheck and suddenly found their food was costing considerably more. This was a really serious problem for a lot of people and the politicians who want to accuse the government of constantly being irresponsible emphasize. Oh, we still got inflation. But if you actually look at the numbers in Canada and the United States and Europe, inflation has actually gotten pretty much under control. It's down to maybe around 3% in most countries. And so people are still feeling it because inflation was really great for a few years. So it's in the interest of politicians who want to overturn the current government to say, oh, affordability is a huge problem. Well, it is a problem but it's a problem that in fact has largely been gotten under control because the inflation rate is down to reasonable levels. So it's a case where the extent of the affordability problem and it's certainly the causes of it can be lied about by politicians rather than the careful economists who try to say. Yeah. Ok, we had had a big problem around coming out of COVID. But now thanks to things like tightening of money and higher interest rates, it looks like it's pretty much under control. So that's another case where you get political po political misinformation.

<time>0:53:57</time> Ricardo Lopes: And in the book, you also talk about misinformation about inequality but isn't it, isn't it a sort of a kind of political misinformation or not? Am I misunderstanding it here?

<time>0:54:12</time> Paul Thagard: Oh, it, it's a lot of it has to do with politics. It's certainly true because the governments have to make decisions about fighting inequality. So if someone says, for example, oh, we've got to raise taxes on the rich so that we can provide services to the poor. That's a political question. But it's broader than that. It happens in other areas too. So it happens, for example, in, in education, education, these are sort of political decisions because, but, but it, it's coming up in a lot of different ways but just even in ordinary life and think about relationships, social relationships, romantic relationships, sexist ideas involve all sorts of kinds of inequality. The things that have to take a really extreme example if someone says, oh men should be in charge of their marriages because they have bigger brains than women. OK. So men should be in charge because they got bigger brains. So they're smarter a whole layers of, of, of misinformation there that isn't political, it has to do with biology. What's the misinformation? Well, actually, men do have bigger brains than women, but that's only because in women, the neurons are more densely connected and more densely packed in. They got the same number of neurons and by any objective measure, they're just as smart as men. So that's one piece of inequality. Sorry, one piece of inequality based misinformation. And it can be used to justify different kinds of of patriarchy that men should be running because they got better brains and other sort of things that could go into that of all sorts of stereotypes of women as being inferior in other ways as being more emotional, it, it's all made up stuff not based on anything that's empirical about the brain or coming from empirical psychology. So that's a case where interpersonal relationships that don't necessarily involve the government can be distorted by misinformation about inequality.

<time>0:56:07</time> Ricardo Lopes: And when it comes to the Russia Ukraine, ongoing conflict, in what ways would you say misinformation might have played a role here? I would imagine both in the initiation of the conflict but also in driving the conflict, the conflict forward.

<time>0:56:28</time> Paul Thagard: Well, war always involves lies. It's whoever is in a war, they're always motivated to make things look good for them and bad for the other. And Ukraine wasn't perfect about this by and large. I think they've been accurate reporting, but there were some stories that came out of the early stage of, of the war that made it made them sound really good. They had various kinds of heroic things that supposedly happened that turned out not to be well documented, but that, that was just minor stuff. Whereas with Russia and the kinds of misinformation that I mentioned earlier, things that they're claiming that the recurring is run by Nazis or that they've got this historical right to it. I mean, that's much more serious and, but on the, as things go on, they've got various lies about who's winning and who's losing. So, misinformation is a big problem in all wars. But in this case, given it's clear that it was a, a just war on the part of the Ukrainians defending themselves and an unjust war on the part of the Russians who invaded. There's really an asymmetry there. And so the, the misinformation spread by Russia is, is far more serious.

<time>0:57:34</time> Ricardo Lopes: So let me ask you one question about these different kinds of types or domains of misinformation that you go through in the book. So we've covered medical scientific, political misinformation, misinformation about inequality and specifically also the Russian Ukraine conflict. There's also social misinformation, but we'll leave that for the audience to read about it in your book. But why exactly do you distinguish between these different domains or kinds of misinformation? I mean, are they to be understood as completely separate or how do we, how should we think about it about

<time>0:58:15</time> Paul Thagard: them? But the important thing from my point of view is that they all get explained by my theory, my aims theory with acquisition inference memory and spread applies perfectly well to all of them. And so it gives a unified theory for all these different ones. And of course, there's other kinds of misinformation as well that I did talk about. But I think what's really cool from my point of view is I've got a unifying theory that not only explains how we get real information, but also explains how misinformation arises, but also gives some hints at what we can do to try to prevent it and cure it. So that's what a good theory does. How do things work when they work? Well, how do they break and how can we fix it? So I don't particularly care about whether something falls under social or political or, or romantic misinformation. The important thing is that all these really rich aspects of human life can be explained by a common theory of information and disinformation.

<time>0:59:12</time> Ricardo Lopes: Earlier, you mentioned ways of tackling misinformation, like for example, inoculation, pre bunking at this point in time, what do we know about the effectiveness of each of those measures, let's say I mean, which one works best as far as we know. That's

<time>0:59:36</time> Paul Thagard: a wonderful question for which we don't really have an answer yet. I mean, the the analogous medical question is look, we got these different kinds of drugs or antibiotics which work on works best. So you got to do a, a complicated clinical trial, you get a whole bunch of people, some people get one drug other people get a different one, different kinds of treatment. This hasn't been done. A bunch of these things have been tested sort of individually that is there are experiments done by good psychologists that show, yeah, sometimes pre bunking works and sometimes motivational interviewing works, sometimes critical thinking works. But we haven't had these kinds of giant clinical trials that would tell us when you've got misinformation, spreading through a population of a lot of people. Exactly which of these techniques works best under which circumstances, it would be wonderful to have that. But these experiments are hard to do and no one's been able to do anything of that scale. So I think that's a great question and I'd love to see that kind of research being done. But by and large, all we can do now is trial and error and in particular situations and see what's the thing to do. One thing I didn't talk about as a, as a way of operating in these situations. Sometimes none of these psychological things are gonna work. Sometimes. Basically what you need is political action. So if you've got Vladimir Putin spreading lies, if you got Donald Trump spreading lies, you're not going to convince Putin that he's wrong, you're not gonna convince Trump that he's wrong. What you've got to do is have political movements that can get these people out of power in the US. It can be done by ensuring you don't vote for Donald Trump in the Soviet Union or sorry, in Russia, it's much harder because he's a dictator. That's exactly where Trump wants to be as well. But at least if you're a democratic company country, you can make sure you vote for leaders who have a commitment to truth, to have a commitment to scientific ways of collecting evidence and making their society better on the basis of these reliable methods rather than just relying on making stuff up and motivated inference and communication by lies. So it puts a big onus on, in fact, individual voters in these situations. Unfortunately, in, in Europe and in, in North America, we we do have the electoral means to do this and you have to vote the liars out of power. That's the political action side of trying to prefer information over real information over misinformation. So it becomes a political question, not just a cognitive or psychological one.

<time>1:02:08</time> Ricardo Lopes: And do you think that a content regulation or moderation on social media should also be a tool in our toolbox here?

<time>1:02:17</time> Paul Thagard: Definitely that's really badly needed. It's very strange the way that social media kind of grew up without any kind of control in the US. It was quite explicit. They passed a law that said that the social media companies aren't responsible for the people who post to them. Well, newspapers aren't like that if someone says in a public newspaper, a complete lie, well, they can be charged with libel or slander or things like that. Anyone can say anything they want, but there needs to be tightening up on the social media so that people can be held responsible for what they've said. There's some movements to try to do that, but it's really hard because these media companies are really powerful. They're really rich. The European Union has actually been much better at this than North America. They brought in various ways of trying to control social media. One of the advances in the European Union that I'm really impressed by is they're bringing in new rules for controlling what happens with generative A I, which is a huge new source of, of misinformation. It was only a little bit of a problem when I wrote that book. But now that the book is out, it's a huge problem because it's really easy to generate not just words but also pictures using generative A I, it's just taken off in the last year. So that's really dangerous. But the European Union is thinking hard about this. Unfortunately, they Canada and the US are have been much slower in the US. It's tricky because you've got all sorts of political forces that don't want control by government. The European Union I think is doing a really good job of, of looking at social media and looking at generative A I as ways of potentially being great sources of misinformation. So politics can work. Sometimes you just have to work with leaders and voting to get people into place who will work for the sake of human needs rather than for the greed of people who are wealthy and powerful.

<time>1:04:13</time> Ricardo Lopes: And when it comes to generative A I and also now with video, audio images, deep fakes, for example, I guess that it not only affects social, I mean, society in general and politics but it can also affect individual people if they have misinformation in the form of video, audio and so on about them over on the internet. And that as a form of music information.

<time>1:04:46</time> Paul Thagard: Yeah, but they, but, but really directly harmful. There's problems in Canadian high schools where some of the students are creating porn videos using pictures of their, there's all these techniques that are now available that can cause immense harm. Obviously, it's really dangerous for political purposes too because it's very easy to create pictures of people saying things that they never said I've got all sorts of videos online. People could produce another video with me saying the opposite of what I actually believe. So these are new sources of misinformation that are just getting worse and worse as the technology gets more and more advanced.

<time>1:05:26</time> Ricardo Lopes: Are there ways by which you think individual people, I mean, something that they can do in their daily lives in their personal lives to try to be less susceptible to misinformation?

<time>1:05:43</time> Paul Thagard: You know, there are a lot of things that people can do. Some of them are more sophisticated, like engaging in critical thinking, which requires a lot of background. But something that I think it's just really basic ask what is the source of that information and what is the motivation of that source? If you just ask that question, then you're gonna be able to wonder. Well, is there, are they saying it because it's true or because they're just trying to trick me into buying some product from them. So if, if people, instead of just automatically getting something in social media and then passing it on to other people, which people do all the time, they get, they get a link. That's interesting. I'll send it to my friends but always stop and think, stop and think who's sending this? Is it true? What's their motivation? If you just ask yourself those three questions that's already going to dramatically slow down the spread of misinformation through particular communities.

<time>1:06:34</time> Ricardo Lopes: So let me just ask you one last question then do you think that there are ways by which this book connects to some of your other work? Like for example, your book, The Cognitive Science of Science or, or not,

<time>1:06:52</time> Paul Thagard: you know, a lot of this comes out of the work I've done in Philosophy of Science. So a lot of that work I've talked about, say the difference between good evidence and, and making stuff up or the difference between evaluating theories carefully, which is something that goes back to my phd dissertation as opposed to just believing what you want. And so yes, my background in philosophy of science definitely fed into this whole account of misinformation.

<time>1:07:20</time> Ricardo Lopes: So the book is again, falsehoods Fly. Why misinformation spreads and how to stop it. I'm leaving a link to it in the description box of the interview and doctor F just before we go apart from the book, would you like to tell people where they can find you and your work on the internet?

<time>1:07:40</time> Paul Thagard: By far? The easiest is my main website is Paul thagard.com. So there you'll find information about my books, copies of hundreds of articles. You can also find a link to my blog post. If you want a sort of non technical introduction to my work, I've got almost 100 and 70 blog posts there that cover some of this in a really quite non technical way that people in general can understand. So go to Paul thr.com and that'll get you a po a pointer to the blogs as well.

<time>1:08:11</time> Ricardo Lopes: Great. So thank you so much again for taking the time to come on the show. It's been a real pleasure to talk with you. Thank

<time>1:08:18</time> Paul Thagard: you for asking great questions.

<time>1:08:20</time> Ricardo Lopes: Hi guys. Thank you for watching this interview. Until the end. If you liked it, please share it, leave a like and hit the subscription button. The show is brought to you by N Lights Learning and development. Then differently check the website at N lights.com and also please consider supporting the show on Patreon or paypal. I would also like to give a huge thank you to my main patrons and paypal supporters, Perera Larson, Jerry Muller and Frederick Suno Bernard Seche O of Alex Adam, Castle Matthew Whitting B no wolf, Tim Ho Erica LJ Connors Philip Forrest Connolly. Then the Met Robert Wine in NAI Z Mark Nevs calling in Holbrook Field, Governor Mikel Stormer Samuel Andre Francis for Agns Ferger Ken Herz J and Lain Jung Y and the K Hes Mark Smith J. Tom Hummel Sran, David Wilson, the desario Roman Roach Diego, Jan Punter Romani Charlotte Bli Nicole Barba, Adam Hunt, Pavlo Stassi Nale Me, Gary G Alman, Samo Zal Ari and YPJ Barboza Julian Price Edward Hall, Eden Broner Douglas Fry Franca Lati Gilon Cortez or Solis Scott Zachary FTW Daniel Friedman, William Buckner, Paul Giorgino, Luke Lova Georgio, Theophano, Chris Williams and Peter Wo David Will Di A Costa Anton Erickson Charles Murray, Alex Chao Marie Martinez, Coralie Chevalier, Bangalore Larry Dey junior, old Eon Starry Michael Bailey. Then Spur by Robert Grassy Zorn, Jeff mcmahon, Jake Zul Barnabas Radick Mark Temple, Thomas Dvor Luke Neeson, Chris to Kimberley Johnson, Benjamin Gilbert Jessica. No. Linda Brendan Nicholas Carlson, Ismael Bensley Man, George Katis Valentine Steinman, Perlis, Kate Van Goler, Alexander Abert Liam Dan Biar Masoud Ali Mohammadi Perpendicular J Ner Urla. Good enough, Gregory Hastings David Pins of Sean Nelson, Mike Levin and Jos Net. A special thanks to my producers is our web, Jim Frank Luca Stina, Tom Vig and Bernard N Cortes Dixon, Benedikt Muller Thomas Trumble Catherine and Patrick Tobin, John Carl Negro, Nick Ortiz and Nick Golden. And to my executive producers, Matthew Lavender, Si, Adrian Bogdan Knit and Rosie. Thank you for all.

</div>

[Back to top](#top)
