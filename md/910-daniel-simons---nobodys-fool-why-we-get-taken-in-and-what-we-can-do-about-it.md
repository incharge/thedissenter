---
draft: false
excerpt: 'Dr. Daniel Simons is a Professor in the Department of Psychology at the
  University of Illinois, where he directs the Visual Cognition Laboratory. Dr. Simons
  studies visual cognition, perception, attention, and memory. Most of his recent
  research has focused on the cognitive underpinnings of our experience of a stable
  and continuous visual world. He is the author of The Invisible Gorilla: And Other
  Ways Our Intuitions Deceive Us, and more recently, Nobody''s Fool: Why We Get Taken
  In and What We Can Do about It.'
id: '910'
image: https://i.ytimg.com/vi/VFDbbAJsVCs/maxresdefault.jpg
publishDate: 2024-03-08
title: '#910 Daniel Simons - Nobody''s Fool: Why We Get Taken In and What We Can Do
  about It'
youtubeid: VFDbbAJsVCs
---
<a name="top"></a>[Jump to transcript](#transcript)
## Show notes
<div class="timelinks">

RECORDED ON OCTOBER 26th 2023.  
Dr. Daniel Simons is a Professor in the Department of Psychology at the University of Illinois, where he directs the Visual Cognition Laboratory. Dr. Simons studies visual cognition, perception, attention, and memory. Most of his recent research has focused on the cognitive underpinnings of our experience of a stable and continuous visual world. He is the author of The Invisible Gorilla: And Other Ways Our Intuitions Deceive Us, and more recently, Nobody's Fool: Why We Get Taken In and What We Can Do about It.

In this episode, we focus on Nobody’s Fool. We talk about our “truth bias”, why it works most of the time, and what makes people skeptical in certain situations. We go through four psychological habits that make us susceptible to deception: focus, prediction, commitment, and efficiency. We discuss expectation-based reasoning, and how it can affect the production of scientific knowledge. We also go through four hooks that deceivers use: consistency, familiarity, precision, and potency. Finally, we talk about how deceivers try to target the most vulnerable people.

Time Links:  
<time>00:00</time> Intro  
<time>00:33</time> The premise of the book  
<time>02:15</time> A “truth bias”  
<time>05:28</time> When are people skeptical?  
<time>07:57</time> Psychological habits that make us susceptible to deception: 1. Focus  
<time>15:34</time> 2. Prediction  
<time>19:30</time> Expectation-based reasoning, and how it can affect the production of scientific knowledge  
<time>26:57</time> 3. Commitment  
<time>31:33</time> 4. Efficiency  
<time>40:46</time> Four hooks: Consistency, familiarity, precision, and potency  
<time>1:03:46</time> Do the best deceivers use all four hooks?  
<time>1:07:28</time> Targeting the most vulnerable people  
<time>1:12:57</time> The message of the book  
<time>1:16:06</time> Follow Dr. Simons’ work!

---

Follow Dr. Simons’ work:  
Faculty page: https://bit.ly/3s0teFz  
Website: https://bit.ly/3DQOhgt  
Nobody’s Fool: https://bit.ly/3YskdRU  
Twitter handle: @profsimons
</div>

[Back to top](#top)
<a name="transcript"></a>
## Transcript
<div class="timelinks">

<p class="text-muted text-sm bg-slate-200 rounded p-1 text-center">Transcripts are automatically generated and may contain errors</p>
<time>0:00:00</time> Ricardo Lopes: Hello, everybody. Welcome to a new episode of the Center. I'm your host, Ricardo Lobs. And today I'm joined by Doctor Daniel Simons. He is a professor in the Department of Psychology at the University of Illinois where he also directs the visual cognition laboratory. And today we're focusing on his latest book together with Dr Christopher Chabris, who I've already have on the show, by the way, nobody is fo why we get taken in and what we can do about it. So Dr Simons, welcome to the show. It's a big pleasure to everyone. Thank you for having me on. So tell us perhaps first a little bit about the premise of the book. I mean, I even have a quote here where you say that it's basically about exploring the cognitive psychology of the cheat, the patterns of thinking and reasoning that make us all vulnerable to deception. Could you explain that?

<time>0:00:54</time> Daniel Simons: Yeah. And that's the broad theme of the book. We took a look over many years at scams and, and cons and just regular run of the mill deception across a wide range of disciplines, everything from investment fraud to cheating in chess to try and see whether there were any commonalities across all of them. And what we started to realize was that there were some common tendencies that we all have that make it possible for people to take advantage of us. And there are tendencies that work well most of the time. But that when somebody is looking to take advantage of us, they co opt them or hijack them for their own purposes. So that was one theme that we found that was really consistent across a wide range of kinds of deception. The other was that any of us can be fooled. We, we have this kind of intuition that and belief that when you hear about a fraud, you hear about somebody falling for a scam. In retrospect, you can see all the red flags they missed, you can see everything that they didn't notice along the way. And that makes it seem like they must be clueless or naive or gullible. But the reality is that the scammers just happen to target them well, for that particular scam and any of us, no matter how educated, smart, skeptical, critical thinking we are can be victimized if the targeting is aimed at us.

<time>0:02:15</time> Ricardo Lopes: Yeah. And we'll get into some of the aspects of human cognition that you explore in the book that make us susceptible, all of us susceptible to deception. And I guess that that's very good point because actually, I mean, almost every single time that we hear about someone falling for what, for us from the outside seems like a very basic scam. We're always like, oh, it's because the person was really gullible or stupid or dumb. Or it's because she's low in intelligence. But that doesn't seem to be really the case, at least most of the time.

<time>0:02:53</time> Daniel Simons: Exactly. And, and there's, there's so much entertainment industry depiction of cons and scams. Right. And you can go to the theater and see a heist movie, you can listen to a podcast and hear all about a con artist. But whenever you do that, you know that there's deception taking place, you, you are watching it knowing that it's about deception, which means that you're looking for all of those hallmarks, you're treating it more like a mystery where you're trying to figure out where they went wrong. But when somebody is immersed in the narrative themselves, when they're, when they're the target of it, they don't see it from that outside perspective, they only see what they're being provided and that can lead to anybody if it's targeted, appropriately being

<time>0:03:32</time> Ricardo Lopes: fooled. But do you think that there is good evidence that we have sort of a truth bias that is that we most of the time tend to believe or have this tendency to believe at face value on what people are, what other people are saying? And I mean, if so, is that really a problem? Because isn't it that at least most of the time, there's very good reasons to think that what someone is saying is actually true. Yeah.

<time>0:04:04</time> Daniel Simons: Absolutely. And most of the time nobody's trying to deceive us. So it makes sense for us to accept what we're hearing is true most of the time. That's what we call a truth bias. That the idea of a truth bias is a little more nuanced than, than just accepting everything is true. It's the idea that whenever we hear something, whenever somebody tells us something, our initial evaluation of what they've said assumes it's true regardless of what it is. And then it takes a little bit of time or a little bit of effort to rip it apart if we think it's wrong. So, and you know, it's easier in some context than others. If somebody says something that we firmly don't believe or there's somebody that we don't ever trust, we know not to trust them, we're going to discount what they say pretty quickly. But we have to take in what they're saying, process it make sense of it. And part of that is kind of like the need to accept that it's real that it's true before we then debunk it. So a truth bias is really a functional thing. We have to have that otherwise we couldn't interact with anybody around us, our society would not be able to function. We have to trust that most of the time what we're hearing is true. And that's the base rate for that is good, right? That, that's actually what we want to be doing. The trick comes in how people who are trying to deceive us, take advantage of that. They'll give us some information that's not true, but then not give us the opportunity to tear it apart or to critique it or to realize that it's false?

<time>0:05:29</time> Ricardo Lopes: And are there specific conditions where people remain uncertain or skeptical of what someone claims? I mean, are there specific situations, cases conditions where I mean, even though for most situations, if someone just says something that doesn't trigger in us, I mean, our perhaps deception detecting or a device or something like that. I mean, that, that we e even then think, OK, so in this particular case, I will remain skeptical until I learn a little bit more.

<time>0:06:13</time> Daniel Simons: So I think we often do that we should do it a lot more remaining uncertain is probably the best thing we could do to avoid spreading unintentionally spreading misinformation or repeating falsehoods. I if you remain uncertain a little bit longer and look for more information, that's a great strategy to make sure you're not being fooled. And there, there certainly are going to be context when we are going to do that, right? We're going to be more willing to be skeptical when it's something that we had doubts about to begin with when it kind of ran counter to our beliefs or our ideology or our, you know, willing. So if somebody, for example, provides scientific evidence, claims to provide scientific evidence for ESP I don't believe that's likely to be true. I think there's plenty of good reasons not to believe that that's true. As a scientist, I should remain uncertain as long as I can until the evidence becomes overwhelming. In that particular case, I think it's pretty overwhelming, but let's say that somebody provides some evidence for something that I don't agree with, I don't think is likely to be true, but it might be, well, that's a context in which I should remain uncertain a little bit longer. I should be willing to accept the possibility that I was wrong initially or that the evidence that they're providing is wrong and that, that's a great strategy to use. It's one that we should use a lot more than we do. Including scientists, scientists don't remain uncertain as much as they should. They're much more willing to take on a strong belief and then discount anything that runs counter to it. But we should remain uncertain until the evidence is clear. The problem is we rarely have the time or energy or willingness to do all of the digging that we need to, to show that it's actually clear.

<time>0:07:56</time> Ricardo Lopes: And so let's get into the aspects of human cognition you explore in the book that really makes make us all susceptible to some, at least some degree of deception. So you talk about four different things, focus prediction, commitment and deficiency in the book. So starting with focus, what is this really about?

<time>0:08:21</time> Daniel Simons: Yeah. So those four, those four elements are what we call habits. So there are cognitive tendencies that apply most of the time in our daily lives, the things that we have to do that usually are really, really effective for us. So focus is the idea that we primarily direct our attention to what we have right in front of us. The information that we have most of the time, the information we have is the information we need. So it makes sense to focus on what we're doing, what we're looking at what we're thinking about at that moment. The challenge of focus is that we often don't realize when we don't have information that we might actually need and that's where we run into problems. So the idea of focus is that most of the time we use the information at hand to do what we need to do with it, to make sense of the world. And that's usually a great thing and we usually don't have to worry about all of the other stuff that would just be distractions from the thing we want to pay attention to. The problem comes when the things that we're missing really should be influencing our judgments, our decisions or our reactions to the world and people who are looking to deceive us will deliberately focus your attention on one thing. So, if you've ever been to a magician's show, a magic show, the magician is going to direct your attention, they're going to get you to focus on the effect what they're wanting you to see and away from the method, the hidden information that they're trying to, that they're trying to keep away from you and they're going to do lots of things to focus your attention. They're going to have a lot of witty banter and joking that gets you focused on what they're saying and not what they're doing. But again, the idea is we focus on a limited amount of information. We can't focus on everything. And the end result of that is sometimes the things that we're not focusing on are things we need to pay attention to.

<time>0:10:10</time> Ricardo Lopes: You mentioned magicians there. But I guess that there's another instance where people really try to make us focus on just the positive aspects of, of something and make us lose focus of the perhaps more negative aspects of something. Like, for example, when a company is trying to sell its products, I, I mean, in advertisement and all of that advertisement is basically all about that, right? It's basically about focus and just focusing on the positive aspects of products. So how do they do that? Exactly.

<time>0:10:49</time> Daniel Simons: Well, I mean, that, that's, they're just taking advantage of the fact that we do that naturally. So, advertising, I don't tend to think of advertising in the same light as cons and deceptions. There they have a goal, they want you to think about their product and not alternative products. They want you to be directed attention to the positive features of their product and not to the negative ones. Right. So, so what do they do? They just don't present the negative ones, they present only the positive ones and we tend to kind of think that those are representatives. So I think one of the best examples of this is demos. So showing a video of a car driving itself and we see that video and say, wow, OK, I could, I would love to be able to do that and just read a book while the car is driving me to work. And we think about all of the possible ways that that same process could generalize. We assume that what we're seeing is representative of what that car can do. And we don't think about all of the things that they haven't shown us things like how many times did they try and do that demo before it worked once? How many times did the car drive off the side of the road? How many times did it run a stop light or a stop sign? We don't think about those sorts of things. Does it only work on straight roads? Does it only work in perfect sunlight conditions or would it not work if it's raining? What if a pedestrian ran out into the road? We don't tend to think about those things in real time while watching this demo. Instead, we take it as representative, our focus on that demo take treats it as typical of what happens in the world and the end result is we just don't think about the information we don't have. So advertisers aren't having to do a whole lot to get us to focus on their product. All they have to do is present the information they want us to have and they can kind of count on us not thinking about the information we don't have unless they say something really egregious, then we might take a step back and say, wait a second. Is that really true? And think about it, in which case they've lost us, that's not what they want us to do.

<time>0:12:52</time> Ricardo Lopes: And I guess, I guess that apart from the product, something that they do often is that they present next to the product, high status or very famous people, right? And that's another thing that perhaps make us lose focus on some of the potential negative aspects of the products. Right. Sure.

<time>0:13:12</time> Daniel Simons: And that, that's actually tapping into one of the hooks that I guess we'll talk about in a little bit of familiarity. As well. It's, it's tapping into the idea that for somebody who's a very famous person we kind of feel like we know them even though we really don't. And that familiarity makes us trust things more. So. Yeah, they, they use a lot of the advertising uses a lot of these sorts of tactics. They take advantage of a lot of our strategies for how we process information. Just like people looking to actually deceive us

<time>0:13:40</time> Ricardo Lopes: do. Mhm. And do you think that there are perhaps some strategies, some things that we could do to counter this tendency that we have to narrowly focus on just one piece of information?

<time>0:13:56</time> Daniel Simons: Well, I mean, it depends what you mean by, by counter them. Can we make it so that we can take in everything at once? No, I mean, and, and people like to kind of think so. So you might know my earlier studies with people passing basketballs and a person in a girl suit walking through a video. And people don't, about half the time people who watch that don't see the gorilla. And one of the most common questions I get is, well, you know, what can I do? So that I see the gorilla and my reaction to that is first, there's nothing you can do that would make it so that you can always see unexpected things. And second, that would be a terrible thing for you. You do not want that because there are limits on how much we can pay attention to and those are structural limits on how our minds work. We all have that sort of limitation we can't take in everything all at once. Instead, we have this remarkable ability to focus on what we care about and to ignore distractions that's essential. Can you imagine trying to drive down the road and not be able to ignore everything that's going on on the buildings next to you and on the sidewalks, that's irrelevant to what you're doing. You'd be perpetually distracted. You couldn't focus on what you needed to do and an inability to focus is harmful. That's a problem for a lot of people. We all have the ability to focus to some extent, right? We, we can do that, but you can't get to the point that you take in everything and notice everything because then you couldn't focus anymore. And given that we have limitations, we have a total amount of resources that we're able to use. Anything you use up on stuff that you don't care about is stuff that you're not using for what you do care about.

<time>0:15:34</time> Ricardo Lopes: Mhm. And I guess that the aspect you mentioned there about expectations leads us to the second habit. You're exploring the book that has to do with prediction. So what's that about?

<time>0:15:49</time> Daniel Simons: Yeah. So prediction is the idea that we tend to kind of look for the things that we expect to be there and want to be there. You can think of this as a little bit like the idea of confirmation bias. We tend to look for information that's consistent with our beliefs as opposed to inconsistent with our beliefs. But we, we frame this a little bit more broadly, which is that when we are given information that fits what we predict, we tend not to question it as much as we do when given information we disagree with. So if you're online and somebody posts something that is completely opposite to your ide ideology or your politics, you're probably going to be highly critical of it. And we're really good at tearing apart things. We don't believe in. We all have that sort of critical ability to rip something into pieces. But if somebody happens to share something that you happen to agree with, you're not likely to dig into it as deeply as you would otherwise. And if you don't dig into it, you might not realize that it's based on weak evidence. So you can pass off something that's not true by making it consistent with what people want to believe. And a huge amount of the misinformation we see online is targeting people with information that they believe it's not, it's not trying to fool me into thinking something that I don't believe in the first place. It's spreading it to people who are likely to believe it who then spread it along to other people and that makes it kind of gain this sort of mass spread. So the whole idea of that sort of viral transmission is not, not persuading people who disagree with you because they're going to tear it to pieces. It's reaching the people who would agree and not think critically enough. So, the idea of the, the habit of prediction is that we, we tend to not think as critically about. We tend to accept the truth of things that we expect and that we predict more than things that we don't.

<time>0:17:45</time> Ricardo Lopes: And perhaps linking here to one of the first points we made in our conversation when we mentioned that being deceived as very little or nothing to do with people being more gullible or less intelligent. I mean, I can't it be, can't it happen that if someone is better at reasoning, they might even be more blinded by their own expectations?

<time>0:18:11</time> Daniel Simons: Yeah, there's some, there's some suggestions of that in the literature that people reason really well, e even for simple problems known as syllogisms, where you give people a logical sequence, where you, you give them two premises and then a conclusion. If that conclusion fits your beliefs, you tend not to question whether it's logically sound as much as you do if it, if you disagree with it. So if you have a conclusion that gun regulations save lives, which is of course an issue in the United states, not as much elsewhere in the world, fortunately, for the rest of the world. But, if you believe that gun regulation will save lives, then a conclusion that fits that, even if it's not logical, even if the premises don't lead to that conclusion, you're going to tend to accept it as true. Whereas if you think that gun regulations are bad, you'll find the logical flaws and the same thing. If you flip it, if you think if you've reached the conclusion that gun regulations are going to hurt safety, then if you believe that you're not going to be as critical as of premises that just that don't match it, right. They don't actually lead to that conclusion. So, yeah, very smart. People can tear apart conclusions that don't follow if they disagree with them but are not as critical when it comes to things that they agree with

<time>0:19:31</time> Ricardo Lopes: and can this sort of expectation based reasoning have a negative impact specifically in science and the production of scientific knowledge?

<time>0:19:43</time> Daniel Simons: I think it's actually the biggest source of inadvertent scientific errors, just mistakes. One way to think about this is imagine you're doing a study and you have a new experimental treatment and you want to test it in a randomized clinical trial. So you have a treatment and you have a placebo and you expect the treatment to do better than the placebo and that's what you find in your results. So great. Publish it. What if you had found that the placebo did better than the treatment? What would you do as a scientist? You go look at your data and see. Did I get something wrong? Did I mislabel the columns? Did I get them backwards? Were there some problematic data points in there, were there some participants who weren't, you know, assigned correctly? So you'd look for problems and you look for mistakes And the key is that you look for mistakes more when something is unexpected and not what you predicted, and you're probably less likely to do that when it's predicted. And one of the most famous examples of this sort of error came from work by Reinhart and Rogoff, who economists at Harvard, who were interested in pushing the idea of austerity for fiscal austerity. So they analyzed historical data from a bunch of countries and their claim from their evidence was that once the country's debt reached 90% of its GDP that their economic growth tapered off, it crashed. So that was an argument that we shouldn't be spending our way out of economic problems because increasing the debt is going to kill our economic growth. The problem was that it was at the conclusion, the data were actually based on an Excel spreadsheet error. They didn't fill down an equation all the way down to the bottom. They, they stopped after 15 countries didn't go to all 20 countries and the result doesn't hold if you actually include the rest of the countries. So it literally was just an error. And it was an innocent mistake. I don't think there was any intentionality. There, there was no fudging of data, there was no, you know, there, there was no scamming going on there, but they firmly believed this idea of austerity and when the results happened to perfectly match it, they ran with it. They didn't bother to check it. I guarantee you that if that result had come out the opposite, if they had filled down and made a mistake in their Excel spreadsheet, that had led to the claim that austerity was terrible and that you could continue spending as much as you want. And there's no problem, they would have really triple checked their data and found the mistake. So that creeps in all the time. I think in scientific era that people are much more likely to rigorously check things that don't match what they predicted than there are things that perfectly match what they predicted

<time>0:22:18</time> Ricardo Lopes: and being realistic here. And since scientists are also people and like other people, they have basically the same psychology. Do you think that since we can't expect scientists to not have any expectations at all that this would be a point in favor of something like viewpoint diversity in science?

<time>0:22:44</time> Daniel Simons: I I think the first thing we should assume is that scientists always have opinions because we're human. So we always have beliefs, we always have expectations. We can't view things completely neutrally. I think this is an argument for implementing policies that make it harder for us to fool ourselves because the real danger in science is fooling ourselves. Most scientists are not trying to fool other people, but they can be fooled themselves and then they spread information that's wrong. I think there are a lot of things we can do to actually hedge that. So one is to use different approaches to publishing. So one is to write your analysis scripts in advance of the study before you have any data and test them out with pilot data that you know, has different characteristics. So that when you apply to the real data, you know that the analysis isn't going to have an Excel spreadsheet error in other is to not use Excel for your data analysis, but that's a different issue. The other thing that I do in my own lab now is that for every study we do, Typically I am a graduate student each independently code the data analysis. So we, we write the analysis separately ourselves and make sure that we get the same results. And if we don't, normally it's just something, you know, a tiny coding bug, but you want to catch those before you publish them and that catches these sorts of mistakes. Because if we're both analyzing the data, it makes it less likely that we're both going to make exactly the same error in, in our analysis or exactly the same error in our coding and you can find the discrepancies and figure out what's wrong with them. So I think those are good things to do in terms of ideological diversity. Yeah, I mean, the real challenge is, of course, people aren't going to believe the opposite side. There are plenty of examples of this in science, you know, in every field of science, there are sub fields in psychology, for example, where there are two sides and they don't believe what the other side has to say. And it doesn't really matter how strong the evidence is, they won't listen to the other side and that's not productive, right? We don't advance. I don't think it's necessarily a terrible thing for science as a whole because people outside of that fight who don't have a stake in, it can look at the evidence from the outside and say, ok, well, here's what they're arguing about and I find one side more plausible than the other. So people not immersed in that fight, they're going to be able to take a step back and be more objective because they don't have, they don't have a horse in the race, right? So for them, it's not, it's not as ideologically, you know, complicated for the debate about, you know, I, I think the debate about ideological diversity, I think it's not just political diversity, it, it's having a range of views so that you aren't all expecting exactly the same outcome and that, that can be true for a really narrow, boring question. You know, is there memory for where you've searched items, letters in a display before or after, after you've searched that location? Is there any reference to that you've been there before? That's, that's a debate within part of the field I'm in. There's nothing, you know, deep and meaningful to anybody outside of that debate, but people within it are going to hold strong views. That's ok. So, I, I think there's inherently diversity in the sense of having different perspectives on the same phenomenon, in science that otherwise there's no interest in doing a study that everybody knows will come out the same way. And I have this discussion in my lab all the time that if a student says I often have an undergrad student who will propose a project. And it's like, you know, wouldn't it be interesting if this were true? It's like, oh, that's, that's great. But often they'll propose a study that's, like, ok, and I'll ask them, is there any reason anybody would disagree with your prediction? And if there's not, then maybe it's not as interesting to do it, it's more interesting to do those studies where if it comes out one way it supports one view if it comes out a different way, it supports the other view. And both of those are interesting. That's, that's the optimal kind of study.

<time>0:26:58</time> Ricardo Lopes: And the third habit you mentioned in the book is commitment. So couldn't tell us first what commitments are and perhaps the differences between assumptions and commitments because that's also something you explore in the book.

<time>0:27:14</time> Daniel Simons: Yeah. So a commitment is an assumption that's held so firmly that we no longer are willing to question it and we don't think about it at all anymore. It just becomes ingrained in how we act. So we all make assumptions all the time. We have to, you have to, we don't always have all the information. We have to assume a lot of things about the world and about how other people are acting with us. And so assumptions are, are normal. What we expect commitments are when they can sometimes become maladaptive. So, so often we want to have strong commitments to some things, right? We, we, we that's not necessarily a bad thing. Most of the time the problem comes when you are so firmly committed to something and it happens to be wrong that you don't question it. So I think my favorite example of this from, from the book was a discussion of a person who was a victim of Bernie Madoff's Ponzi scheme. So the investment Ponzi scheme fraud biggest Ponzi scheme in the modern era. And there were a number of people who were questioning what was going on with Madoff's scheme. They were suspicious that there was something fraudulent going on. And one of them told one of his customers that had a customer whose parents were heavily invested in NADO. And he's told this customer it's like, you know, you should tell your father this isn't good. He should be getting out of this. He shouldn't be trusting this and the father's response was, well, he just doesn't know Bernie. I know Bernie and Bernie would never screw us. That's a commitment. It's so firmly beheld that there's no way that Bernie Madoff could possibly be somebody who would treat us badly. And when you're committed to that belief, anything goes, you, you're not willing to take a step back and say, could this be a fraud because he'd never screw us? It's a, it's a firm commitment and we see commitments going leading people astray in a lot of sort of conspiracy thinking. And in politics where people are so firmly holding the belief that this person, this politician, this person I like is infallible. They can do no wrong. They only tell the truth that you have to go to incredible lengths to kind of make all of their inconsistent statements hold together because you've got that commitment that you can't back away from and it can lead you down this conspiratorial rabbit hole where you try and find all of these things to make everything work. It's like trying to find ways to make it so that all of the planets in the sun are orbiting the earth. Right? If you start with that assumption, you can find all sorts of weird convoluted ways to make it seem like it kind of works given the evidence at hand, even though it's wrong and for anybody on the outside who doesn't have that commitment, it seems crazy, But from the inside, it's logically coherent and that, that's where you run into these problems where people can't talk to each other because one has a commitment that's so firm that they've gone down an entire path of logic, very reasonable, entire path of logic starting from that commitment that they never questioned.

<time>0:30:21</time> Ricardo Lopes: But psychologically speaking, when it comes to this move from a simple assumption to a commitment, what is it based on exactly? Is it trust, confidence or some other thing?

<time>0:30:37</time> Daniel Simons: You know, that's a great question and I don't have a great answer for it. It's, the, the, I think the key challenge for making sure that you're not being deceived is thinking about what are the assumptions that you won't question. And sometimes those, you know, those are reasonable assumptions. You know, I have an assumption that people can't predict random events better than chance. And I think there's a lot of evidence to back that assumption, but it's an assumption. If I became firmly committed to it, even if somebody were to come along and prevent present unquestionable evidence at some level, I wouldn't accept it. And that's for a scientist that becomes a problem when you're so committed that you won't look at evidence that challenges your perspective. That's when it's moved into commitments rather than assumptions. And, but what, what leads people to go that route? That's, it's a great question. I wish I had a strong answer for it.

<time>0:31:34</time> Ricardo Lopes: That's fair enough. So let's get into the final habit before we talk about the four hooks you want to explore in the book. So, efficiency, what, what does that mean in this context? Exactly. Well,

<time>0:31:48</time> Daniel Simons: efficiency is just a tendency. We have to try and get things done in the fastest way and simplest way we can with the least effort, which the vast majority of the time is exactly what we want to do. You don't want to take the long way to work, you want to get there quickly. So, efficiency is, is usually a great thing and it just means that we sometimes don't ask questions when we should. So when people are looking to deceive us, they take advantage of the fact that we aren't likely to ask more questions. We're not likely to dig deeper and we take glib empty answers as good enough so that we can move on. And one way to think about this is it can be really uncomfortable and awkward to ask for more information. So imagine you're at a psychic performance and you stand up and say, well, you know, do you, do you actually know that this person had bone cancer? You know, or, well, you started with Rob and then you said Bobby, why did you start with Bobby? Those sorts of questions are awkward to ask and imagine you're getting a, a business pitch. Somebody's pitching your, you and they want to they want to be a consultant for you and they cite all of their, you know, success stories like, well, that's great. It's really uncomfortable to ask, what are all your failure stories? How many other companies have you, have you consulted for that? Didn't get these results? You know, asking those sorts of questions is exactly what we need to get more information. It's, it's, you know, it's recognizing when somebody is getting us to focus on the information they're presenting. And in that for the sake of efficiency, we often don't question even when we probably should. We take empty answers as, as good enough like, oh, well, it's been validated. What does that mean? We're using best practices whenever somebody says that it often means that they can't define what a best practice is. My favorite of these is somebody saying, well, we're being transparent whenever somebody says that they're not being transparent because being transparent means showing not say not telling, right? Showing what you've done. So if you're being transparent, like, well, how are you being transparent? What, what have you shown us? I've run into that all the time. Like university administrators bragging about how transparent they're being when they haven't actually given any information.

<time>0:34:15</time> Ricardo Lopes: Yeah. But don't you think, and if you disagree, please tell me, but don't you think that there are perhaps situations cases where when it comes to asking more questions, perhaps we are simply not sure about what are, what are the correct questions to ask because we are not familiar with that particular kind of subject or where someone might be trying to sell us, for example. And in that case, I mean, it's also a lack of information. And the fact that because we lack that information, we don't really know what questions we should ask.

<time>0:34:59</time> Daniel Simons: I think that's exactly right. That much of the time, we don't know what, what information we still need, we don't know what to ask. And of course, people are going to take advantage of that because people are going to be not confident about asking a question if they don't have some idea of what they want to get out of it. So that's how, that's how people will bluster past you and take advantage of your efficiency. It's efficient not to ask questions. It's also efficient to avoid kind of making yourself uncomfortable, right? Because that's just gonna take more effort and energy. But I think there are a lot of things you can do just to, to start asking questions that sometimes will reveal more even if you don't quite know what you want. So, one good thing is what else can you tell me or say more? And it's not a question but it gets, gets whoever you're talking to, to, to talk more and you know, that, that's like that standard sort of trope of detective movies where, you know, you've got the, got the person who you think is the criminal there and you just want them to talk more so they give them, give away information, same principle in cases that aren't that adversarial just say, OK, can you, can you tell me a little more or say more about that? And if you do that people will talk more and if they talk more, that might raise more specific questions you could ask. So that's, that's a good tactic to just start out. Another, another question you can ask, that's a little more directed that that we'll get more information is what could you tell me that might make me disagree with you, which is, a way of kind of, you know, eliciting this information that, you know, we really need. That, that's the sort of question that I recommend that journalists ask when they talk to scientists, like who might disagree with this position. And why would they disagree with you? And any scientists should be able to answer that and say, ok, well, here's why somebody might disagree with my position. Here's why I think they're wrong, but here's why they might disagree. And that gives you an end to what are the commitments that they have? What are their assumptions, who might have different sets of assumptions and who could you ask about them? So, the whole idea is to get people to give you information that they wouldn't spontaneously give you if they were trying to take advantage of your willingness not to ask questions and you're willing just to kind of get through things efficiently.

<time>0:37:22</time> Ricardo Lopes: Also because in this particular case, I would imagine that if you're not familiar with the whatever the other person is talking about or trying to sell you, for example, that's also a way of getting more information. And I mean, if at the end of the conversation, you still do not fully understand what they're trying to sell you, then perhaps it's just better to not

<time>0:37:47</time> Daniel Simons: buy. Yeah. And I think that's often the often the case, right? That more often than not the reason for asking questions is to get more information. Well, one way to get more information is to ask really focused questions. If you happen to know enough to ask those, the other is just to get the person to talk more because when somebody is trying to advertise to you. They want to show you just the information they have in front of them that they want to provide you. If they have to talk more, if they just start repeating themselves, then you know that they actually don't have anything to say. But if they can provide more information that you might have a better understanding. So, yeah, absolutely. That's, that's the whole idea is take a moment, even if it's just asking one or two more questions, when you're making an important decision can get you a lot more information and often one question will lead to others.

<time>0:38:34</time> Ricardo Lopes: And related still to efficiency. There's this concept of opportunity costs. I mean, what are opportunity costs and why is it that sellers usually do not want you to consider them?

<time>0:38:48</time> Daniel Simons: Yeah. So I mean, opportunity costs. The simple way to think about an opportunity cost is what else could you do with your time or money? And would you prefer that? So somebody is trying to sell you something means that they want to take your money for their product, which means you don't have that money available for anything else for any to invest or to buy something different. So they want to focus you on the benefits of their product and they don't want you to think about what else you could use that money for because then you might not buy the product. So a lot of the goal of advertising, of course, is to get you to buy things without thinking about opportunities that you might have if you use the money for something else. I, I think, yeah, I mean, I think that's the basic idea of, of opportunity costs. One thing to think about for opportunity costs is that, you know, thinking about all of those opportunity costs is inefficient. So if you have to think about all of the other things that you might do instead that slows you down, it means that you're not making quick decisions, you're having to, you, you're trying to decide which of several strategies you want to use for your business. That means, you know, thinking about what would happen if you didn't do any of those. It takes extra time, it takes extra effort. So anticipating opportunity costs and thinking about them is inefficient in the sense that we don't just plow ahead and get done and we have a strong drive to do that. So countering that when it matters is the key. You don't, you don't want to think about opportunity costs. Every time you go to the grocery store and decide to buy a box of cereal, you don't want to stop and think what else could I use this money for other than cereal? You know, if I, if I need breakfast food, I could think about other breakfast food. But what if I invested that money now? And you know how much value would it have to me later if I skipped breakfast, you don't want to go through that sort of thought process every time you do anything you want to think about when it matters and when it doesn't.

<time>0:40:47</time> Ricardo Lopes: And so we've gone through the four main psychological habits, I guess that make us vulnerable to deception getting now into the hooks that people use to deceive us. So in the book, you go through consistency, precision, potency and familiarity starting with consistency, what do you that is really about in this context?

<time>0:41:11</time> Daniel Simons: But let me step back and say what hooks hooks are. So we think of hooks as information in a form that we find really attractive. So people who are looking to deceive us are going to present information in a way that appeals to us that we find more likely to be true that we don't think as much about. So again, it's one of those tactics people use to get us to stick with our initial assessment that something is true and not to question it as much. And all of these hooks lead us to sort of jump right in without thinking. So the metaphor I like to use for this is a bull fight, a matador. And so the matador stand there perfectly still with their red cape and they're going to wave that cape around and the bull finds that irresistible and charges charges right in without realizing that, you know, there's a blade behind it. So that, that sort of running in without thinking about it, is what happens when we get information that we find particularly appealing and it's not always just blindly running in, it's just accepting something is true when we maybe shouldn't. So, the first of those that you mentioned is consistency, which is, and, and again, just like for the habits, the vast majority of time, these kinds of information are really good, they're really useful. Consistency is a perfect example of that. Usually, if something is consistently the case, that means it's reliable, that means it's predictable, that means we can count on it. And those are typically great things for most of what we do in the world, having something to be consistent is terrific. That's, that's what we want it to be. The problem comes in that we don't always recognize first when we shouldn't expect consistency. And don't look for when it should be varying. But second, when somebody is looking to deceive us, they use these hooks, they'll present these hooks without having the underlying truth behind it. So somebody will present information that seems really consistent because it's fabricated, not because it's actually genuine and, and reliable and robust. So in fabricated data, this is something that happens in science, you know, unfortunately, more often than we like, people will, people who have committed scientific fraud often will present results that are consistently great. They get the same result every single time and just as strong an effect, every single time when in reality, that's not how randomness works. And it's not how human behavior typically works. You don't always get the same thing every single time, especially in sort of a field where there's a lot of randomness inherent in it. Even in physics where you're measuring something really, really precisely. And you want to get the same results every time there's still randomness in the measurement and it's not going to be exactly the same to an infinite level of precision every single time you expect that noise. So if somebody gave you exactly the same thing to 20 decimal places, every single time, you'd worry about it. You should be worried about it because that doesn't account for how random things are. So somebody who's committing fraud will present that consistency because we like consistency. It appeals. If somebody can get the same results every time, it's like, wow, that must be true. And the reality is that yes, if they genuinely got the same result every time, that'd be great. And we use that as a great rule of thumb most of the time. But when somebody is committing fraud, they just don't have to do the data, don't have to do the actual studies. They can just make up consistent data. And that appeals to us and we don't think critically enough about it.

<time>0:44:50</time> Ricardo Lopes: So it's basically that idea if it's too perfect or too good to be true. So, I mean, if it, if it sounds like that then prep probably it's not true.

<time>0:45:02</time> Daniel Simons: Well, and that, that's the challenge, right? Because what sounds too good to be true to one person sounds just good enough to another. And so it becomes really difficult to use that rule of thumb consistently because you know, something AAA con artist or a scammer who is targeting you is going to make it sound just good enough. Whereas the person next door to you who hears that same pitch might say that's ridiculous. That's way too good to be true, right? So it, it has to be targeted appropriately. And I think targeting is what counts for whether you think it's too good or just good enough, but they're going to present information that is good enough that you will accept it as true and they use all of these hooks. But consistency is I think in science, one of the most common ones to give you data that just seems great. So I think one of the famous examples of this is Jan Hendrik Schon who's a, was a German in America in Bell Labs, but he, he studied superconductivity back in the early two thousands and was a physics superstar young guy at what was then Bell labs and he published, I think 16 papers in the journals, Nature and Science, the top two science wide journals, 16 papers in two years himself. And that's, that's like the output of an entire top notch physics department in in two years, it might be higher than that. So superstar publishing evidence of superconductivity with different materials. And it turns out that if you line up all the papers next to each other, he was reusing the same data and just changing the axes and changing the materials and changing the voltages in, in the figures. But the figures were the same they were likely just manufactured. It's not clear that there was ever any result. But that cost, you know, hundreds of labs, more than 100 labs had spent years trying to replicate his works and millions and millions of dollars trying to replicate his work. So it had consequence, but the, the hallmark of the the misconduct there was that the images were the same, the data were too consistent to be possible. And the thing I find most interesting about this sort of scientific misconduct and scientific fraud is it's out there in the open. It's literally in the publications, you can see that it's too consistent to be true, but it gets past peer reviewers and editors and other scientists for a variety of reasons. It seems really good, it seems consistent, you know, and people don't ask one more question, they process it efficiently, they read it quickly and say, oh, yeah, he found this again and that sounds like a positive when in reality it should be a red flag.

<time>0:47:47</time> Ricardo Lopes: Mhm. Yeah. And that's the thing, right. Even earlier when we talked about the scientists, that's another sort of evidence that we can look into, and make the case that scientists really are like, other people because in, if it goes past peer review and all of that, I mean, it's not at least not usually the case that people who are reviewing the studies are really incompetent. It's just that they are most of the time relying on these psychological habits.

<time>0:48:25</time> Daniel Simons: Yeah, I mean, and, and we can't dig into the details of every aspect of every paper and compare them to every other paper that somebody has written in real time. While we're also doing our own work, people have to be efficient. But I think this is a great example because it does illustrate that we all can be fooled by, by people trying to deceive us, especially if those people who are trying to deceive us are at all sophisticated about it. But the people who are being fooled in the sciences are generally pretty smart, definitely highly trained, they're trained to be critical thinkers, they're trained to evaluate evidence and they still can be fooled. We all can be if it's targeting it, right. And if you look at a lot of the scientific fraud that's out there more often than not. It's not earth shattering or groundbreaking work more often than not. It is kind of what we would predict in, in a field or at least kind of what a lot of people in that field would predict and expect. It's often a little bit more impressive in some way. So it's methodologically heroic. It took a huge amount of effort to do or it used a group of participants or subjects or, you know, a population or animals that are hard to access. So that makes it more impressive, right? It, it usually is slightly cleaner, slightly better than what other people have found. So the result is that it kind of fits right in with other sorts of studies that have been published, but improves on them a little bit. So it makes that person seem like they're just that much better than the other people around them but not doing something so extraordinary that people immediately doubt it. So a contrast example for this is in, you know, some years ago, a famous paper published in the top journal in social psychology claimed to find evidence that people could predict random events better than chance, right? So essentially a form of psychic ability and the immediate reaction to that was no, that's not right. It can't be right. So the question then is what's wrong with it. But that was because it didn't fit into what people already believed and it wasn't fraudulent. I think he just, it was somebody fooling themselves, you know, with their analysis and there were lots of issues with how they did their analysis. But, it wasn't fraud and that would have been a dumb study to make up right, as a fraud because people would immediately discount it and start digging into it and looking into the problems with it. So the things that kind of survive as frauds for a while before they get caught are typically not outlandish claims. They are typically landish just, you know, slightly slightly, you know, slightly impressive. They, they land in the right spot.

<time>0:51:08</time> Ricardo Lopes: They are physically credible enough,

<time>0:51:12</time> Daniel Simons: credible enough, right? They, they, they're still impressive, but they're credible enough and credible enough within the realm of other things that have been published in that area. And that, that's kind of the typical finding. So I think a great example of science working correctly and not necessarily involving fraud is, you know, claims of room temperature fusion which have come and gone repeatedly over the years in physics. There have been cases of fraud in, in that world, but more often than not, it's just somebody who's, there was something odd about the materials they're working with and they didn't figure out what it was and it sounded good. So they went with the claim that it was, you know, called fusion and then physicists immediately dug into it because that's a big claim. Right? And big claims require very strong evidence and people will dig into them more. That's, you know, that's part of why those sorts of claims garner so much attention is that they are out there, they are a little too far and that's if, and they're one of those, if true, that would be amazing sorts of findings. And anytime you hear, like, if that's true, that would be amazing. You should be skeptical about it because, you know, amazing breakthroughs are pretty rare.

<time>0:52:26</time> Ricardo Lopes: Right? So, getting into the second hook, familiarity, I think that we've already mentioned this briefly earlier in our conversation. But what does familiarity indicate to us?

<time>0:52:40</time> Daniel Simons: Exactly. So, usually familiarity is a great cue to something being trustworthy. So, imagine, you know, your friends, your family, people, you know, personally, if you've been around them for a long time, you know, whether or not you can trust them and you know, how much to trust what they say and how much to discount it. Right. We all have that relative. We don't trust what they say. But for the most part, if you're around people a lot that familiarity makes it reasonable to continue to trust, to accept the truth of what they're saying without questioning it as much, it makes the truth bias reasonable. And that's, that's a great cue for, for us most of the time. It becomes a problem in terms of deception because we mistake superficial familiarity with genuine familiarity. So we see a celebrity a lot, we hear a lot of interviews with them. We kind of feel like we know them and because we kind of feel like we know them, we tend not to be as critical when they say something, you know, as we should. Romance scams, which are a major source of scams, financial scams and other sorts of scams right now, often targeting older folks who are, are lonely, divorcees or widowers or widows. And they, the way they work, it's almost entirely online and they establish over time familiarity. They feel you feel like you're getting to know this person who you're interacting with a lot online, but you've never actually met them in person and they probably look nothing like what they tell you they do. And that's those scams are really effective because we confuse the sort of familiarity we sort of evolved with interacting with people directly having close associates that we know really well. And can distinguish from people we don't know very well. We confuse that with, you know, friends on Facebook who you might never have met in person or you encounter only on social media and people can present a persona very easily. So somebody looking to deceive you is going to take advantage of that present themselves like they like a friend would and take advantage of that experience of familiarity.

<time>0:54:57</time> Ricardo Lopes: And what about precision? So what does it mean to be precise here? And but basically, how do, how can we distinguish reliable information from detailed concrete information? That is just BS,

<time>0:55:18</time> Daniel Simons: that's the real challenge, right? And that's why these hooks can fool us so easily. So usually if somebody can give you a precise answer and it's grounded, it's based on real evidence. That's great. That's really impressive. So that physicist who can measure some constant to six decimal places, that's great. They can do it reliably, they can give you the exact number more or less. And that precision means that they have great understanding. A weather forecaster who can say that it's going rain will cover 25% of this region between two and four tomorrow. That's a great prediction that's precise. And to the extent that they are calibrated and do it well, that means they have a good understanding of the weather pattern for that day. Much better. It's much more informative than saying it might or might not rain sometime in the next three days. But that doesn't, that doesn't have any value to us. So we value precision because precision usually is a sign of great understanding. The problem of course, is anybody looking to deceive us can just fake precision. They'll give us numbers and those numbers don't necessarily have any meaning to them. That's where we run into problems that it's very easy to give a precise number and make it seem like it's something genuine when there's no actual evidence backing it.

<time>0:56:41</time> Ricardo Lopes: Mhm. And when, when, when it comes to potency, there is the last hook. What is it really about?

<time>0:56:50</time> Daniel Simons: So, potency is, are you almost like, you know, the desire for big fixes, quick fixes that one, you know, this one simple trick will fix your problem. And there's a reason why that Clickbait works well on, on social media. We all want the sort of quick fix the easy solution, the, you know, become a master at something in just a few hours. That sort of ability to radically change things with the minimal effort. So big effects from small, small effort, a small intervention, there are rare cases where that holds true where a tiny little thing can have a gigantic effect. The discovery of antibiotics, vaccines, huge consequences from a tiny little thing, right? That's those are, you know, those are rare and few and far between. But we have this tendency to kind of assume that things should be easier than they are that we can stave off the effects of cognitive aging by playing a brain game for 10 hours like nope, not gonna work. But that, that potency, that desire for potent effects genuinely is a good thing when it's true. It's just that we see it far more often than we think we do. And people who are looking to deceive us always take advantage of that one, right, that they can, who are trying to sell us some sort of fake product will always claim giant benefits from something that really doesn't have giant benefits. As a general rule, big consequences require big interventions. You, you don't get, you don't get a big outcome from a small thing.

<time>0:58:34</time> Ricardo Lopes: A and again and again, I imagine that here, as we said, it has nothing to do or very little to do with cognitive ability, but with lack of information. Because if, for example, you are a scientist of a particular area and you are advertised something that promises to get huge benefits from very small investment or from a very small thing. And you are sort of familiar with what they're talking about. They would, you would say immediately, oh this is just BS come on. It's much more complicated than that. But people who just lack that sort of knowledge are much more vulnerable to that kind of advertisement, for example.

<time>0:59:23</time> Daniel Simons: And even even scientists fall for this sort of stuff all the time, right? There is, there is an entire field of what sometimes is called social priming where you, you kind of flash some words briefly or have people these scramble sentences. And the claim was doing that sort of trivial task would have these big effects on behavior, right? That would actually change what you do. And it was sort of a cottage industry and social psychology to generate these effects that were more and more kind of outlandish, like, you know, scrambling and unscrambling sentences related to being old makes you walk more slowly. It just doesn't none of those hold up. But there are tons and tons of papers in the literature on this big interventions designed to remedy really complex social problems. Things like there, there are a whole series of studies recently that are called sometimes called wise interventions and they're called wise interventions. The idea is that they don't require much effort and they are highly efficient and lead to these big outcomes. So their claims that like doing a one hour affirmation in a school at the beginning of school, reduces disparities in suspensions for black and white kids or increases academic achievement two years later, like, you know, these are really complex multiply determined problems in society, right? The suspension gap has there's so many factors that contribute to that suspension gap and it's not just something that's going to go away with a one hour, you know, thinking about yourself intervention. But these things are pervasive in the schools, growth mindset interventions, you probably have heard of growth mindset. Yeah. So there are claims that, you know, one hour affirmation, you know, one hour growth mindset, intervention is going to change your academic performance sometime later. Like no, you know, that you, you'd be hard pressed to find a school district in the United States, at least that doesn't apply growth mindset in some way. And it's a big industry now. If you look, there's a recent meta analysis of all of these interventions and most of them had severe method problems, most of them didn't actually even measure whether the intervention changed people's mindsets. And if you look at the handful of them that did it, well, there's basically no effect of these interventions on academic performance or outcomes. So it's one of these things where it's, you know, a tiny little intervention to address something that's a big societal complex problem. And people find those really appealing and aren't sufficiently critical of them when they, when they are made because as scientists, we should be always skeptical of big effects from small interventions, but they appeal a lot when they're true. And if it were true, it would be amazing, right? If, if it were true that you could just spend an hour and fix a major problem, that would be great. Just we tend to find it more appealing than we should.

<time>1:02:25</time> Ricardo Lopes: Yeah. And I mean, I guess that generally speaking, if we're talking about the multifactorial issue, if someone claims that just targeting one single factor will solve it, it's probably not going to happen.

<time>1:02:40</time> Daniel Simons: Yeah. And there's there's a sort of, you know, desire to find the single, the single solution, the single cause, fixing one thing to fix all the things. And, you know, often that's not a terrible approach to, to look for, to try and find that single cause. This is a common practice in medicine, right? If you have somebody who's got a bunch of symptoms, you want to look to see is there one thing that's causing all the symptoms? And often there is, and that's, that's the simplest possible explanation for what's going on. In these cases, it's more commonly, there's one issue that we want to address. There's basically one symptom, say racial disparities in suspensions or, and we have that one issue but it's caused by many, many things and those are cases where fixing one of those many, many things isn't going to likely have a complete effect on the outcome. It's, it works great when you've got one cause for many symptoms. It doesn't work so great when there's many causes for one symptom.

<time>1:03:46</time> Ricardo Lopes: Right. So, I have two or three more questions before we wrap up the interview about the hooks. Is it that the best deceivers out there resort always to all four Hooks or can they just resort to one or two of them or does it work? Exactly.

<time>1:04:05</time> Daniel Simons: I, I think it, it varies a lot. Based on what's necessary to pull somebody in and what the, what the scope of a deception is for something that's just sort of AAA, very limited, you know, limited sort of fooling somebody just, you know, quick encounter where they're just trying to pass off some product they might not use more than one or two of these. Something that's a long running scam, likely has to adopt a lot more of them. So take, Bernie Madoff's Ponzi scheme, I think that's a good example of one, you know, ran for 15 plus years where he didn't process a single transaction, they were all faked for for that longer duration. And so he, you know, he, he used focus to some extent because he's going to give you the information, you want your returns but not tell you all of the details about how he managed to do that. You know the missing information. He's counting on you not asking how is it that you managed to get identical returns month to month, year to year because nobody else can. So most people don't ask that most people don't ask for more information than he provides. And he, he he set people up to expect the same returns every year. They would get their 8 to 14% every year, not having any down years. And as long as they kept getting what they expected, people didn't complain, they didn't question it. If they had a big down year, he would have, they would have questioned it, but he gave them what they expected. He counted on commitments as we already discussed that people trusted him and they didn't think he would be ever the sort of person who would screw them over. He was also familiar to many of the people who invested with him. He specifically targeted members of his social community in New York, e especially he selected the people who could invest with him. He didn't just let anybody invest with him, he would turn people away. So he selected the people who he was, he was in, who are investing with him. He used precision. So he would give people this huge print out of every of records of trades that were all fabricated in their, you know, in their reports, it wasn't online like it would be for most major investors. It was just all of these trade transaction forms. So lots of detail there that just didn't have anything backing it. It was, it was a perfect example of, you know, giving precise information without any substance to it. Potency, maybe he didn't use a whole lot because we think of potency as the classic Ponzi scheme where invest now and you're guaranteed 50% returns in six months. He never did that. In fact, he kind of performed about the same as the S and P 500 the major stock index over the course of his Ponzi scheme. His investment wasn't that outstanding? It was just stable. It was, you never had a down year with Bernie. So he used consistency a lot more than he used potency. But yeah, I mean, he, he used a lot of these techniques and how he went about it,

<time>1:07:05</time> Ricardo Lopes: which in a way perhaps made it even more grabbable.

<time>1:07:09</time> Daniel Simons: Yeah. Well, in order to keep it, keep it going that long, he would have to tap into a lot of the sort of ways of thinking that keep people from questioning the truth of what he's saying. So, yeah, that's, that's, that's right. The longer something goes, the more complex it is, the more they're going to have to rely on deceiving you in different ways.

<time>1:07:29</time> Ricardo Lopes: And another question I have here is so we've already mentioned several times how this has very little or nothing to do with people's cognitive ability or any other kind of psychological threats. But isn't it the case that many times scammers or receivers target specific vulnerable people? Of course, to do that, they have to have specific kinds of information about specific people. I mean, some, sometimes they target just the elderly in general, sometimes they might target very specific niches of people. Like for example, if it's a romantic scam, they might target people that they know are single and do not like to be single or something like that. But I, I mean, it's also the case that the, some of the most successful scammers are also the ones that know who to target.

<time>1:08:28</time> Daniel Simons: So there are two different approaches, right? And there undoubtedly are some people who are more gullible than others. There are going to be individual differences there. I don't think that's the defining factor in whether or not somebody can be scammed. So I think the danger is in assuming that because you're a smart critical thinker that you can't be, can't be deceived. That's undoubtedly wrong. The, the idea that some people are more likely to be seed than others is certainly true and some people are more easy to target than others. But there are two different approaches that scammers can take. One is to specifically learn a lot about a person and meet them where they are. So, yeah, if you're a romance scammer, you're not going to target somebody who's happily married. That's just not going to be an effective target. If you are using the calling card scam, which is a standard tactic or the call center scam where people will call up people targeting them for a particular fear. So often in the scams are often based out of other countries. And then we'll call in to say the United States and we will target people who are here on a limited visa status or, or here illegally and we threaten them with deportation or with arrest unless they pay up right away. That scam is not going to work on me. It's no work on somebody who is an immigrant. And there are variants of it that will work. There are variants of that, that work on professors, right? There's a, there's a variant of this right now, which is really clever. So if you are a professor who gives invited talks at conferences, on occasion, quite often the conference organizers will arrange your hotel and some of your travel for you. So there's a con right now that's working pretty effectively where the con artist will look at the conferences, figure out who's invited to speak. And we call those people and pretend to be the conference organizers to arrange their travel and they'll arrange their hotel and flight information, which means they get all of their personal information and their credit card and they have nothing to do with the conference. They just looked up the information and targeted. So again, professors can fall for this and have. So that's one approach is the specific targeting. The other approach is to allow the victims to select themselves. So I don't know if you have this particular scam in, in Portugal, but where you get an automated call asking you about extending your cars warranty. Do you guys have that one? I

<time>1:11:06</time> Ricardo Lopes: got that not about a car warranty about other things, but yeah, I, I got, I got that kind

<time>1:11:14</time> Daniel Simons: of thing. So these are these robocalls. It's like most people like, yeah, those are scam. But the people who call it back have just identified themselves as somebody who is a target. It's somebody who is concerned about their car's warranty. So they, they self identified. So the scammers there don't have to waste any time selecting people. All they have to do is just blast it out to as many people as possible. And then some people will respond same thing with the original Nigerian prints email scam, which has been going on for decades now. It, it was, it existed before email. As, as letters. But the idea of that scam is they can send out now millions of those emails, most of which look ridiculous, right? Most people are not going to fall for that. There's bad grammar. It's weird, you know, I still get these in my inbox, mostly caught by the spam filters now. But but if you think about it, they're not trying to reach you or me. They're trying to reach those very small number of people who have not heard of this scam and who will respond to that email. So they want to make it as obvious as possible so that they don't have to waste any time with people who aren't going to eventually pay up. They want only the most gullible, they want the person who calls back about their car's warranty. So anybody who responds to that email is a likely target and it's cost efficient for them because they don't have to waste time with all of the people who are more skeptical of that particular email. So, yeah, they scams are targeted in, in different sorts of ways either by selecting and really getting to know the people you're, they're trying to victimize or by allowing people to select themselves.

<time>1:12:58</time> Ricardo Lopes: So, my last question, then I guess that we can say here that there's no foolproof way of being able to always identify the scammers and the deceivers. But I guess that the point of your book here is for people to be more aware of the fact that we have this sort of psychological habits, this truth bias and to perhaps in specific situations, be more aware and wary of certain things that people say and, and perhaps ask more questions in specific situations as well and stuff like that. Because most of the time our proof bias still works. Most

<time>1:13:48</time> Daniel Simons: of the time, all of these things still work. Most of the time, none of us are very few of us are going to be victims of a grand con, right? Most of us are not going to succumb to that. We'll, we'll all be fooled by misinformation at times. We'll all be fooled by deception and every now and then we'll get taken for some money by somebody who's trying to rip us off. But most of us are not going to be a victim of a grand scam of the Madoff variety. Fortunately, but I think, I think your first point is exactly right that, you know, you'd like to think. Oh, is there a quick, quick fix an easy solution to not ever being scammed? And that would, that would be tapping into the hook of potency if I promised you that if I, if I said here's all you have to do to avoid ever being scammed, there is no such thing and we should know that after reading about the potency that there's no one quick fix for a really complex multifaceted problem. But I do think there's an advantage in learning about these hooks. It's a lifelong process to think about when you need to be skeptical and when you shouldn't. But all of these hooks and habits are things that underlie almost all forms of deception so far known and likely to exist in the future. And as you start kind of recognizing the patterns, you might start recognizing when they're at play in times when you're at risk. So, one of the strategies that I think is probably helpful is next time you're listening to a story about a con or reading an article about somebody who is taken in, think about how this con artist applied these hooks and habits. Think about from the victim's perspective, which red flags did they miss because they were too focused or because they didn't ask another question when you start examining the scans and scams in that way, kind of as we did over the course of doing our research for the book, you start to see the patterns and you start to recognizing, start to recognize when something is maybe a little too good to be true. So I think it's, I think that's the best approach in general is to try and understand it from the perspective of the, of the victim in that moment and how they were targeted and how they how the con artist applied these tricks, took advantage of them.

<time>1:16:07</time> Ricardo Lopes: Great. So the book is again, nobody is full. Why we get taken in and what we can do about it. I'm leaving a link to it in the description box down below. And Doctor Simons, apart from the book, would you like also to tell people where they can find you and your work on the internet?

<time>1:16:24</time> Daniel Simons: Sure. Yeah, just Dan simons.com. It's the easiest place to get all the information.

<time>1:16:29</time> Ricardo Lopes: Great. So I'm adding that to the description and thank you so much again for taking the time to come on the show. It's been really fun to talk to you.

<time>1:16:37</time> Daniel Simons: My pleasure. Thank you for inviting me.

<time>1:16:39</time> Ricardo Lopes: Hi guys. Thank you for watching this interview. Until the end. If you liked it, please share it, leave a like and hit the subscription button. The show is brought to you by the N Lights learning and development. Then differently check the website at N lights.com and also please consider supporting the show on Patreon or paypal. I would also like to give a huge thank you to my main patrons and paypal supporters, Perera Larson, Jerry Muller and Frederick Suno Bernard Seche O of Alex Adam Castle Matthew Whitten Bear, no wolf, Tim Ho Erica LJ Connors, Philip Forrest Connelly. Then the Met Robert Wine in NAI Z Mark Nevs calling in Holbrook Field, Governor Mikel Stormer Samuel Andre Francis for Agns Ferus and H her meal and Lain Jung Y and the Samuel K Hes Mark Smith J Tom Hummel S friends, David Sloan Wilson Yaar, Roman Roach Diego, Jan Punter Romani Charlotte, Bli Nico Barba Adam hunt Pavlo Stassi Nale medicine, Gary G Alman, Sam of Zed YPJ Barboza Julian Price Edward Hall, Eden Broner. Douglas Fry Franca, Beto Lati Gilon Cortez Solis Scott Zachary FTD and W Daniel Friedman, William Buckner, Paul Giorgio, Luke Loki, Georgio Theophano Chris Williams and Peter Wo David Williams, the Ausa Anton Erickson Charles Murray, Alex Shaw, Marie Martinez, Coralie Chevalier, Bangalore Larry Dey junior, Old Eon Starry Michael Bailey then Spur by Robert Grassy Zorn, Jeff mcmahon, Jake Zul Barnabas Radick Mark Temple, Thomas Dvor Luke Neeson, Chris Tory Kimberley Johnson, Benjamin Gilbert Jessica. No week in the B brand Nicholas Carlson Ismael Bensley Man George Katis, Valentine Steinman Perros, Kate Von Goler, Alexander Albert Liam Dan Biar. Masoud Ali Mohammadi Perpendicular J Ner Urla. Good enough, Gregory Hastings David Pins of Sean Nelson, Mike Levin and Jos Net. A special thanks to my producers is our web Jim Frank Luca, Toni, Tom Ween, Bernard N Cortes Dixon, Benedikt Muller Thomas Trumble, Catherine and Patrick Tobin, John Carlman, Negro, Nick Ortiz and Nick Golden. And to my executive producers, Matthew lavender, Si Adrian Bogdan Knits and Rosie. Thank you for all.

</div>

[Back to top](#top)
