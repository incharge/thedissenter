WEBVTT

1
00:00:00.750 --> 00:00:03.470
Hello, everybody. Welcome to a new episode of

2
00:00:03.480 --> 00:00:06.509
the Decent. I'm your host as always Ricardo Loops

3
00:00:06.519 --> 00:00:08.739
. And today I'm joined by Doctor Stephanie. Her

4
00:00:09.239 --> 00:00:12.359
, she is a researcher, broadcaster and author focused

5
00:00:12.368 --> 00:00:15.750
on technology, politics and history. And today we're

6
00:00:15.759 --> 00:00:19.260
going to talk about her book Technology is Not Neutral

7
00:00:19.269 --> 00:00:22.940
, a short guide to technology ethics. So doctor

8
00:00:22.949 --> 00:00:25.120
her, welcome to the show. It's a pleasure

9
00:00:25.129 --> 00:00:27.638
to everyone. Thank you so much for having me

10
00:00:27.649 --> 00:00:33.590
or Gala. Great. So um uh tech uh

11
00:00:33.618 --> 00:00:39.168
technology ethics, I guess that uh people who think

12
00:00:39.179 --> 00:00:42.679
about is who look at these would think that OK

13
00:00:42.689 --> 00:00:46.598
, it's just another uh philosophy thing. Why should

14
00:00:46.609 --> 00:00:49.728
we care about that? It's just some about some

15
00:00:49.740 --> 00:00:52.719
abstract questions. But I mean, what is it

16
00:00:52.728 --> 00:00:57.380
really about? And what kinds of uh more practical

17
00:00:57.389 --> 00:00:59.520
questions, let's say, does it deal with?

18
00:01:00.009 --> 00:01:02.298
I love, I love your idea of like one

19
00:01:02.310 --> 00:01:04.510
more philosophy is if we're being bombarded by philosophies and

20
00:01:04.519 --> 00:01:07.219
all the time, and there's just philosophers walking around

21
00:01:07.359 --> 00:01:11.760
selling their wares in the street, which I guess

22
00:01:11.769 --> 00:01:12.638
is maybe true, we would just call them marketing

23
00:01:12.650 --> 00:01:17.588
people now. Uh No. So I think,

24
00:01:17.599 --> 00:01:22.239
look, I think technology and the way that humans

25
00:01:22.879 --> 00:01:27.209
have a relationship with technology has existed probably since we

26
00:01:27.219 --> 00:01:30.269
, you know, developed depos, thumbs and started

27
00:01:30.278 --> 00:01:33.150
making tools. Um, you know, so we

28
00:01:33.159 --> 00:01:36.739
would have picked up bones or stones or twigs and

29
00:01:36.750 --> 00:01:40.838
started fashioning them creating fire. And probably from that

30
00:01:40.849 --> 00:01:42.558
moment you started having human beings disagreeing about, you

31
00:01:42.569 --> 00:01:45.319
know, when is it acceptable to make a fire

32
00:01:45.329 --> 00:01:47.180
? What are the rules around fire? Is fire

33
00:01:47.189 --> 00:01:49.189
for cooking and keeping us warm and keeping predators away

34
00:01:49.198 --> 00:01:52.430
or is it ok to like torch our enemy camps

35
00:01:52.439 --> 00:01:53.680
village? Um, or use it, you know

36
00:01:53.689 --> 00:01:56.849
, launch it into an arrow and shoot it at

37
00:01:56.859 --> 00:01:59.959
people. So I just feel like in some ways

38
00:01:59.969 --> 00:02:01.659
it's like nothing new under the sun, as Shakespeare

39
00:02:01.668 --> 00:02:04.569
said, it's, it's always been there. So

40
00:02:04.579 --> 00:02:07.019
I don't feel like this is like a new idea

41
00:02:07.409 --> 00:02:10.778
, um that people are hawking. I think it's

42
00:02:10.788 --> 00:02:14.469
, it's one of the oldest things because it's so

43
00:02:14.479 --> 00:02:17.460
fundamental to us. Beings have been making technology,

44
00:02:17.469 --> 00:02:19.909
you know, for a really long time. And

45
00:02:19.919 --> 00:02:22.508
we've also been philosophizing for a really long time because

46
00:02:22.520 --> 00:02:23.758
if we think about philosophy, kind of the way

47
00:02:23.770 --> 00:02:28.469
it's taught today, it's very abstract. We think

48
00:02:28.479 --> 00:02:30.020
about it in universities, uh you know, philosophy

49
00:02:30.028 --> 00:02:32.338
departments writing about topics that most of us probably are

50
00:02:32.349 --> 00:02:35.308
never going to read a book about, uh or

51
00:02:35.319 --> 00:02:38.270
an article or really care, which is a shame

52
00:02:38.278 --> 00:02:40.838
because we're actually doing philosophy all the time. We're

53
00:02:40.849 --> 00:02:44.758
doing it every day. So if you're interested in

54
00:02:44.939 --> 00:02:47.800
, in power and in politics that welcome to philosophy

55
00:02:47.808 --> 00:02:51.409
, you're doing political philosophy. If you're interested in

56
00:02:51.419 --> 00:02:53.838
like good and bad, right and wrong, um

57
00:02:53.849 --> 00:02:54.879
where do we draw the line on certain things?

58
00:02:54.889 --> 00:02:58.110
Welcome to philosophy. You're doing ethics. If you

59
00:02:58.118 --> 00:03:01.469
have really strong views on aesthetics, which could be

60
00:03:01.479 --> 00:03:06.588
anything from, you know, design in your house

61
00:03:06.599 --> 00:03:09.028
to like the sustainability or labor relations that go into

62
00:03:09.038 --> 00:03:13.069
the materials that you buy, any product that you

63
00:03:13.080 --> 00:03:15.449
buy or service that you buy or even things like

64
00:03:15.460 --> 00:03:17.469
user design and user experience. Welcome to philosophy,

65
00:03:17.479 --> 00:03:20.558
you are doing aesthetics, right, and so on

66
00:03:20.569 --> 00:03:22.750
and so forth. So we're doing it all the

67
00:03:22.758 --> 00:03:24.868
time, but I think we weren't certainly in the

68
00:03:25.288 --> 00:03:29.270
Anglo Saxon world, we're not really taught it in

69
00:03:29.278 --> 00:03:30.909
the way that often you are in the continent much

70
00:03:30.919 --> 00:03:34.558
more explicitly. So I think that was like the

71
00:03:34.569 --> 00:03:37.229
first bridge I wanted to build with people that I

72
00:03:37.240 --> 00:03:38.569
work with both in my client work. But also

73
00:03:38.580 --> 00:03:42.800
in my writing was to kind of get everybody confident

74
00:03:42.808 --> 00:03:44.599
with the fact that actually you've already been doing this

75
00:03:44.610 --> 00:03:46.778
your whole life. So now that we give you

76
00:03:46.788 --> 00:03:49.689
the terms, you have like a name for what

77
00:03:49.699 --> 00:03:51.960
you're doing. And I can take you through examples

78
00:03:51.969 --> 00:03:53.169
of how you've been doing it, that's a bit

79
00:03:53.179 --> 00:03:55.679
empowering and confidence building. So now you can start

80
00:03:55.689 --> 00:03:59.939
doing it deliberately because that is uh that is a

81
00:03:59.949 --> 00:04:03.979
shift. I think there's something really cool about how

82
00:04:03.990 --> 00:04:08.919
philosophy exists as a tool set. It's very practical

83
00:04:08.929 --> 00:04:12.118
. It's very pragmatic. So if you're facing,

84
00:04:13.219 --> 00:04:14.868
oh, I don't know, a problem or an

85
00:04:14.879 --> 00:04:16.769
opportunity you're trying to evaluate to do something or not

86
00:04:16.778 --> 00:04:19.928
to do something or just what you think about something

87
00:04:19.939 --> 00:04:21.509
. Like, what's your point of view on it

88
00:04:21.869 --> 00:04:26.709
? Sometimes, particularly today, life is very complicated

89
00:04:27.048 --> 00:04:29.149
. It can be nice to have a tool set

90
00:04:29.160 --> 00:04:30.350
that helps you to think through things so that you

91
00:04:30.358 --> 00:04:33.439
can do it with a bit of rigor and then

92
00:04:33.449 --> 00:04:35.170
you can talk about it. It gives you like

93
00:04:35.178 --> 00:04:40.720
a shared menu if you will a shared script for

94
00:04:40.730 --> 00:04:43.358
talking about it with other people. And it's really

95
00:04:43.369 --> 00:04:46.100
nice if you're a problem solver by a profession,

96
00:04:46.699 --> 00:04:48.790
which doesn't necessarily mean you have to be a technologist

97
00:04:48.798 --> 00:04:50.540
or an engineer. You might be a problem solver

98
00:04:50.548 --> 00:04:55.709
as a lawyer, as a regulator. Um You

99
00:04:55.720 --> 00:04:57.399
might be, or even as like a CEO and

100
00:04:57.410 --> 00:04:58.600
you're having to figure out, you know, do

101
00:04:58.608 --> 00:05:00.079
we go this way or that way? What,

102
00:05:00.088 --> 00:05:01.119
what problem I'm trying to solve here. It can

103
00:05:01.129 --> 00:05:03.838
be really nice because it's like a due diligence exercise

104
00:05:03.850 --> 00:05:05.699
that allows you, you can go through it and

105
00:05:05.709 --> 00:05:06.920
when you're done, you're like, OK, I've

106
00:05:06.928 --> 00:05:09.519
done this, I've done this, I've done this

107
00:05:09.528 --> 00:05:12.798
, I've done this and that's really helpful. So

108
00:05:12.809 --> 00:05:14.829
I think that's the thing that I find really exciting

109
00:05:14.838 --> 00:05:17.639
about technology ethics is it's really practical. Like when

110
00:05:17.649 --> 00:05:19.579
I go in and teach this to people afterwards,

111
00:05:19.588 --> 00:05:21.798
they're like, we're doing our, the way our

112
00:05:21.809 --> 00:05:24.879
team functions is different now or the way that we

113
00:05:24.889 --> 00:05:29.379
tackle opportunity and risk assessment is different now and by

114
00:05:29.389 --> 00:05:31.100
different, I'm hoping they mean better. Right.

115
00:05:31.108 --> 00:05:34.259
So it doesn't have to necessarily be right now.

116
00:05:34.269 --> 00:05:36.920
A I Ethics is very buzzy and has been for

117
00:05:36.928 --> 00:05:39.879
a couple of years. But like, I don't

118
00:05:39.889 --> 00:05:43.588
limit my analysis to A II I go as broad

119
00:05:43.600 --> 00:05:46.540
as you can in terms of all technology because A

120
00:05:46.548 --> 00:05:48.048
I is just, it's an exciting technology and it

121
00:05:48.059 --> 00:05:50.769
is definitely the technology of the day in terms of

122
00:05:50.778 --> 00:05:55.639
the media and marketing cycle. But there's so much

123
00:05:55.649 --> 00:05:58.750
more, there's so much more we can do with

124
00:05:58.759 --> 00:06:01.389
philosophy in terms of the human tech relationship. So

125
00:06:01.399 --> 00:06:03.850
I think it's really fun. I wouldn't, I

126
00:06:03.858 --> 00:06:05.399
wouldn't have spent my time on it if I found

127
00:06:05.410 --> 00:06:10.350
it boring or not useful. Um On the contrary

128
00:06:10.459 --> 00:06:12.449
, once I started really working with this, I

129
00:06:12.459 --> 00:06:16.528
was like, this is powerful and it's helpful and

130
00:06:16.540 --> 00:06:19.230
that is great because if you are trying to tackle

131
00:06:19.238 --> 00:06:21.809
particularly complicated problems, you need every tool that you

132
00:06:21.819 --> 00:06:26.509
have. Uh And I mean, the main question

133
00:06:26.519 --> 00:06:30.309
you tackle in the book is, is technology neutral

134
00:06:30.319 --> 00:06:31.899
. And uh of course, just by looking at

135
00:06:31.910 --> 00:06:34.939
the title, your position is obvious, but e

136
00:06:34.949 --> 00:06:40.189
even before we get into your position and go through

137
00:06:40.199 --> 00:06:45.105
some examples that really are illustrative of the fact that

138
00:06:45.113 --> 00:06:48.024
technology might not be neutral. Give us perhaps some

139
00:06:48.035 --> 00:06:53.264
examples of arguments from the other side. People who

140
00:06:53.274 --> 00:06:57.415
argue that technology is indeed neutral, that you find

141
00:06:57.423 --> 00:07:00.178
perhaps the most compelling. Yeah. So I actually

142
00:07:00.189 --> 00:07:02.660
used to think technology was neutral. It was,

143
00:07:02.670 --> 00:07:04.790
it was in the writing of the book that I

144
00:07:04.798 --> 00:07:08.379
had to change my mind and I'll give a few

145
00:07:08.389 --> 00:07:10.689
examples of why I used to think this. Um

146
00:07:10.699 --> 00:07:14.028
First of all, I came from a business perspective

147
00:07:14.069 --> 00:07:16.619
where and I should declare my nationality interest. So

148
00:07:16.629 --> 00:07:19.178
I'm American by birth. And then I've had my

149
00:07:19.189 --> 00:07:20.970
career in the United Kingdom. So this is very

150
00:07:20.980 --> 00:07:26.750
much an Anglo Saxon uh free market capitalism, hardcore

151
00:07:26.759 --> 00:07:29.838
perspective because I appreciate that's not the case everywhere.

152
00:07:30.069 --> 00:07:32.928
Uh For your global audience of this interview, that

153
00:07:32.939 --> 00:07:38.869
perspective uh is very anti regulation. Regulation is always

154
00:07:38.879 --> 00:07:41.778
being portrayed as like hindering innovation. It's going to

155
00:07:41.790 --> 00:07:46.088
stop innovation and innovation is really key particularly in the

156
00:07:46.100 --> 00:07:48.329
US, you know, to American superpower, competitiveness

157
00:07:48.338 --> 00:07:53.209
. So anything that would hinder that instantly becomes political

158
00:07:53.278 --> 00:07:55.238
, it doesn't matter if you're a Republican or Democrat

159
00:07:55.250 --> 00:07:57.048
, everybody's like, oh, nobody wants to,

160
00:07:57.100 --> 00:08:01.459
everything that hinders that is the bloody communists. Exactly

161
00:08:01.470 --> 00:08:03.139
. Like take your pick. Are we scared of

162
00:08:03.149 --> 00:08:05.290
like the former Soviet Union in the eighties? It

163
00:08:05.298 --> 00:08:07.250
was Japan now. It's China, right? So

164
00:08:07.259 --> 00:08:13.449
like nobody wants to hinder innovation with pesky regulation.

165
00:08:13.869 --> 00:08:16.619
Uh so you have, you have that, that

166
00:08:16.629 --> 00:08:18.959
right there shows you like, it's not at the

167
00:08:18.970 --> 00:08:20.028
end of the, the innovation cycle. If you

168
00:08:20.040 --> 00:08:22.019
will, you decide, you build something and you

169
00:08:22.028 --> 00:08:24.649
decide if you're going to regulate it or not,

170
00:08:24.660 --> 00:08:26.600
that is inherently not neutral. But the way it

171
00:08:26.608 --> 00:08:31.769
was being portrayed to argue against regulation, you would

172
00:08:31.779 --> 00:08:33.690
be like, whoa, whoa, whoa um you

173
00:08:33.700 --> 00:08:37.379
know, classic example in the United States is guns

174
00:08:37.389 --> 00:08:39.609
don't kill people, people kill people. And that

175
00:08:39.619 --> 00:08:45.359
argument has been if you will weaponized uh very successfully

176
00:08:45.369 --> 00:08:46.710
in the United States to stop us from doing any

177
00:08:46.719 --> 00:08:50.779
real meaningful gun control. Not just because we have

178
00:08:50.788 --> 00:08:52.590
the second amendment which gives Americans the right to bear

179
00:08:52.599 --> 00:08:56.668
arms, but when that law was crafted, we

180
00:08:56.678 --> 00:08:58.979
didn't have some of the weapons that we have today

181
00:08:58.989 --> 00:09:01.649
that you can buy at your local Walmart. Um

182
00:09:01.658 --> 00:09:05.178
often without an ID background check, it's actually quite

183
00:09:05.190 --> 00:09:09.859
staggering. And so the founding fathers were not imagining

184
00:09:09.869 --> 00:09:13.619
taking guns and walking into a school and shooting up

185
00:09:13.629 --> 00:09:16.259
an entire school, which unfortunately is a very common

186
00:09:16.269 --> 00:09:18.340
occurrence now, um, tragically, all too common

187
00:09:18.769 --> 00:09:22.058
. And so I started looking at being like,

188
00:09:22.070 --> 00:09:24.389
well on the one hand, it is true guns

189
00:09:24.399 --> 00:09:26.599
do not on their own, kill someone because they

190
00:09:26.609 --> 00:09:31.019
can't like self pull the trigger, they can't self

191
00:09:31.029 --> 00:09:31.989
shoot if you will. Although people I'm sure are

192
00:09:33.000 --> 00:09:35.219
now working on building guns that do exactly that A

193
00:09:35.229 --> 00:09:39.678
I powered weaponry but even then there's a human that's

194
00:09:39.690 --> 00:09:41.279
, that's ultimately coding that and controlling it. So

195
00:09:41.288 --> 00:09:43.719
it's still, there's always a human that takes the

196
00:09:43.729 --> 00:09:46.899
gun and makes the decision to pull a trigger.

197
00:09:46.849 --> 00:09:50.000
But I also was like, yeah, but the

198
00:09:50.009 --> 00:09:52.979
muskets that were there in the 18th century are really

199
00:09:52.989 --> 00:09:54.788
different from like an A K 15 assault rifle.

200
00:09:56.759 --> 00:09:58.940
You can kill a lot more people with the latter

201
00:09:58.038 --> 00:10:01.038
than with the former. So like a gun is

202
00:10:01.048 --> 00:10:03.960
not just a gun, like even within like the

203
00:10:03.969 --> 00:10:07.139
gun analogy, the amount of harm I can do

204
00:10:07.149 --> 00:10:11.500
with a musket versus like a pistol versus like the

205
00:10:11.509 --> 00:10:13.489
kind of weaponry that frankly, you should only ever

206
00:10:13.500 --> 00:10:16.538
be seeing held by the military in like a theater

207
00:10:16.548 --> 00:10:20.168
of war and is unfortunately on the street or in

208
00:10:20.178 --> 00:10:22.090
people's homes, um is, is like inherently not

209
00:10:22.099 --> 00:10:26.009
neutral. There were design choices that went into the

210
00:10:26.019 --> 00:10:28.200
making of the gun, the way that the bullets

211
00:10:28.210 --> 00:10:30.788
are done. Um There's like cop killer bullets that

212
00:10:30.798 --> 00:10:33.369
can pierce um body armor, right? So like

213
00:10:33.840 --> 00:10:37.178
the people who designed that knew that and the people

214
00:10:37.190 --> 00:10:39.769
who are choosing to sell it know it. So

215
00:10:39.779 --> 00:10:43.269
like they're not neutral either because you could decide to

216
00:10:43.279 --> 00:10:46.210
be like, we're not selling guns here and there

217
00:10:46.219 --> 00:10:48.288
indeed was a sporting store in the U SI think

218
00:10:48.298 --> 00:10:50.940
it was Dick's sporting good sporting goods, which decided

219
00:10:50.950 --> 00:10:52.729
not to. And then it got this massive blowback

220
00:10:52.739 --> 00:10:56.769
and it became a national issue precisely because they were

221
00:10:56.779 --> 00:11:00.379
exercising their right not to sell. Right. But

222
00:11:00.389 --> 00:11:03.149
that's not neutral because now you're like removing my,

223
00:11:03.158 --> 00:11:05.369
my right. Damn it to have guns. Um

224
00:11:05.379 --> 00:11:09.408
, so this isn't like a, I don't want

225
00:11:09.418 --> 00:11:11.668
to make a sort of pro or anti gun statement

226
00:11:11.678 --> 00:11:13.158
. I have my own view on that obviously,

227
00:11:13.168 --> 00:11:13.548
of course, as a citizen, I'm sure it's

228
00:11:13.558 --> 00:11:16.080
probably obvious from here. But what I mean is

229
00:11:16.349 --> 00:11:20.989
even with something that's like such a little easy example

230
00:11:20.000 --> 00:11:24.070
, like guns, easy. And compared in comparison

231
00:11:24.080 --> 00:11:26.359
to A I because it's just a physical, you

232
00:11:26.369 --> 00:11:30.119
know, tool, even that you start to realize

233
00:11:30.129 --> 00:11:33.590
like it is not neutral to decide to design bullets

234
00:11:33.599 --> 00:11:37.029
that can pierce wound right. There's like no other

235
00:11:37.038 --> 00:11:37.379
reason that you would do that. There's no other

236
00:11:37.389 --> 00:11:41.750
purpose of particularly a good benign purpose that you could

237
00:11:41.759 --> 00:11:43.509
use that for. So when you start thinking about

238
00:11:43.519 --> 00:11:46.928
it in that way, you can actually start looking

239
00:11:46.940 --> 00:11:48.428
at pretty much, I'm just looking around my my

240
00:11:48.440 --> 00:11:50.590
house right now, like almost any object, you're

241
00:11:50.599 --> 00:11:54.859
like, shit. Somebody has designed every aspect of

242
00:11:54.869 --> 00:11:56.070
it from the, the raw materials that were pulled

243
00:11:56.080 --> 00:12:01.269
out of the ground to like the environmental impact of

244
00:12:01.279 --> 00:12:03.820
that, to how much the workers all got paid

245
00:12:03.830 --> 00:12:07.250
all along the supply chain, all of it.

246
00:12:07.259 --> 00:12:09.779
Um Whether or not it's designed for the majority of

247
00:12:09.788 --> 00:12:11.759
the population, which is right handed or like,

248
00:12:11.769 --> 00:12:13.070
do we take left handed people into account What about

249
00:12:13.080 --> 00:12:15.960
if you're color blind? What if you have like

250
00:12:15.969 --> 00:12:22.200
dyslexia, like every single design consideration is not neutral

251
00:12:22.690 --> 00:12:24.058
. And that's just, that's just, again,

252
00:12:24.070 --> 00:12:28.678
that's for like analog world, physical objects. Now

253
00:12:28.690 --> 00:12:30.440
you take that to the next level and you start

254
00:12:30.450 --> 00:12:33.330
getting into code, it's the same principle, but

255
00:12:33.340 --> 00:12:37.658
it's also like turbocharged because A I, one of

256
00:12:37.668 --> 00:12:41.580
the things that's fascinating about what the world we're living

257
00:12:41.590 --> 00:12:43.710
in now is that because we have more data than

258
00:12:43.719 --> 00:12:48.210
ever before and computer processing power than ever before.

259
00:12:48.349 --> 00:12:52.989
We can do things faster and at a greater scale

260
00:12:52.729 --> 00:12:56.048
than at any time in human history. Whether or

261
00:12:56.058 --> 00:12:58.649
not that will hold by the way is very contentious

262
00:12:58.658 --> 00:13:00.239
. We don't know if we've reached the limits of

263
00:13:00.250 --> 00:13:03.509
computer processing power. For instance, we definitely haven't

264
00:13:03.519 --> 00:13:07.979
reached the limits of data. So that starts getting

265
00:13:07.989 --> 00:13:09.158
really messy. You also look at like who is

266
00:13:09.168 --> 00:13:11.798
doing the designing, be it for code or a

267
00:13:11.808 --> 00:13:18.690
physical object and those groups are not representative of the

268
00:13:18.700 --> 00:13:22.580
whole of our populations, which is why it can

269
00:13:22.590 --> 00:13:26.460
sound like diversity and equality and inclusion. We call

270
00:13:26.469 --> 00:13:28.389
it de I here. I'm not sure what it

271
00:13:28.399 --> 00:13:31.609
is in, in um Portuguese, but you probably

272
00:13:31.619 --> 00:13:35.399
have a similar concept for it. Yeah, the

273
00:13:35.408 --> 00:13:37.820
initials are pretty much the same, the same.

274
00:13:37.109 --> 00:13:41.269
Ok, cool. So de I can in many

275
00:13:41.279 --> 00:13:45.719
ways just seem like another version of being politically correct

276
00:13:45.729 --> 00:13:48.219
writer in the United States. A woke and it

277
00:13:48.229 --> 00:13:50.710
seems like a bad thing. I don't look at

278
00:13:50.719 --> 00:13:52.979
it as a bad thing in terms of the political

279
00:13:52.989 --> 00:13:54.308
sense. I look at it from a design perspective

280
00:13:54.320 --> 00:13:58.408
of being like I want, if I'm selling something

281
00:13:58.798 --> 00:14:00.479
, you know, bring out the capitalism. If

282
00:14:00.489 --> 00:14:03.519
I'm selling a service or a tool or a product

283
00:14:03.538 --> 00:14:07.889
, I want it to work for the vast majority

284
00:14:07.899 --> 00:14:09.750
, it ideally for everybody. So I have a

285
00:14:09.759 --> 00:14:13.548
challenge there because I need it to scale. But

286
00:14:13.558 --> 00:14:16.038
I also need to be able to personalize and customize

287
00:14:16.500 --> 00:14:18.928
, depending on your individual needs or the needs of

288
00:14:18.940 --> 00:14:22.029
your company or the needs of the country that you're

289
00:14:22.038 --> 00:14:22.798
based in. Right? Because you might have different

290
00:14:22.808 --> 00:14:26.080
laws there. Um How do I, how do

291
00:14:26.090 --> 00:14:30.009
I focus on that? And that kind of stuff

292
00:14:30.019 --> 00:14:31.609
really fascinates me because I don't understand why it gets

293
00:14:31.619 --> 00:14:35.908
lampooned so much in certain certain branches of the press

294
00:14:35.918 --> 00:14:39.250
and indeed investment communities as being politicized because I'm like

295
00:14:39.259 --> 00:14:41.349
, that's just truly, that's just good business.

296
00:14:41.359 --> 00:14:41.908
But like that, you know, that's just my

297
00:14:43.379 --> 00:14:43.869
, that's just my view, but I would assume

298
00:14:43.879 --> 00:14:46.269
as a good hearted capitalist that you would want to

299
00:14:46.279 --> 00:14:48.399
design products that the, you know, the majority

300
00:14:48.408 --> 00:14:50.070
of people can buy because that's, you know,

301
00:14:50.080 --> 00:14:54.298
catching more money. So it's very strange. Um

302
00:14:54.798 --> 00:14:56.190
So I guess that's what I mean when I say

303
00:14:56.200 --> 00:14:58.690
like technology ethics is so much bigger than just like

304
00:14:58.700 --> 00:15:01.619
, is something good or bad. Like that's a

305
00:15:01.629 --> 00:15:05.529
really binary way of looking at it. It's very

306
00:15:05.899 --> 00:15:09.700
complex and rich. It's like a tapestry, you

307
00:15:09.710 --> 00:15:11.779
start pulling on one thread and then you pull on

308
00:15:11.788 --> 00:15:13.389
another and another and you, you know, you

309
00:15:13.399 --> 00:15:18.320
come out with this whole complex analysis that you can

310
00:15:18.330 --> 00:15:22.710
use if you wish to make things better. Yeah

311
00:15:22.719 --> 00:15:24.519
, I mean, at a certain point there,

312
00:15:24.529 --> 00:15:28.908
you mentioned regulation and regulation across different countries. And

313
00:15:28.918 --> 00:15:33.219
perhaps later in the interview when we talk about specific

314
00:15:33.229 --> 00:15:35.710
kinds of technologies, we can come back to this

315
00:15:35.719 --> 00:15:39.639
because uh recently with the release of threads, it's

316
00:15:39.649 --> 00:15:43.009
interesting because here in the European Union, it's not

317
00:15:43.019 --> 00:15:46.849
available yet and it has to do with data privacy

318
00:15:46.859 --> 00:15:48.239
, online privacy, data collection, data, the

319
00:15:48.250 --> 00:15:52.099
ownership and all of that. So uh we can

320
00:15:52.109 --> 00:15:54.340
come back to this uh later. But uh I

321
00:15:54.349 --> 00:15:58.710
mean, uh at a certain point you mentioned there

322
00:15:58.719 --> 00:16:00.639
or alluded to one of the points you make in

323
00:16:00.649 --> 00:16:03.279
the book because at a certain point you talk about

324
00:16:03.288 --> 00:16:07.599
or explore the idea of what is a tool and

325
00:16:07.609 --> 00:16:11.889
the di the difference, for example, between tools

326
00:16:11.899 --> 00:16:14.879
that are found and tools that are created. So

327
00:16:15.139 --> 00:16:18.298
uh uh tell us a little bit about that because

328
00:16:18.308 --> 00:16:22.259
I think it's very helpful in terms of trying to

329
00:16:22.288 --> 00:16:26.469
reframe the way we think about these questions. Yeah

330
00:16:26.479 --> 00:16:27.658
. So for me, this was um I wrote

331
00:16:27.668 --> 00:16:30.428
a lot of the book during the pandemic during lockdown

332
00:16:30.570 --> 00:16:32.820
. Uh And I would, you know, I

333
00:16:32.830 --> 00:16:36.469
go for my sort of hour long walk sometimes longer

334
00:16:36.479 --> 00:16:37.960
than an hour who the British police will find out

335
00:16:37.969 --> 00:16:41.009
now that I was walking for an hour and a

336
00:16:41.019 --> 00:16:44.070
half. Um, I would do these really long

337
00:16:44.080 --> 00:16:45.269
laps around my local park and, you know,

338
00:16:45.279 --> 00:16:48.580
there was such a weird time. Right. It

339
00:16:48.590 --> 00:16:51.048
was such a strange time for all of us and

340
00:16:51.058 --> 00:16:56.469
I started to really go into some fairly abstract directions

341
00:16:56.479 --> 00:16:57.330
of thinking. And so one of the things was

342
00:16:57.340 --> 00:17:03.389
like, let's think of the most neutral tool possible

343
00:17:03.399 --> 00:17:06.269
and then the most like non neutral tool. So

344
00:17:06.279 --> 00:17:07.209
my examples because, you know, I wanted to

345
00:17:07.219 --> 00:17:11.588
like draw the, the map if you will or

346
00:17:11.598 --> 00:17:12.809
draw matrix, you know, so what's what's like

347
00:17:12.818 --> 00:17:17.489
the most neutral and the the most completely value laden

348
00:17:17.920 --> 00:17:19.868
um thing. So the, the hardcore one for

349
00:17:19.880 --> 00:17:23.170
me was the atomic bomb, which was, there's

350
00:17:23.180 --> 00:17:26.750
only one reason that you would build an atomic bomb

351
00:17:26.549 --> 00:17:29.559
and only one reason you're really going to use it

352
00:17:29.568 --> 00:17:30.759
, which is to harm because there's, there's no

353
00:17:30.769 --> 00:17:33.309
like there's no way of getting around that harm.

354
00:17:33.318 --> 00:17:36.410
It will, you know, the radiation damage to

355
00:17:36.420 --> 00:17:40.160
any human that comes within the blast radius and also

356
00:17:40.170 --> 00:17:45.598
just like other parts of nature for sure. Um

357
00:17:45.219 --> 00:17:48.910
is just non negotiable, it's going to happen in

358
00:17:48.930 --> 00:17:51.680
physics. So there's that, but there's also like

359
00:17:51.689 --> 00:17:53.049
the only two times that human beings have used,

360
00:17:53.059 --> 00:17:55.920
it was in the theater of war Right. So

361
00:17:55.930 --> 00:17:56.858
, it was like, it was designed in a

362
00:17:56.868 --> 00:18:00.029
war to be used in a war and we have

363
00:18:00.039 --> 00:18:03.979
lived under the shadow of threat of nuclear war ever

364
00:18:03.989 --> 00:18:07.078
since. And I grew up in the Cold War

365
00:18:07.509 --> 00:18:07.979
in the US. So, for me as a

366
00:18:07.989 --> 00:18:11.029
child, this was like the scariest thing that could

367
00:18:11.039 --> 00:18:14.858
ever happen to human beings as a nuke, like

368
00:18:14.868 --> 00:18:17.818
a rogue nuke situation or nukes getting out of control

369
00:18:17.828 --> 00:18:22.140
and just decimating entire countries. And very, unfortunately

370
00:18:22.150 --> 00:18:25.969
recently we've been living more or less through that kind

371
00:18:25.979 --> 00:18:27.779
of fear and we're still living through that. Yeah

372
00:18:27.789 --> 00:18:29.729
, I mean, that's the thing is like,

373
00:18:29.739 --> 00:18:30.309
everybody freaks out about A I, and I'm like

374
00:18:30.318 --> 00:18:33.943
, there's all these nukes, you know, it's

375
00:18:33.953 --> 00:18:34.943
like thousands and thousands of them and like, lots

376
00:18:34.953 --> 00:18:37.404
of countries have them that maybe shouldn't and it's too

377
00:18:37.414 --> 00:18:40.045
late now. Like, we can't put that genie

378
00:18:40.055 --> 00:18:41.285
back in the bottle. So that was like,

379
00:18:41.295 --> 00:18:42.164
that was, that was over here in my most

380
00:18:42.174 --> 00:18:45.265
extreme example of a technology that, like, you

381
00:18:45.275 --> 00:18:48.493
just wouldn't use a nuke for something good. Maybe

382
00:18:48.505 --> 00:18:49.275
you would have like, aliens were coming or an

383
00:18:49.285 --> 00:18:52.404
asteroid that was attacking earth and the only way we

384
00:18:52.414 --> 00:18:53.430
could stop it would be if we, like,

385
00:18:53.439 --> 00:18:56.239
launched a nuke out in space to, you know

386
00:18:56.250 --> 00:18:57.199
, blow up the asteroid. This is how I

387
00:18:57.209 --> 00:19:00.328
talk with little kids about tech ethics and they're like

388
00:19:00.338 --> 00:19:02.269
, they get it. They're like, yeah,

389
00:19:02.279 --> 00:19:04.539
you nuke against the asteroid. Maybe not the alien

390
00:19:04.549 --> 00:19:06.809
though. But, uh, we would want to

391
00:19:06.818 --> 00:19:08.479
talk with them first. Perhaps so. Yeah.

392
00:19:08.489 --> 00:19:11.608
Yeah. Perhaps. Let's not just assume immediately that

393
00:19:11.618 --> 00:19:15.449
they would come here to work and we would be

394
00:19:15.459 --> 00:19:21.289
preemptively killing another life farmer. I mean, come

395
00:19:21.299 --> 00:19:23.039
on, let's just give them a chance. Exactly

396
00:19:23.049 --> 00:19:26.209
. That's, that's my view as well in case

397
00:19:26.219 --> 00:19:29.799
they're listening. Uh, but then the other extreme

398
00:19:29.809 --> 00:19:30.769
I was like, well, what's the other,

399
00:19:30.779 --> 00:19:33.578
other extreme? And I got really into looking at

400
00:19:33.588 --> 00:19:36.049
nature when I was on my walks. And of

401
00:19:36.059 --> 00:19:38.318
course, this led to animals who use tools because

402
00:19:38.328 --> 00:19:41.689
what humans are not the only species that make tools

403
00:19:41.779 --> 00:19:42.588
, which is so cool, you can really go

404
00:19:42.598 --> 00:19:45.739
down a rabbit hole with this. Um And I

405
00:19:45.750 --> 00:19:47.729
did, I went down that rabbit hole so that

406
00:19:47.739 --> 00:19:49.358
you don't have to and looked at all of the

407
00:19:49.368 --> 00:19:52.209
different ways that animals fashion tools. And of course

408
00:19:52.219 --> 00:19:56.660
, this starts to become if you're interested in the

409
00:19:56.670 --> 00:20:00.009
history of what differentiates human beings from our other ape

410
00:20:00.019 --> 00:20:04.358
chimpanzee brethren. One of the big questions was human

411
00:20:04.368 --> 00:20:07.199
beings make tools. That's like a defining characteristic of

412
00:20:07.209 --> 00:20:08.920
what it means to be human, which is kind

413
00:20:08.930 --> 00:20:11.068
of trippy if you think about. Well, so

414
00:20:11.118 --> 00:20:14.318
the crows. So like, why is, why

415
00:20:14.328 --> 00:20:15.939
is that about making us human? But it just

416
00:20:15.949 --> 00:20:17.799
is. And so that was one of the things

417
00:20:17.809 --> 00:20:21.640
when Jane Goodall was um doing her amazing research about

418
00:20:21.650 --> 00:20:26.049
chimpanzees and she wrote to her then phd supervisor to

419
00:20:26.059 --> 00:20:29.269
describe what she was observing and he wrote back saying

420
00:20:29.660 --> 00:20:32.469
either we have to redefine what a tool is or

421
00:20:32.479 --> 00:20:33.630
we have to redefine what man is. And I

422
00:20:33.640 --> 00:20:37.630
was like, oh, there's something in this.

423
00:20:37.640 --> 00:20:37.549
And so it was like, well, what are

424
00:20:37.559 --> 00:20:40.989
those animals doing? And what were we doing?

425
00:20:41.338 --> 00:20:42.559
So, they were doing something along the lines of

426
00:20:42.568 --> 00:20:45.630
what I call a found tool. So they would

427
00:20:45.640 --> 00:20:49.338
find an object in nature, a stone, um

428
00:20:49.348 --> 00:20:52.608
, a branch and they would fashion it in some

429
00:20:52.618 --> 00:20:55.890
way to make a weapon. Usually it's used to

430
00:20:55.900 --> 00:20:59.068
hunt for food, um, rather than harm others

431
00:20:59.189 --> 00:21:00.489
, trapping food, et cetera, but it showed

432
00:21:00.500 --> 00:21:03.140
like advanced cognitive abilities. So I was like,

433
00:21:03.150 --> 00:21:07.118
ok, they're taking something that, that exists already

434
00:21:08.019 --> 00:21:11.630
and they're fashioning it in some way and they're coming

435
00:21:11.640 --> 00:21:14.358
up with really interesting uses for it. And there's

436
00:21:14.368 --> 00:21:15.118
a number of species that do it, of which

437
00:21:15.130 --> 00:21:18.039
we are one. So let's call that like the

438
00:21:18.049 --> 00:21:22.568
most even fire potentially could be viewed as neutral in

439
00:21:22.578 --> 00:21:23.598
the sense that it exists in nature. Like you

440
00:21:23.608 --> 00:21:26.279
can just look over in Canada right now where you're

441
00:21:26.289 --> 00:21:30.039
just getting these spontaneous wildfires because of the heat or

442
00:21:30.049 --> 00:21:33.209
when lightning strikes the earth, it can spark fires

443
00:21:33.568 --> 00:21:36.420
so that can exist in. So we didn't like

444
00:21:36.430 --> 00:21:38.529
invent fire. Nature invented fire. We just figured

445
00:21:38.539 --> 00:21:42.309
out how to harness it and then deliberately create conditions

446
00:21:42.318 --> 00:21:47.108
in which fire appears So I took that thinking and

447
00:21:47.118 --> 00:21:49.059
went back to the atomic bomb thinking and was like

448
00:21:49.068 --> 00:21:52.279
, OK, what do we mean by the atomic

449
00:21:52.289 --> 00:21:53.239
bomb? Because there's a whole process, you don't

450
00:21:53.250 --> 00:21:56.279
just start with an atomic bomb, they're incredibly difficult

451
00:21:56.289 --> 00:21:57.799
to build. Thank God uh given the harm that

452
00:21:57.809 --> 00:22:02.559
they can do. So I started reading honestly,

453
00:22:02.568 --> 00:22:04.170
it's like bringing back all these weird pandemic memories.

454
00:22:04.180 --> 00:22:07.539
But I spent like months, months and months reading

455
00:22:07.549 --> 00:22:11.479
about the journey to make that bomb and the scientists

456
00:22:11.489 --> 00:22:15.160
who started out working on it were not doing it

457
00:22:15.170 --> 00:22:18.640
to make a weapon, which I think is important

458
00:22:18.809 --> 00:22:19.250
because what you want to do is you want to

459
00:22:19.259 --> 00:22:23.039
identify where, where from like the first discovery to

460
00:22:23.049 --> 00:22:27.989
the first detonation over Hiroshima and the Nagasaki, where

461
00:22:29.000 --> 00:22:32.549
in that line do you cross, do you cross

462
00:22:32.559 --> 00:22:33.160
a line and it stops being neutral? So I

463
00:22:33.170 --> 00:22:34.779
was like, OK, the scientists who are just

464
00:22:34.789 --> 00:22:40.959
looking to understand what happens when you bombard uranium,

465
00:22:41.140 --> 00:22:45.039
that's just like pure science and the, the information

466
00:22:45.049 --> 00:22:48.078
of that the fact of that exists in nature or

467
00:22:48.088 --> 00:22:51.348
whether or not we ever discovered it as humans,

468
00:22:51.358 --> 00:22:53.078
it would exist because again, it's, it's,

469
00:22:53.088 --> 00:22:56.559
it's physics. So when does it start to become

470
00:22:56.568 --> 00:23:00.039
a weapon? And I identified in the book that

471
00:23:00.049 --> 00:23:03.650
it becomes a weapon in the mind of a brilliant

472
00:23:03.660 --> 00:23:07.969
Hungarian scientist, Leo Solar as he was walking down

473
00:23:07.979 --> 00:23:10.469
the street here in London, he attended a lecture

474
00:23:11.170 --> 00:23:12.759
, I think in 1938 and he suddenly had this

475
00:23:12.769 --> 00:23:17.039
idea of how to do it. And because he

476
00:23:17.049 --> 00:23:18.358
was friends with everyone, he's an amazing man.

477
00:23:18.368 --> 00:23:19.959
His book, Genius In The Shadows. It's a

478
00:23:19.969 --> 00:23:22.549
book about his life is really worth reading to discover

479
00:23:22.559 --> 00:23:26.309
like the networking of science and how an idea goes

480
00:23:26.318 --> 00:23:29.529
from idea to weapon or hopefully the idea to vaccine

481
00:23:29.539 --> 00:23:32.180
or idea to, you know, wonderful cure that

482
00:23:32.189 --> 00:23:33.969
will save us all from climate change. So he

483
00:23:33.979 --> 00:23:37.660
goes and talks to Einstein about it and because both

484
00:23:37.670 --> 00:23:40.939
of them were Central European and Jewish, which I

485
00:23:40.949 --> 00:23:42.289
think is also very important, they recognize the threat

486
00:23:42.299 --> 00:23:47.150
of Hitler far earlier than their American counterparts did.

487
00:23:47.578 --> 00:23:49.559
And they were like a, you could do this

488
00:23:49.568 --> 00:23:53.739
with the scientific information that we now have about how

489
00:23:53.750 --> 00:23:57.088
to split the atom, you could do this and

490
00:23:57.098 --> 00:24:00.949
you could weaponize it and we think that Hitler will

491
00:24:00.160 --> 00:24:03.969
so we'd better have a plan in place. And

492
00:24:03.979 --> 00:24:07.098
because Einstein was able due to his incredible status as

493
00:24:07.108 --> 00:24:11.368
a Nobel Prize winner to get an audience with the

494
00:24:11.380 --> 00:24:15.539
then US President Franklin Delano Roosevelt, they explained this

495
00:24:15.549 --> 00:24:18.729
to him, laid it out and then FDR green

496
00:24:18.739 --> 00:24:22.140
lit the deal if you will to create what became

497
00:24:22.150 --> 00:24:23.838
the Manhattan project, which ended up involving over 1000

498
00:24:23.848 --> 00:24:26.009
scientists and you know, massive budget and became a

499
00:24:26.019 --> 00:24:29.680
military project and scientists from all over the world worked

500
00:24:29.689 --> 00:24:30.618
on it. So you're like, so was it

501
00:24:30.630 --> 00:24:33.949
FDR that did it because he, he gave like

502
00:24:33.959 --> 00:24:37.799
the political nouse if you will and power and approval

503
00:24:37.809 --> 00:24:41.509
and money. Was it Einstein who like formed the

504
00:24:41.519 --> 00:24:42.469
bridge? Because Leo Solar could have had the idea

505
00:24:42.479 --> 00:24:45.000
. We all have great ideas, but like that

506
00:24:45.009 --> 00:24:48.818
doesn't necessarily lead to them being executed. So there's

507
00:24:48.828 --> 00:24:51.453
like a chain. It was like solar. Einstein

508
00:24:51.463 --> 00:24:55.064
FDRFDR then tasked Ben our Bush who is like head

509
00:24:55.074 --> 00:24:57.914
of all of America's totally cool World War Two science

510
00:24:57.924 --> 00:25:03.414
stuff. Another fascinating person to read about Robert Oppenheimer

511
00:25:03.424 --> 00:25:06.574
. Now subject of a major movie uh who led

512
00:25:06.834 --> 00:25:07.614
, you know, who like literally run the man

513
00:25:07.625 --> 00:25:12.539
project. All of it was absolutely fascinating for me

514
00:25:12.549 --> 00:25:15.660
to like I had to build out the map of

515
00:25:15.670 --> 00:25:18.410
who was working on it. You know, you

516
00:25:18.420 --> 00:25:19.269
could ultimately be like, no, all of these

517
00:25:19.279 --> 00:25:22.118
things could have happened and it actually comes down to

518
00:25:22.130 --> 00:25:23.559
the pilots who flew the plane and dropped the two

519
00:25:23.568 --> 00:25:27.959
bombs because they were the last kind of line of

520
00:25:27.969 --> 00:25:30.039
defense who could have, I don't know, made

521
00:25:30.049 --> 00:25:33.420
an ethical protest and done what many people wanted by

522
00:25:33.430 --> 00:25:37.078
that point, which was a demonstration of the bomb

523
00:25:37.088 --> 00:25:40.400
but not on a human population. You could have

524
00:25:40.410 --> 00:25:42.068
dropped it out in the ocean to let people see

525
00:25:42.219 --> 00:25:45.059
what it was capable of doing. And hopefully,

526
00:25:45.068 --> 00:25:47.439
then that would have made Japan surrender. That was

527
00:25:47.449 --> 00:25:49.009
like an actual idea that was being put forward.

528
00:25:49.019 --> 00:25:52.618
But by that point the new president, Harry Truman

529
00:25:52.630 --> 00:25:52.900
was like, no, we have to do this

530
00:25:52.910 --> 00:25:56.489
because he was given statistics saying if we don't drop

531
00:25:56.500 --> 00:26:00.858
this bomb and the fighting continues for another 18 months

532
00:26:00.868 --> 00:26:03.578
, which were the predictions, however many people will

533
00:26:03.588 --> 00:26:04.299
die and it was in the millions. So he

534
00:26:04.309 --> 00:26:08.400
was weighing up his ethical calculus, right. And

535
00:26:08.410 --> 00:26:11.118
it's easy for all of us to judge these things

536
00:26:11.130 --> 00:26:14.118
now knowing what we know now. But back then

537
00:26:14.130 --> 00:26:15.430
they didn't know and they had to make a call

538
00:26:15.439 --> 00:26:18.250
and they'd already been fighting war for a really long

539
00:26:18.259 --> 00:26:19.650
time. And, you know, we can argue

540
00:26:19.660 --> 00:26:22.500
about that and people do argue about that until the

541
00:26:22.509 --> 00:26:25.019
cows come home. So for me, I didn't

542
00:26:25.029 --> 00:26:26.809
want to argue about it. I wanted to sort

543
00:26:26.818 --> 00:26:32.420
of forensically map it because I can see it happening

544
00:26:32.430 --> 00:26:36.068
again. Uh I can see it happening in all

545
00:26:36.078 --> 00:26:37.640
sorts of different things. And like, I don't

546
00:26:37.650 --> 00:26:38.019
mean in the sense of it's leading to death.

547
00:26:38.029 --> 00:26:41.269
I mean, I, I can see it happening

548
00:26:41.279 --> 00:26:45.630
again in that we are in this incredible moment of

549
00:26:45.640 --> 00:26:49.358
flourishing scientifically and technologically. This is an, this

550
00:26:49.368 --> 00:26:51.939
is an amazing time. Like people will write about

551
00:26:51.949 --> 00:26:53.539
this. I think centuries later from now that this

552
00:26:53.549 --> 00:26:56.670
was like a real turning point moment in human science

553
00:26:56.680 --> 00:27:00.910
and technology evolution. And so what I'm hoping to

554
00:27:00.920 --> 00:27:02.769
do many people are working on this, I'm just

555
00:27:02.779 --> 00:27:03.680
like one tiny little person. But what I'm hoping

556
00:27:03.689 --> 00:27:07.799
to do um as a historian in training is like

557
00:27:07.809 --> 00:27:10.078
, write the history of the future, which is

558
00:27:10.088 --> 00:27:11.699
like, ok, so if, if we've got

559
00:27:11.709 --> 00:27:14.920
a, I now, what can we learn from

560
00:27:14.939 --> 00:27:17.890
the atomic bomb exercise that we just went through?

561
00:27:17.900 --> 00:27:21.439
You? And I here today to understand who's working

562
00:27:21.449 --> 00:27:22.358
, for instance, on A I, although it

563
00:27:22.368 --> 00:27:25.400
can also be genetic engineering, it could be any

564
00:27:25.410 --> 00:27:26.299
technology, put it in the whole point is that

565
00:27:26.309 --> 00:27:29.769
it should work for anything who's working on it.

566
00:27:30.289 --> 00:27:32.549
What are the ethical decisions that are in play?

567
00:27:32.729 --> 00:27:36.338
Who has the power to actually get things done or

568
00:27:36.348 --> 00:27:41.400
more importantly to stop something, right? All of

569
00:27:41.410 --> 00:27:42.568
that stuff and also who doesn't have the power,

570
00:27:42.578 --> 00:27:45.699
who's just on the receiving end of this? Because

571
00:27:45.709 --> 00:27:51.509
like, you know, the atomic crisis, if

572
00:27:51.519 --> 00:27:53.170
you will, that resulted from 1945 I think helped

573
00:27:53.180 --> 00:27:56.059
a lot of people to understand that this is something

574
00:27:56.068 --> 00:27:56.789
that affects all of humanity, but not all of

575
00:27:56.799 --> 00:28:00.209
humanity was involved in the design and deployment considerations.

576
00:28:00.529 --> 00:28:04.209
And even with nuclear arms control, even today,

577
00:28:04.390 --> 00:28:07.848
certain countries have a greater voice in that than others

578
00:28:07.858 --> 00:28:11.368
. And that matters because you hear with people talking

579
00:28:11.380 --> 00:28:14.380
about A I governance and they're like, we should

580
00:28:14.390 --> 00:28:18.779
have an international Atomic Energy Agency like exists today in

581
00:28:18.789 --> 00:28:22.868
Vienna to look at nuclear technology. We should have

582
00:28:22.880 --> 00:28:23.588
something like that for A I. And it's like

583
00:28:23.598 --> 00:28:26.309
, well, OK, let's just check that,

584
00:28:26.318 --> 00:28:30.400
that interesting idea. Let's examine that is the IAE

585
00:28:30.410 --> 00:28:34.969
A actually a good example, a template a model

586
00:28:36.250 --> 00:28:38.400
for us to use to govern A I. And

587
00:28:38.410 --> 00:28:41.449
like we need to interview the people who are working

588
00:28:41.459 --> 00:28:44.209
on it and also their critics and come up with

589
00:28:44.219 --> 00:28:45.430
that view, I've seen some people really dismiss it

590
00:28:45.680 --> 00:28:48.880
. You also saw a bunch of people saying we

591
00:28:48.890 --> 00:28:52.640
should have a CERN for A I research. So

592
00:28:52.650 --> 00:28:55.019
cern being the particle physics laboratory that's based on the

593
00:28:55.029 --> 00:28:57.489
French Swiss border as physicists again from around the world

594
00:28:57.500 --> 00:29:00.750
. And it's public, public science, if you

595
00:29:00.759 --> 00:29:03.250
will public interest science, so you would want to

596
00:29:03.259 --> 00:29:06.130
talk with CERN and be like, OK, like

597
00:29:06.140 --> 00:29:07.199
we have an example, we run the CERN experiment

598
00:29:07.209 --> 00:29:11.170
now for, you know, 5060 years. Do

599
00:29:11.180 --> 00:29:15.049
you think that's actually relevant and appropriate if it isn't

600
00:29:15.059 --> 00:29:17.630
, could we do better with an A I research

601
00:29:17.640 --> 00:29:19.180
lab? What would that look like to make it

602
00:29:19.189 --> 00:29:26.209
fair equitable? Um representative more democratic. Uh how

603
00:29:26.219 --> 00:29:29.949
do we factor in things like climate and biodiversity,

604
00:29:29.959 --> 00:29:32.858
which we didn't necessarily in the early atomic discussions but

605
00:29:32.868 --> 00:29:34.640
actually really matter that sort of thing. So I

606
00:29:34.650 --> 00:29:37.318
think there's a lot we can learn from the history

607
00:29:37.328 --> 00:29:41.309
of this found technology if it's just something that's out

608
00:29:41.318 --> 00:29:44.368
there versus something that you very deliberately set out to

609
00:29:44.380 --> 00:29:47.660
make like an atomic bomb and most of us when

610
00:29:47.670 --> 00:29:51.838
we're making technology or using it or investing in it

611
00:29:52.400 --> 00:29:55.229
uh or buying it are not ever going to have

612
00:29:55.239 --> 00:29:57.920
to face the extremes of an atomic weapon, but

613
00:29:57.930 --> 00:30:00.479
we'll probably be somewhere closer from, we just found

614
00:30:00.489 --> 00:30:03.939
something and we, we like fashioned it or we're

615
00:30:03.949 --> 00:30:07.439
deliberately creating something that's probably more middle of the road

616
00:30:07.449 --> 00:30:11.130
between those two. So that's a really long example

617
00:30:11.140 --> 00:30:11.380
. But I think it's quite important because you can't

618
00:30:11.390 --> 00:30:15.608
really rush through talking about nuclear technology. Um,

619
00:30:15.618 --> 00:30:18.049
and it matters because now we're having this big conversation

620
00:30:18.059 --> 00:30:22.049
globally about how to regulate A I and thing that

621
00:30:22.059 --> 00:30:23.709
people keep coming back to again and again and again

622
00:30:25.549 --> 00:30:27.650
is the nuclear war threat. They also cite the

623
00:30:27.660 --> 00:30:30.088
pandemic threat given that we've all just lived through that

624
00:30:30.098 --> 00:30:33.750
. I think we all had a very uh upfront

625
00:30:33.759 --> 00:30:37.848
close and personal stress test of pandemic governance and health

626
00:30:37.858 --> 00:30:42.039
governance and bio laboratory governance, right? Like was

627
00:30:42.049 --> 00:30:45.279
this a virus that was manufactured in the lab?

628
00:30:45.539 --> 00:30:47.559
Was it something that came from nature? Like this

629
00:30:47.568 --> 00:30:48.750
is something that's still being discussed? Scientists are still

630
00:30:48.759 --> 00:30:52.650
evolving their views on that and even if it is

631
00:30:52.660 --> 00:30:53.750
something that was found in nature, it still raises

632
00:30:53.759 --> 00:30:56.549
the issue of these labs, right? And like

633
00:30:56.559 --> 00:31:02.209
how the ethics, the ethics of bioengineering that all

634
00:31:02.219 --> 00:31:03.709
comes from World War Two, all of that thinking

635
00:31:03.719 --> 00:31:07.309
medical ethics, all of it really got an update

636
00:31:07.318 --> 00:31:10.098
from World War Two. So if you want to

637
00:31:10.108 --> 00:31:11.858
think about the technologies of the future, knowing your

638
00:31:11.868 --> 00:31:17.108
second World War Science and technology studies, history from

639
00:31:17.118 --> 00:31:19.500
the second World War onwards I think is essential,

640
00:31:21.828 --> 00:31:23.039
right? You know, you have, you can't

641
00:31:23.180 --> 00:31:26.719
, you can't be talking about A I to today

642
00:31:26.729 --> 00:31:30.689
in the abstract, you have to know we've already

643
00:31:30.699 --> 00:31:34.489
seen scientists taking ethical stances and doctors taking ethical stances

644
00:31:34.608 --> 00:31:37.680
. Um, some people have said that A I

645
00:31:37.689 --> 00:31:40.318
should be regulated more like the food and drug agency

646
00:31:40.328 --> 00:31:41.890
in the United States. Like you can't just,

647
00:31:41.900 --> 00:31:45.598
you can't just roll out a drug on the American

648
00:31:45.608 --> 00:31:48.559
population. It has to go through extremely rigorous testing

649
00:31:48.848 --> 00:31:51.920
, right? And God forbid when we're talking about

650
00:31:51.930 --> 00:31:56.479
global pharmaceutical manufacturing or global research um or research on

651
00:31:56.489 --> 00:32:00.098
the human body or embryos and stem cell tissue,

652
00:32:00.108 --> 00:32:02.338
right? Like there's entire governance structures set up for

653
00:32:02.348 --> 00:32:07.400
this that come from weirdly a World War Two starting

654
00:32:07.410 --> 00:32:10.969
framework because that's when we saw not just the potentially

655
00:32:10.979 --> 00:32:15.289
positive but also controversial narrative around atomic weapons, but

656
00:32:15.299 --> 00:32:20.078
also a lot of the Nazi medical experiments and bioresearch

657
00:32:20.608 --> 00:32:22.759
experiments, which were absolutely horrific, right? So

658
00:32:22.769 --> 00:32:24.500
all of that thinking is there. So if you

659
00:32:24.509 --> 00:32:28.759
don't know that thinking you're doing the classic thing that

660
00:32:28.769 --> 00:32:30.578
tech people do, which is like, oh what

661
00:32:30.588 --> 00:32:31.000
if we invented this thing? And you're like,

662
00:32:31.009 --> 00:32:34.769
you've invented something that's literally already existed and that people

663
00:32:34.779 --> 00:32:36.539
have been working on for decades, like do your

664
00:32:36.549 --> 00:32:40.469
literature review before you start talking, right? So

665
00:32:40.479 --> 00:32:45.779
classic. So classic, I mean, let me

666
00:32:45.789 --> 00:32:49.709
just ask you one question about all of what you

667
00:32:49.719 --> 00:32:52.358
what you've just said. So, um, you've

668
00:32:52.368 --> 00:32:57.838
talked mostly about nuclear weapons and you also have the

669
00:32:57.848 --> 00:33:01.000
discovery of nuclear fusion, for example. And uh

670
00:33:01.009 --> 00:33:05.358
I, I was wondering if you think that perhaps

671
00:33:05.368 --> 00:33:12.479
certain scientific discoveries themselves might not be neutral because I

672
00:33:12.489 --> 00:33:14.104
, I mean, we could, we could just

673
00:33:14.114 --> 00:33:17.354
say, uh and I'm not pointing fingers at anyone

674
00:33:17.364 --> 00:33:21.265
that studies or studied nuclear fission. I mean,

675
00:33:21.275 --> 00:33:22.894
it's uh as far as I, as I,

676
00:33:22.904 --> 00:33:25.824
as I'm concerned, it's perfectly fine to understand how

677
00:33:25.884 --> 00:33:29.094
atoms work and all of that. And the same

678
00:33:29.104 --> 00:33:31.334
for how genes work, for example. But at

679
00:33:31.344 --> 00:33:35.949
the same time, isn't it the case that uh

680
00:33:35.959 --> 00:33:39.118
first of all people, uh people who are making

681
00:33:39.130 --> 00:33:44.588
the scientific discoveries themselves are people and they have their

682
00:33:44.598 --> 00:33:49.529
own motivations and their work is u usually uh uh

683
00:33:49.539 --> 00:33:55.039
paid for by governments or private institutions. And that's

684
00:33:55.049 --> 00:34:02.299
also not random or usually not arbitrary. I mean

685
00:34:02.309 --> 00:34:06.420
, if they pay for something, they have particular

686
00:34:06.430 --> 00:34:09.458
goals in mind, they want certain developments instead of

687
00:34:09.469 --> 00:34:13.028
others, they want c to work. Why there

688
00:34:13.039 --> 00:34:16.648
certain knowledge instead of some other knowledge? So could

689
00:34:16.657 --> 00:34:21.998
it also, could you think or say that certain

690
00:34:22.009 --> 00:34:28.398
scientific discoveries are themselves not neutral even though they are

691
00:34:28.789 --> 00:34:34.599
just uh just uh uh at first sight producing useful

692
00:34:34.608 --> 00:34:37.648
knowledge or? Well, I think it's probably important

693
00:34:37.657 --> 00:34:42.117
to differentiate between the discovery and what leads to it

694
00:34:42.128 --> 00:34:44.739
. So, back in the day when I thought

695
00:34:44.748 --> 00:34:45.958
that technology was neutral before I wrote a book of

696
00:34:45.967 --> 00:34:50.458
the change if I was coming from the, the

697
00:34:50.467 --> 00:34:52.175
sort of technology um digital perspective. And I was

698
00:34:52.184 --> 00:34:55.083
like, this is math, this is mathematics and

699
00:34:55.094 --> 00:34:58.385
you hear that a lot um like Gary Kasparov,

700
00:34:58.405 --> 00:35:00.833
the chess grandmaster who wrote a book on A I

701
00:35:00.844 --> 00:35:02.224
called Deep Thinking was like on Twitter a few years

702
00:35:02.235 --> 00:35:04.695
ago. And I cited him in the book saying

703
00:35:04.704 --> 00:35:07.554
ethical A I is like ethical, electricity, like

704
00:35:07.563 --> 00:35:09.864
electricity is just electricity. Like he was kind of

705
00:35:09.875 --> 00:35:13.704
like, what is this uh this argument? And

706
00:35:13.715 --> 00:35:15.364
I, I understand what he means and you see

707
00:35:15.375 --> 00:35:19.264
it a lot. I follow Twitter obsessively and I'm

708
00:35:19.273 --> 00:35:22.148
constantly watching people argue about code is neutral. Math

709
00:35:22.159 --> 00:35:24.010
is neutral and all these people are trying to talk

710
00:35:24.019 --> 00:35:27.679
about values, but math has no values. It's

711
00:35:27.688 --> 00:35:30.500
like the universal language. And I understand that just

712
00:35:30.510 --> 00:35:34.539
like a phenomenon that exists in chemistry or a phenomenon

713
00:35:34.550 --> 00:35:37.239
that exists in physics. Again, putting the atom

714
00:35:37.659 --> 00:35:39.208
has like doesn't care what my politics are or who

715
00:35:39.219 --> 00:35:42.320
writes my paycheck, right? Like it just,

716
00:35:42.329 --> 00:35:44.840
it just exists, it's knowledge. So I think

717
00:35:44.849 --> 00:35:46.889
that part is, is neutral, something that just

718
00:35:46.898 --> 00:35:51.820
exists, is neutral in the natural physical world.

719
00:35:52.780 --> 00:35:59.369
That doesn't mean that motivations for seeking that knowledge out

720
00:36:00.228 --> 00:36:02.320
are irrelevant because I think they are relevant. Uh

721
00:36:02.329 --> 00:36:06.159
Absolutely the funding model. I mean, we're seeing

722
00:36:06.168 --> 00:36:07.300
this right now with A I like most people can't

723
00:36:07.309 --> 00:36:12.289
afford to build large language models there, there's this

724
00:36:12.300 --> 00:36:14.688
whole thing of like elite capture and whether or not

725
00:36:14.699 --> 00:36:16.228
we're going to have like a new monopoly of these

726
00:36:16.239 --> 00:36:17.309
things, which is why we're getting a lot of

727
00:36:17.320 --> 00:36:20.228
pushback and some people are wanting to release them as

728
00:36:20.239 --> 00:36:22.378
source. Now. Uh What data goes into the

729
00:36:22.389 --> 00:36:24.829
training sets, all of this stuff, the intellectual

730
00:36:24.840 --> 00:36:29.110
property thereof. Can these things be audited or not

731
00:36:29.119 --> 00:36:30.860
? And should they be particularly if they're involved in

732
00:36:30.869 --> 00:36:34.898
public procurement of any kind? Um or like public

733
00:36:34.909 --> 00:36:38.510
service use of any kind. So I think we're

734
00:36:38.519 --> 00:36:42.500
sophisticated enough as a species where we can have this

735
00:36:42.510 --> 00:36:45.349
conversation and go if you are doing something, if

736
00:36:45.360 --> 00:36:49.469
you're seeking out knowledge and doing research on behalf of

737
00:36:49.478 --> 00:36:53.699
shareholders for a company or a private company or the

738
00:36:53.708 --> 00:36:57.619
government, governments are completely value laden. So of

739
00:36:57.628 --> 00:36:59.269
course, it matters if you're doing it for the

740
00:36:59.280 --> 00:37:02.030
US government versus the Chinese government versus let's pick Switzerland

741
00:37:02.039 --> 00:37:07.050
which claims to be neutral, uh an interesting country

742
00:37:07.059 --> 00:37:09.050
to tackle on that claim. Of course, these

743
00:37:09.059 --> 00:37:12.010
things matter. So I feel like we can,

744
00:37:12.188 --> 00:37:14.878
we can separate out the neutrality of the fact like

745
00:37:14.889 --> 00:37:15.398
, oh wow, if you cut off my finger

746
00:37:15.409 --> 00:37:17.929
, this is what happens like a finger being removed

747
00:37:17.938 --> 00:37:22.000
from its hand produces X numbers of physical responses and

748
00:37:22.010 --> 00:37:23.728
we can observe them and describe them forensically and repeat

749
00:37:23.739 --> 00:37:27.280
that experiment and hopefully stop cutting people's fingers off because

750
00:37:27.289 --> 00:37:31.019
we've, we've answered those questions. But why of

751
00:37:31.030 --> 00:37:34.918
doing that? The who of doing that? The

752
00:37:35.289 --> 00:37:37.418
, for what purpose are we going to use that

753
00:37:37.429 --> 00:37:37.728
knowledge? Is it, you know, maybe we're

754
00:37:37.739 --> 00:37:39.699
chopping our fingers for a really good reason. Maybe

755
00:37:39.708 --> 00:37:43.148
we're doing it terribly just to be awful. Like

756
00:37:43.579 --> 00:37:45.969
all of those questions are relevant and matter and we

757
00:37:45.978 --> 00:37:50.739
can use them to, to do science potentially in

758
00:37:50.750 --> 00:37:52.809
a more ethical way. And like, I know

759
00:37:52.820 --> 00:37:54.179
that's a really problematic statement for a lot of people

760
00:37:54.188 --> 00:37:55.849
. And it should be, I'm delighted that it's

761
00:37:55.860 --> 00:37:59.269
a problematic statement because it means that our thinking is

762
00:37:59.280 --> 00:38:00.989
like switched on and we're all going to go.

763
00:38:00.309 --> 00:38:02.550
Does that mean to do more ethical science? What

764
00:38:02.559 --> 00:38:07.429
does it mean to do ethical technology or ethical A

765
00:38:07.438 --> 00:38:09.030
I? And we see that with A I,

766
00:38:09.039 --> 00:38:12.449
right. I, I cannot think of another technology

767
00:38:12.458 --> 00:38:14.519
where so many people have been in such a hurry

768
00:38:14.610 --> 00:38:17.659
to claim that it's trustworthy, responsible, reliable,

769
00:38:17.869 --> 00:38:20.840
um ethical, you know, we don't, we

770
00:38:20.849 --> 00:38:22.409
don't feel the need to do that. And it's

771
00:38:22.418 --> 00:38:27.760
because I think people understand we've matured enough as a

772
00:38:27.769 --> 00:38:30.570
species to understand that A I is inherently not neutral

773
00:38:30.579 --> 00:38:32.449
, that we have to rush out to brand it

774
00:38:32.719 --> 00:38:37.760
as trustworthy or responsible because people are terrified. And

775
00:38:37.769 --> 00:38:38.378
there's, you know, there's a reason for that

776
00:38:38.389 --> 00:38:40.378
. There are some really scary uses, you could

777
00:38:40.389 --> 00:38:44.139
put this technology to. So you need to reassure

778
00:38:44.148 --> 00:38:45.418
people up front that, you know, we're just

779
00:38:45.429 --> 00:38:47.378
using it for I don't know, whatever it is

780
00:38:47.389 --> 00:38:49.938
. People want to be using it for, uh

781
00:38:49.949 --> 00:38:51.878
, it seems to me again, largely for advertising

782
00:38:51.889 --> 00:38:52.699
and marketing but there's a lot more, you know

783
00:38:52.708 --> 00:38:54.639
, drug discovery would be a great one. But

784
00:38:54.648 --> 00:38:58.128
even then, even then there could be, we

785
00:38:58.139 --> 00:39:00.239
could discover some really trippy stuff with that and it's

786
00:39:00.250 --> 00:39:00.989
gonna be, you know, what do we do

787
00:39:00.000 --> 00:39:02.228
with it? What do we do with that knowledge

788
00:39:02.239 --> 00:39:05.340
? You can't unknow something once you know it.

789
00:39:06.550 --> 00:39:08.550
Mhm. Yeah. Uh, but I mean,

790
00:39:08.559 --> 00:39:13.909
uh, explain a little bit better why in certain

791
00:39:13.918 --> 00:39:16.668
instances, technology A I systems, for example,

792
00:39:16.909 --> 00:39:21.039
can be biased. I mean, they can have

793
00:39:21.050 --> 00:39:23.688
, for example, sexual racial bias or biases of

794
00:39:23.699 --> 00:39:28.369
any other kind because there are people that, uh

795
00:39:28.378 --> 00:39:31.579
, particularly when it comes, for example, to

796
00:39:31.590 --> 00:39:37.898
how certain police departments in the US use systems to

797
00:39:37.199 --> 00:39:40.679
, uh, fight against crime, I guess in

798
00:39:42.219 --> 00:39:45.128
that way. And, uh, pe people,

799
00:39:45.139 --> 00:39:47.878
uh, just rely on the data, those systems

800
00:39:47.889 --> 00:39:51.239
generate and they say, oh, you're just feeding

801
00:39:51.250 --> 00:39:53.010
them data and they are processing the data and then

802
00:39:53.019 --> 00:39:57.458
they help, uh, the police. Uh,

803
00:39:57.469 --> 00:39:59.418
uh, I, I mean, when it comes

804
00:39:59.429 --> 00:40:02.438
to, uh, they have limited resources and they

805
00:40:02.449 --> 00:40:05.739
have in terms of when, when it comes for

806
00:40:05.750 --> 00:40:08.978
them to decide which particular areas they should police more

807
00:40:08.989 --> 00:40:13.519
or less. So it's not biased at all.

808
00:40:13.530 --> 00:40:16.820
It's just, uh, computer processing data. But

809
00:40:17.070 --> 00:40:20.579
I, I mean, that's not really the case

810
00:40:21.269 --> 00:40:22.239
. Oh, no. I mean, it's totally

811
00:40:22.250 --> 00:40:24.728
biased. It is completely biased and like that's the

812
00:40:24.739 --> 00:40:28.219
tricky thing. So you're right to highlight things like

813
00:40:28.228 --> 00:40:30.199
facial recognition technology because that's going to be regulated under

814
00:40:30.208 --> 00:40:32.449
the EU A I Act. And this whole question

815
00:40:32.458 --> 00:40:37.438
of, can you just have real time identity surveillance

816
00:40:37.449 --> 00:40:39.128
? Right. So people walking around like you see

817
00:40:39.139 --> 00:40:40.909
in the movies and you and I'd be walking down

818
00:40:40.918 --> 00:40:43.708
the street in a little square with a pair above

819
00:40:43.719 --> 00:40:45.139
our head and it would be like, Stephanie her

820
00:40:46.010 --> 00:40:47.869
, you know, Ricardo Lopez are walking down the

821
00:40:47.878 --> 00:40:51.010
street going into a coffee shop and they would have

822
00:40:51.019 --> 00:40:52.179
like our height and our weight and our eye color

823
00:40:52.289 --> 00:40:54.510
, but potentially more, you know how we voted

824
00:40:54.519 --> 00:40:57.099
in our last election, whether or not one of

825
00:40:57.110 --> 00:40:59.969
us has credit cards and um you know, pick

826
00:40:59.978 --> 00:41:01.659
your, pick your, your fantasy information profile about

827
00:41:01.668 --> 00:41:06.519
yourself or your nightmare all about your political, you

828
00:41:06.539 --> 00:41:08.398
know, our sexuality, uh you know, last

829
00:41:08.409 --> 00:41:12.530
last pornography was looked at yesterday, right? Because

830
00:41:12.539 --> 00:41:14.050
all that stuff is being tracked, all of it's

831
00:41:14.059 --> 00:41:16.800
being track. Um So yes, that exists,

832
00:41:16.809 --> 00:41:19.719
it's there. The eu is looking to take a

833
00:41:19.728 --> 00:41:22.090
position not to do that. We use it here

834
00:41:22.099 --> 00:41:22.860
in the United Kingdom where I'm talking to you from

835
00:41:22.869 --> 00:41:28.239
the London Metropolitan Police loves facial recognition technology um for

836
00:41:28.250 --> 00:41:30.128
reasons that are really bewildering because it doesn't seem to

837
00:41:30.139 --> 00:41:31.398
improve their performance at all, but they insist on

838
00:41:31.409 --> 00:41:37.139
using it. Um Despite parliament asking them repeatedly not

839
00:41:37.148 --> 00:41:37.820
to. But that's what happens when you don't pass

840
00:41:37.829 --> 00:41:40.938
laws making something, you know, banned or controlling

841
00:41:40.949 --> 00:41:43.909
it. You just go, please don't do it

842
00:41:43.918 --> 00:41:45.269
and the police just ignore it. In the US

843
00:41:45.280 --> 00:41:47.340
. We've done a really different approach with that,

844
00:41:47.349 --> 00:41:52.878
which is that certain cities or towns or states have

845
00:41:52.889 --> 00:41:57.429
put into law rules about using it or not using

846
00:41:57.438 --> 00:41:59.260
it and who can use it? Is it the

847
00:41:59.269 --> 00:42:02.918
cops or do you also need to regulate private sector

848
00:42:02.929 --> 00:42:05.489
use? Because one thing you could do is you

849
00:42:05.500 --> 00:42:07.559
could ban the police from using it but allow the

850
00:42:07.570 --> 00:42:08.878
private sector to carry on because remember, we must

851
00:42:09.019 --> 00:42:12.849
upset the private sector in the US. But the

852
00:42:12.860 --> 00:42:15.110
problem is the police can then just work around that

853
00:42:15.139 --> 00:42:17.969
and buy the data or sometimes just get it for

854
00:42:17.978 --> 00:42:20.619
free. But you know why get it for free

855
00:42:20.628 --> 00:42:22.250
when someone can make money off of it. Uh

856
00:42:22.260 --> 00:42:23.969
You can buy the data from a third party data

857
00:42:23.978 --> 00:42:29.128
broker legally. So they're still getting the data and

858
00:42:29.139 --> 00:42:30.280
we see this with Amazon Ring is a great example

859
00:42:30.289 --> 00:42:32.648
of this. Uh people putting all those doorbells up

860
00:42:32.659 --> 00:42:36.228
needing, needing to identify everybody have no idea that

861
00:42:36.239 --> 00:42:37.628
that footage can actually just be taken by the cops

862
00:42:37.639 --> 00:42:39.760
with nothing bumping it. So like well done for

863
00:42:39.769 --> 00:42:43.978
participating in a surveillance society in your neighborhood. Uh

864
00:42:43.989 --> 00:42:45.688
It's just, you know, it's just happening.

865
00:42:45.789 --> 00:42:49.239
So that question sounds like well, so what?

866
00:42:49.250 --> 00:42:51.208
Nothing to hide, nothing to fear. Right.

867
00:42:51.219 --> 00:42:52.820
Like I'm not doing anything wrong. I don't care

868
00:42:52.829 --> 00:42:53.179
if I'm being observed. I hear this all the

869
00:42:53.188 --> 00:42:54.760
time and it's like, ok, cool. But

870
00:42:54.769 --> 00:43:00.000
the problem is that this technology tends to perform better

871
00:43:00.010 --> 00:43:05.719
on men with lighter skin and worst on women with

872
00:43:05.728 --> 00:43:08.519
darker skin. So we've had a number of wrongful

873
00:43:08.530 --> 00:43:10.938
arrests in the United States in which the police have

874
00:43:10.949 --> 00:43:15.199
used facial recognition technology to make arrests like as part

875
00:43:15.208 --> 00:43:17.780
of their arrest process and they have misidentified people who

876
00:43:17.789 --> 00:43:22.469
were innocent. So these people get subject to really

877
00:43:22.478 --> 00:43:23.898
traumatic arrests often in front of their family, they

878
00:43:23.909 --> 00:43:25.550
might be held in custody for, you know,

879
00:43:25.559 --> 00:43:30.110
36 92 hours, something horrific. Um, and

880
00:43:30.119 --> 00:43:30.648
anybody who hasn't, you know, who thinks,

881
00:43:30.659 --> 00:43:32.949
oh, that's not so bad has obviously never been

882
00:43:32.958 --> 00:43:36.269
in a US police custody situation. It's not,

883
00:43:36.280 --> 00:43:38.530
not something you would do voluntarily. Um, no

884
00:43:38.539 --> 00:43:40.469
disrespect to law enforcement. It's just, it's not

885
00:43:40.478 --> 00:43:43.320
, it's not nice to be treated as a suspected

886
00:43:43.329 --> 00:43:47.139
criminal and particularly if you're innocent. And then there's

887
00:43:47.148 --> 00:43:51.269
also the problem that there's no legal requirement in the

888
00:43:51.280 --> 00:43:52.500
United States when you are, you know, when

889
00:43:52.510 --> 00:43:57.039
you've been arrested and brought to trial, you don't

890
00:43:57.050 --> 00:43:59.978
have to be told there's no requirement to protect you

891
00:44:00.409 --> 00:44:04.780
telling you that facial recognition was used in your arrest

892
00:44:06.099 --> 00:44:08.159
, which is really problematic for technology that doesn't work

893
00:44:08.168 --> 00:44:13.510
very well. So that all of that is really

894
00:44:13.519 --> 00:44:15.309
bad, but then people will go. Ok,

895
00:44:15.320 --> 00:44:15.820
cool. So what we have to do to fix

896
00:44:15.829 --> 00:44:19.708
all of those, you know, acknowledge risks.

897
00:44:19.719 --> 00:44:22.340
It's really bad. Let's just pump it full of

898
00:44:22.349 --> 00:44:24.300
more data. Refine, refine, refine and get

899
00:44:24.309 --> 00:44:27.599
to a tool that works. It's never going to

900
00:44:27.610 --> 00:44:30.300
work 100% of the time, but like with high

901
00:44:30.309 --> 00:44:34.019
degree of accuracy, 99% of accuracy. So you're

902
00:44:34.030 --> 00:44:36.769
like, all right, if you solve the accuracy

903
00:44:36.780 --> 00:44:39.458
problem, have you solved the problem of facial recognition

904
00:44:39.929 --> 00:44:44.550
? I personally have argued that you do not why

905
00:44:45.378 --> 00:44:47.458
? Because now you've got your cameras that apparently are

906
00:44:47.469 --> 00:44:52.010
pretty accurate everywhere because and we've seen this um in

907
00:44:52.039 --> 00:44:53.539
the US is a great case in point. It

908
00:44:53.550 --> 00:44:55.489
isn't just the cops who want it. People are

909
00:44:55.500 --> 00:44:58.628
like, well, I I don't feel very confident

910
00:44:58.699 --> 00:45:00.340
we've got high gun crime in the United States or

911
00:45:00.349 --> 00:45:04.570
we're in schools or fill in the blank, whatever

912
00:45:04.579 --> 00:45:07.728
your personal security concerns are, I'm going to get

913
00:45:07.739 --> 00:45:09.250
a camera and put it everywhere. So now imagine

914
00:45:09.260 --> 00:45:13.909
a United States in which private individuals have cameras in

915
00:45:13.918 --> 00:45:16.168
their homes. Every business has cameras, cities get

916
00:45:16.179 --> 00:45:17.168
in on the act because like we got, you

917
00:45:17.179 --> 00:45:21.159
know, we'll do this to fight crime and you

918
00:45:21.168 --> 00:45:25.478
now have it where people are being surveyed nonstop.

919
00:45:25.489 --> 00:45:28.340
You would actually have to almost flip it and say

920
00:45:28.349 --> 00:45:30.869
, where are they not being surveyed? Right?

921
00:45:30.878 --> 00:45:32.938
And where is that data not being kept recorded?

922
00:45:32.949 --> 00:45:37.519
Traded? You know who owns the cameras. So

923
00:45:37.530 --> 00:45:38.110
here in the UK, we have a problem that

924
00:45:38.119 --> 00:45:40.449
a lot of the CCTV cameras that we have all

925
00:45:40.458 --> 00:45:44.550
over this country are very awkwardly sourced from China.

926
00:45:45.260 --> 00:45:46.840
And so a big campaign has gone to rip them

927
00:45:46.849 --> 00:45:51.199
out uh because this is now finally, finally being

928
00:45:51.208 --> 00:45:52.500
deemed to be a security risk. And then the

929
00:45:52.510 --> 00:45:55.119
question becomes ok. So is it the fact that

930
00:45:55.128 --> 00:45:58.978
the camera is made by a Chinese company? Is

931
00:45:58.989 --> 00:46:00.688
that the security risk or is the act of having

932
00:46:00.699 --> 00:46:05.168
these cameras up at all a security risk? Like

933
00:46:05.179 --> 00:46:07.039
, would you feel more comfortable if the camera making

934
00:46:07.050 --> 00:46:09.398
it was a British company? Right? And I

935
00:46:09.409 --> 00:46:13.269
think a lot of people to be completely frank would

936
00:46:13.378 --> 00:46:15.628
they would be fine with that. Um For them

937
00:46:15.639 --> 00:46:15.889
, the issue is, it's a, it's a

938
00:46:15.898 --> 00:46:20.010
known hostile power. I mean, China has been

939
00:46:20.019 --> 00:46:22.530
identified as a great one of the national security risks

940
00:46:22.539 --> 00:46:25.050
to the UK. So you get into these situations

941
00:46:25.059 --> 00:46:30.219
where you can just tell nobody thought this through because

942
00:46:30.860 --> 00:46:31.398
, and you always have to do this. And

943
00:46:31.409 --> 00:46:34.360
again, this is like my historian training, you

944
00:46:34.369 --> 00:46:38.510
have to always imagine whatever system you're building in your

945
00:46:38.519 --> 00:46:45.989
peaceful, liberal democratic happy country being weaponized if somebody

946
00:46:46.000 --> 00:46:49.849
gets elected, who is awful. Now, the

947
00:46:49.860 --> 00:46:51.889
classic example would be like, what if Hitler had

948
00:46:51.898 --> 00:46:52.208
all of this tech, right? But you know

949
00:46:52.219 --> 00:46:54.610
, let's not give that man any more um time

950
00:46:54.619 --> 00:46:58.199
and attention that he's already had. You don't have

951
00:46:58.208 --> 00:46:59.750
to go back to World War Two to look at

952
00:46:59.760 --> 00:47:04.128
examples of countries that have become increasingly um how can

953
00:47:04.139 --> 00:47:06.369
we say this, you know, cracking down on

954
00:47:06.378 --> 00:47:09.110
women's reproductive rights that happened in the United States right

955
00:47:09.119 --> 00:47:10.458
now, right? Like we don't, we don't

956
00:47:10.469 --> 00:47:12.429
have to go to World War Two. We can

957
00:47:12.438 --> 00:47:15.860
literally just open the newspaper today and see that women

958
00:47:15.869 --> 00:47:16.789
who need to get abortions or to go to an

959
00:47:16.800 --> 00:47:20.409
abortion clinic or a reproductive clinic simply to get health

960
00:47:20.418 --> 00:47:23.469
advice are now being criminalized in several US states.

961
00:47:23.559 --> 00:47:27.579
As are the people that help them, their friends

962
00:47:27.590 --> 00:47:30.728
, their mothers, whatever. And that was something

963
00:47:30.739 --> 00:47:31.539
that has always been a threat. But then I

964
00:47:31.550 --> 00:47:34.898
think most people, if you had said before,

965
00:47:34.909 --> 00:47:37.780
Roe versus Wade was, was challenged um successfully.

966
00:47:38.958 --> 00:47:40.958
If you had told them this could be a risk

967
00:47:40.969 --> 00:47:43.260
, they would have looked at you like you were

968
00:47:43.360 --> 00:47:46.289
some crazy feminist. Well, here you are crazy

969
00:47:46.300 --> 00:47:50.579
feminist. It's happened, it's happened. And so

970
00:47:50.590 --> 00:47:53.000
you've got your phone data, all of your internet

971
00:47:53.010 --> 00:47:55.739
data, right? So Facebook has had problems.

972
00:47:55.750 --> 00:47:59.539
Meta has had problems because they've been handing over data

973
00:47:59.570 --> 00:48:01.869
to cops, to arrest women who need to go

974
00:48:01.878 --> 00:48:05.250
and get an abortion. And if you had told

975
00:48:05.260 --> 00:48:07.679
somebody that when Facebook came on the scene in the

976
00:48:07.688 --> 00:48:09.010
mid two thousands, they would not have believed you

977
00:48:09.019 --> 00:48:12.619
. I'm sure that Mark Zuckerberg and his designing crew

978
00:48:12.648 --> 00:48:14.809
never thought that that would be a risk because no

979
00:48:14.820 --> 00:48:17.739
one imagined the US political context changing in that way

980
00:48:19.050 --> 00:48:22.969
. You can imagine it with the Lbgtqi A plus

981
00:48:22.978 --> 00:48:25.668
community which again is constantly under threat, not just

982
00:48:25.679 --> 00:48:29.250
in the US, but like everywhere, in terms

983
00:48:29.260 --> 00:48:30.570
of their right to get married, their right to

984
00:48:30.579 --> 00:48:34.090
adopt, um just their right to not be like

985
00:48:34.099 --> 00:48:37.929
harassed and persecuted on the street. You are now

986
00:48:37.938 --> 00:48:40.030
going to have all of this surveillance equipment that potentially

987
00:48:40.039 --> 00:48:44.519
can be put in the hands of a democratically elected

988
00:48:44.530 --> 00:48:46.909
government that is bad, right? And bad in

989
00:48:46.918 --> 00:48:50.208
the sense of like would prosecute them, persecute them

990
00:48:50.219 --> 00:48:51.398
. And that's, you know, that's my view

991
00:48:51.409 --> 00:48:52.800
. That's bad. I know there's people that would

992
00:48:52.809 --> 00:48:53.829
disagree with that and I don't care. I bet

993
00:48:53.840 --> 00:48:57.969
, I bet that the Center in Florida would love

994
00:48:57.978 --> 00:49:00.599
that. Yeah. No, they absolutely would love

995
00:49:00.610 --> 00:49:01.148
it. They would love it. So, like

996
00:49:01.159 --> 00:49:04.398
, you just, you have to design for that

997
00:49:04.409 --> 00:49:08.320
in mind and that's where like sci fi training and

998
00:49:08.329 --> 00:49:13.079
like a very good, healthy uh background in literature

999
00:49:13.090 --> 00:49:15.840
and cinema can be really helpful because it helps you

1000
00:49:15.849 --> 00:49:21.628
to imagine scenarios that will seem crazy at the time

1001
00:49:21.989 --> 00:49:22.398
and be like, yeah, but what if,

1002
00:49:22.760 --> 00:49:25.199
how many steps away or again, like, and

1003
00:49:25.208 --> 00:49:27.438
that's why one of the chapters in my book is

1004
00:49:27.449 --> 00:49:28.969
, where do you draw the line? I'm like

1005
00:49:28.978 --> 00:49:31.099
, how many steps do you have before your liberal

1006
00:49:31.110 --> 00:49:38.329
democracy turns into like fascism or simply authoritarianism? Or

1007
00:49:38.349 --> 00:49:42.360
like a Christian theocracy or whatever, it doesn't have

1008
00:49:42.369 --> 00:49:43.429
to be Christian. It could be any religion.

1009
00:49:43.438 --> 00:49:46.949
But like that matters and those rights that we have

1010
00:49:46.958 --> 00:49:51.239
in so many liberal democracies are so precious and they

1011
00:49:51.250 --> 00:49:53.469
have been so fought and hard won and they're also

1012
00:49:53.478 --> 00:49:55.860
so easily taken away. And that's where you must

1013
00:49:55.869 --> 00:49:59.079
know your history because if you don't know history,

1014
00:49:59.090 --> 00:50:00.159
someone will say, yeah. But you know,

1015
00:50:00.168 --> 00:50:01.369
you're just worrying about nothing and you need to be

1016
00:50:01.378 --> 00:50:05.119
able to go. No, this has already happened

1017
00:50:05.139 --> 00:50:07.559
or it happened in this way. And actually here

1018
00:50:07.570 --> 00:50:08.800
in this case, we're only, you know,

1019
00:50:08.809 --> 00:50:10.579
it would only take two or three steps for us

1020
00:50:10.590 --> 00:50:14.760
to enter that world. So how do I design

1021
00:50:14.769 --> 00:50:16.079
for that? I mean, a really good strategist

1022
00:50:16.510 --> 00:50:22.478
and a really good technology designer, technology ethicist can't

1023
00:50:22.489 --> 00:50:27.039
simply rely on a technological background. You must have

1024
00:50:27.300 --> 00:50:30.070
the social sciences and you know, liberal arts and

1025
00:50:30.079 --> 00:50:31.648
humanities training as well. I think it's one of

1026
00:50:31.659 --> 00:50:35.110
the toughest jobs to do actually. And that's no

1027
00:50:35.119 --> 00:50:38.469
disrespect to engineering colleagues or more sort of classically trained

1028
00:50:38.719 --> 00:50:43.159
stem colleagues. Their, their work is also extremely

1029
00:50:43.168 --> 00:50:46.418
challenging and difficult. But there there's something especially hard

1030
00:50:46.429 --> 00:50:52.260
about the human component, right? People don't use

1031
00:50:52.269 --> 00:50:54.019
things that necessarily the way they were intended or they

1032
00:50:54.030 --> 00:50:57.989
modify them because again, it's just in our nature

1033
00:50:58.398 --> 00:51:01.099
. So you have to always design with the worst

1034
00:51:01.110 --> 00:51:04.500
in mind. And that means you have to have

1035
00:51:05.349 --> 00:51:08.090
incredible knowledge and a really good imagination and like a

1036
00:51:08.099 --> 00:51:15.469
humility to think about your own blind spots, right

1037
00:51:15.478 --> 00:51:17.969
? Which is why you don't want monocultural teams.

1038
00:51:19.148 --> 00:51:22.199
You have to have people with really different experiences and

1039
00:51:22.208 --> 00:51:24.739
those different views have to be really respected because those

1040
00:51:24.750 --> 00:51:29.688
people will help you see risk that you would just

1041
00:51:29.699 --> 00:51:30.708
miss you. You won't hear it, you won't

1042
00:51:30.719 --> 00:51:32.659
see it. You need somebody else who's like,

1043
00:51:32.668 --> 00:51:36.449
I know what this is like because I am of

1044
00:51:36.458 --> 00:51:37.840
this community or I'm from this country and I saw

1045
00:51:37.849 --> 00:51:40.648
this or my, my country lived through this.

1046
00:51:42.099 --> 00:51:46.519
Um That's, that's a tough one. But uh

1047
00:51:46.530 --> 00:51:51.148
you mentioned uh sci-fi there. Uh And I mean

1048
00:51:51.159 --> 00:51:53.280
, I, I understand all of your arguments but

1049
00:51:53.289 --> 00:51:57.099
II, I have to say that at least to

1050
00:51:57.110 --> 00:52:00.389
some extent and unless I'm un I'm misunderstanding what you're

1051
00:52:00.398 --> 00:52:04.820
saying there about sci fi, I might have some

1052
00:52:04.829 --> 00:52:09.219
issue with people uh real uh looking into or relying

1053
00:52:09.228 --> 00:52:13.019
on. I don't know, something that is portrayed

1054
00:52:13.030 --> 00:52:15.559
in a sci fi movie or sci fi book when

1055
00:52:15.570 --> 00:52:21.938
it comes to uh worrying about the potential dangers of

1056
00:52:21.949 --> 00:52:27.250
technology A I or something like that. Because um

1057
00:52:27.510 --> 00:52:30.090
I mean, for example, if you think that

1058
00:52:30.559 --> 00:52:35.079
uh the things you should be worried about are I

1059
00:52:35.090 --> 00:52:38.610
don't know, a terminator like scenarios or West world

1060
00:52:38.739 --> 00:52:45.389
like scenarios where technology suddenly becomes sentient and develops their

1061
00:52:45.398 --> 00:52:50.228
own uh motives and goals and all of that and

1062
00:52:50.239 --> 00:52:53.349
suddenly wants to wipe out humanity or perhaps, uh

1063
00:52:53.360 --> 00:52:57.728
, the next day we have to be worried about

1064
00:52:57.849 --> 00:53:00.769
, uh, mistreating, uh A I systems because

1065
00:53:00.780 --> 00:53:02.688
they might be sentient and all of that. I

1066
00:53:02.699 --> 00:53:07.478
mean, I just worry that, uh, if

1067
00:53:07.489 --> 00:53:12.878
people take those kinds of scenarios too seriously, they

1068
00:53:12.889 --> 00:53:17.159
might distract, that might help distract them from the

1069
00:53:17.168 --> 00:53:23.030
actual more realistic issues that might derive from technology.

1070
00:53:23.039 --> 00:53:25.320
You know? I mean, do you understand what

1071
00:53:25.329 --> 00:53:29.000
I'm worried about here? I completely understand it.

1072
00:53:29.010 --> 00:53:30.610
And that's been a concern that a lot of people

1073
00:53:30.619 --> 00:53:31.789
have raised in the past couple of months ever since

1074
00:53:31.800 --> 00:53:34.809
people started writing those letters saying we should have a

1075
00:53:34.820 --> 00:53:37.449
pause and A I research and warning of the different

1076
00:53:37.458 --> 00:53:40.849
risks that it presents on an existential societal level.

1077
00:53:42.110 --> 00:53:45.168
And that group of people who are worried about existential

1078
00:53:45.179 --> 00:53:50.228
risks of A I have been accused of worried about

1079
00:53:50.239 --> 00:53:52.519
something that may never happen because it's not really a

1080
00:53:52.530 --> 00:53:54.679
I that they're worried about, they're worried about artificial

1081
00:53:54.688 --> 00:53:59.820
general intelligence, which is a different beast in the

1082
00:53:59.829 --> 00:54:01.570
sense that that's, that's the moment that again,

1083
00:54:01.579 --> 00:54:05.079
it's hypothetical, it has not happened and it may

1084
00:54:05.090 --> 00:54:07.539
never happen. But in theory, it's the moment

1085
00:54:07.550 --> 00:54:12.289
when smart machines become smarter than human beings. I

1086
00:54:12.300 --> 00:54:14.329
love how I said that and the dog just that's

1087
00:54:14.340 --> 00:54:16.739
hilarious. The robot dog, um smart machines,

1088
00:54:16.750 --> 00:54:20.699
when, when these machines become more intelligent than us

1089
00:54:21.119 --> 00:54:22.769
as a species and like, what would they do

1090
00:54:22.780 --> 00:54:24.639
to us is the big fear and there is a

1091
00:54:24.648 --> 00:54:28.349
concern that that's distracting from what I guess you could

1092
00:54:28.360 --> 00:54:30.949
call now. Risks, risks you could have now

1093
00:54:30.958 --> 00:54:36.659
, risks or even near future quite of, you

1094
00:54:36.668 --> 00:54:37.750
know, it's either it's happening now and here is

1095
00:54:37.760 --> 00:54:39.840
, you know, the risk of discrimination in like

1096
00:54:39.849 --> 00:54:42.949
how A I is used in healthcare, how A

1097
00:54:42.958 --> 00:54:44.590
I is used in the medical or sorry, the

1098
00:54:44.599 --> 00:54:47.860
legal profession or risks of misinformation and disinformation in terms

1099
00:54:47.869 --> 00:54:51.789
of elections and journalism and like public confidence in the

1100
00:54:51.800 --> 00:54:55.050
integrity of how the the citizen state relationship works.

1101
00:54:55.429 --> 00:55:00.269
That's all happening or selling your online data, for

1102
00:55:00.429 --> 00:55:01.840
example, selling your online data, gathering your data

1103
00:55:01.849 --> 00:55:04.320
. I mean, like literally a month doesn't go

1104
00:55:04.329 --> 00:55:06.679
by when meta isn't being fined for some sort of

1105
00:55:06.688 --> 00:55:07.489
data violation and they just, you know, they

1106
00:55:07.500 --> 00:55:10.510
just price it in and everybody is there. It's

1107
00:55:10.519 --> 00:55:14.539
incredible to me, but they do. Um So

1108
00:55:14.550 --> 00:55:15.909
that's all happening now and then you're right to identify

1109
00:55:15.918 --> 00:55:17.840
like near term risks, which is like we're not

1110
00:55:17.849 --> 00:55:22.110
quite there as a risk. Perhaps a good example

1111
00:55:22.119 --> 00:55:23.478
, perhaps a good example of that would be certain

1112
00:55:23.489 --> 00:55:29.168
genetic engineering technologies. I mean, we're not really

1113
00:55:29.179 --> 00:55:31.619
there yet, but it's probably in the near future

1114
00:55:31.628 --> 00:55:35.219
. So yeah, you could come up with,

1115
00:55:35.228 --> 00:55:37.590
I'm sure a number of different categories to kind of

1116
00:55:37.599 --> 00:55:39.168
like, you know, make columns if you will

1117
00:55:39.179 --> 00:55:40.949
. So definitely need to worry about this now because

1118
00:55:40.958 --> 00:55:45.010
it's already happening likely to happen soon, but we're

1119
00:55:45.019 --> 00:55:45.969
not there yet. And here's the conditions that we

1120
00:55:45.978 --> 00:55:50.119
would have to fulfill to get there versus like may

1121
00:55:50.128 --> 00:55:52.849
never happen. But if they did call them low

1122
00:55:52.860 --> 00:55:57.969
probability, high impact events, um egag I takes

1123
00:55:57.978 --> 00:55:59.909
over um and what will they do to us and

1124
00:55:59.918 --> 00:56:04.148
turn us into slaves or something? So, you

1125
00:56:04.159 --> 00:56:06.398
know, is that distracting is your question? I

1126
00:56:06.409 --> 00:56:07.719
think, I don't know. First of all,

1127
00:56:07.728 --> 00:56:08.760
I don't think that you're going to get, I

1128
00:56:08.769 --> 00:56:10.958
don't think it's like helpful to tell people not to

1129
00:56:10.969 --> 00:56:13.739
think about something because they're going to think about it

1130
00:56:13.820 --> 00:56:14.719
. It's like, you know, that, that

1131
00:56:14.728 --> 00:56:16.519
experiment of don't think of the white polar bear.

1132
00:56:16.530 --> 00:56:17.760
You know, as I'm telling you to do this

1133
00:56:17.769 --> 00:56:20.360
, your brain is like all I can think of

1134
00:56:20.369 --> 00:56:22.409
is a white polar bear. So I think,

1135
00:56:22.418 --> 00:56:23.958
I think first of all, it's actually probably I'm

1136
00:56:23.969 --> 00:56:27.840
not the cognitive psychologist, but my guess would be

1137
00:56:28.039 --> 00:56:30.489
the easiest thing to do is actually to name it

1138
00:56:30.289 --> 00:56:32.010
. Like do what we just did be like,

1139
00:56:32.019 --> 00:56:35.050
there's these different types of risks. The one that

1140
00:56:35.059 --> 00:56:37.239
the media really loves to go for is the one

1141
00:56:37.250 --> 00:56:38.829
that's actually the least likely why do they like to

1142
00:56:38.840 --> 00:56:42.708
go for it? Because it's great storytelling. We've

1143
00:56:42.719 --> 00:56:45.889
actually, we've literally seen this movie before. So

1144
00:56:45.070 --> 00:56:46.559
I talk with clients a lot and I've got a

1145
00:56:46.570 --> 00:56:50.179
presentation that I've been using the past couple of months

1146
00:56:50.188 --> 00:56:52.239
that it is really like driven people wild in a

1147
00:56:52.250 --> 00:56:54.659
good way that is looking at cinema and we talk

1148
00:56:54.668 --> 00:56:58.438
about the different ways that A I appears in cinema

1149
00:56:58.449 --> 00:57:01.789
over time and it's so effective because you have,

1150
00:57:01.800 --> 00:57:05.090
you can't have a conversation about A I without naming

1151
00:57:05.099 --> 00:57:07.239
Terminator, you just can't. So I make it

1152
00:57:07.250 --> 00:57:07.789
the first slide. I'm like, let's, let's

1153
00:57:07.800 --> 00:57:12.309
name it, let's dismantle it and deconstruct it like

1154
00:57:12.320 --> 00:57:14.019
a bomb, you know, take it apart and

1155
00:57:14.030 --> 00:57:15.728
neutralize it if you will and then talk about why

1156
00:57:15.739 --> 00:57:17.728
it's so resonant. Everybody has a really good laugh

1157
00:57:17.739 --> 00:57:20.369
and this kind of like looks around like, you

1158
00:57:20.378 --> 00:57:21.648
know, I'm not the only one who thinks about

1159
00:57:21.659 --> 00:57:23.050
Terminator. No, we all think about Terminator.

1160
00:57:23.059 --> 00:57:25.530
Why is that? And then you move on,

1161
00:57:25.539 --> 00:57:28.429
you would maybe talk about the matrix, you might

1162
00:57:28.438 --> 00:57:31.349
talk about Blade Runner. Um You can talk about

1163
00:57:31.360 --> 00:57:34.050
Westworld, you could talk about black mirror, right

1164
00:57:34.059 --> 00:57:35.550
? So you go through all the different things that

1165
00:57:35.559 --> 00:57:37.199
are in popular culture and you also look at the

1166
00:57:37.208 --> 00:57:39.860
imagery, right? So it's not just the story

1167
00:57:40.079 --> 00:57:43.228
, it's the picture. So like the Terminator,

1168
00:57:43.239 --> 00:57:45.418
what's quite terrifying about the Terminator is he's both human

1169
00:57:45.840 --> 00:57:47.878
. Uh although he's like a superman, she's,

1170
00:57:47.889 --> 00:57:51.918
it's Arnold Schwarzenegger, but he's also when he like

1171
00:57:51.929 --> 00:57:53.280
rips off all of his fleshy bits. He is

1172
00:57:53.289 --> 00:57:57.119
made the designer who is very cleverly in the movie

1173
00:57:57.128 --> 00:58:00.429
, made it to look like a human technological skeleton

1174
00:58:00.438 --> 00:58:02.208
. So it's like a metal head. It's literally

1175
00:58:02.219 --> 00:58:05.329
a metal skull and it has teeth, like it

1176
00:58:05.340 --> 00:58:07.168
has actual human teeth and you're like, why,

1177
00:58:07.179 --> 00:58:07.530
like, why does it need human teeth? It's

1178
00:58:07.539 --> 00:58:09.550
a robot. It does not need. So what

1179
00:58:09.559 --> 00:58:12.648
is that about? And the reason is because it's

1180
00:58:12.659 --> 00:58:15.079
terrifying, right? It's really scary. If you

1181
00:58:15.090 --> 00:58:15.280
saw that when you were a kid, you were

1182
00:58:15.289 --> 00:58:19.239
like unable to not ever see it again. So

1183
00:58:19.250 --> 00:58:20.909
you have to think about why that is or like

1184
00:58:20.918 --> 00:58:22.409
the image of um like a human hand kind of

1185
00:58:22.418 --> 00:58:24.239
going like that to another human hand. And it's

1186
00:58:24.250 --> 00:58:29.579
, it's, it's riffing off of Michelangelo's Sistine chapel

1187
00:58:29.590 --> 00:58:31.949
, right of God touching Adam and giving the spark

1188
00:58:31.958 --> 00:58:36.289
of life. And you'll see that, that image

1189
00:58:36.300 --> 00:58:37.329
a lot when we talk about A I because it's

1190
00:58:37.340 --> 00:58:42.659
a really useful shorthand visually for us to think about

1191
00:58:42.668 --> 00:58:45.079
, you know, God God, something that people

1192
00:58:45.090 --> 00:58:47.989
call like God in the judeo-christian sense with that picture

1193
00:58:49.000 --> 00:58:52.159
created humans. And so then they'll riff on it

1194
00:58:52.168 --> 00:58:54.360
and you'll see another image of a human hand touching

1195
00:58:54.369 --> 00:58:57.590
a robot finger, right? Like it's going like

1196
00:58:57.599 --> 00:59:00.250
that. And then in this case, humans have

1197
00:59:00.260 --> 00:59:02.949
become God and the robot is our creation. And

1198
00:59:02.958 --> 00:59:06.918
that taps into one of the best science fiction films

1199
00:59:06.929 --> 00:59:07.969
of all time or movies or books around of all

1200
00:59:07.978 --> 00:59:10.110
time, which is of course, Mary Shelley's Frankenstein

1201
00:59:10.530 --> 00:59:12.989
, like this idea that you can, you can

1202
00:59:13.000 --> 00:59:14.530
create it and then it goes rogue and it's a

1203
00:59:14.539 --> 00:59:19.739
fascinating piece of literature uh that I think captured something

1204
00:59:19.989 --> 00:59:22.750
in, again humans because we create things all the

1205
00:59:22.760 --> 00:59:23.780
time and it's this sort of primal fear of what

1206
00:59:23.789 --> 00:59:27.360
happens when our creations come back and like kill us

1207
00:59:27.369 --> 00:59:29.679
, which probably actually is about like parents with their

1208
00:59:29.688 --> 00:59:32.418
Children, right? Like it's in a really demented

1209
00:59:32.429 --> 00:59:35.699
way. But I'm talking, I'm talking subconscious stuff

1210
00:59:35.708 --> 00:59:37.398
, right? Stuff that works across all societies that

1211
00:59:37.409 --> 00:59:40.978
there's that fear of your creation getting out of control

1212
00:59:40.989 --> 00:59:44.570
because that, that's a narrative that we know we

1213
00:59:44.579 --> 00:59:47.619
recognize it uh across time. So you have to

1214
00:59:47.628 --> 00:59:51.949
, I think you actually, it's a wasted amount

1215
00:59:51.958 --> 00:59:53.688
of energy to tell people don't think about these things

1216
00:59:53.699 --> 00:59:57.300
. It's distracting. I think it's actually more effective

1217
00:59:57.309 --> 00:59:59.800
to think about it right up front. Name it

1218
00:60:00.070 --> 00:60:02.780
have a chat together, build everybody's critical thinking and

1219
00:60:02.789 --> 00:60:05.878
images on the news. Whenever you talk about A

1220
00:60:05.889 --> 00:60:07.619
I, I do a lot of work with the

1221
00:60:07.628 --> 00:60:08.199
media. When I go on television, it will

1222
00:60:08.208 --> 00:60:10.030
be a split screen. It will be me talking

1223
00:60:10.039 --> 00:60:12.438
about A I with a bunch of books in the

1224
00:60:12.449 --> 00:60:15.478
background, hopefully saying intelligent things and then the images

1225
00:60:15.489 --> 00:60:16.449
that they put on the other side of the screen

1226
00:60:16.458 --> 00:60:21.878
to illustrate A I are like on drugs, they're

1227
00:60:21.889 --> 00:60:25.269
like hallucinatory acid trips. It'll be like it'll be

1228
00:60:25.280 --> 00:60:28.918
like a light sort of floating. You know,

1229
00:60:28.929 --> 00:60:30.918
like when people say they, they almost die and

1230
00:60:30.929 --> 00:60:31.409
they have like a near death experience, they're in

1231
00:60:31.418 --> 00:60:34.539
a, they're in a white tunnel going towards the

1232
00:60:34.550 --> 00:60:37.409
light, they'll show something like that, then they'll

1233
00:60:37.418 --> 00:60:40.679
show like a video game graphic of a human head

1234
00:60:40.688 --> 00:60:45.050
from the neck up. That's completely translucent. You

1235
00:60:45.059 --> 00:60:45.878
can see right through it. And inside is a

1236
00:60:45.889 --> 00:60:52.239
human brain glowing orange and it's like rotating around and

1237
00:60:52.250 --> 00:60:53.320
it's like floating on a magic carpet, like a

1238
00:60:53.329 --> 00:60:55.878
video game version of a magic carpet. Why?

1239
00:60:55.938 --> 00:61:00.340
Because I'm assuming it's because they're like, oh if

1240
00:61:00.349 --> 00:61:01.628
we're talking about artificial intelligence, we have to show

1241
00:61:01.639 --> 00:61:02.958
what do we think of intelligence, you think of

1242
00:61:02.969 --> 00:61:06.590
a brain? So we'll show the, we'll show

1243
00:61:06.599 --> 00:61:08.969
the viewers a brain but like a like a sci

1244
00:61:08.978 --> 00:61:10.429
fi version of a brain. It's not like an

1245
00:61:10.438 --> 00:61:13.429
actual brain because an actual brain is a bit gross

1246
00:61:13.438 --> 00:61:16.708
, right? It's sort of the biological wet thing

1247
00:61:16.739 --> 00:61:21.280
. So they show you instead an abstraction of a

1248
00:61:21.289 --> 00:61:23.228
brain and then they might show the finger image,

1249
00:61:23.239 --> 00:61:25.418
right? Like they, they riff on weird stuff

1250
00:61:25.429 --> 00:61:28.168
and once you see this or you'll see like lots

1251
00:61:28.179 --> 00:61:30.648
of zeros and ones raining down, right? Like

1252
00:61:30.659 --> 00:61:32.559
in the matrix. And there's a reason for that

1253
00:61:32.570 --> 00:61:35.619
. They're not, this is not an accident.

1254
00:61:35.659 --> 00:61:39.280
These things are highly iconic images from the films and

1255
00:61:39.289 --> 00:61:40.708
shows that we've all seen. So they become a

1256
00:61:40.719 --> 00:61:45.409
visual shorthand. So you can't, I just think

1257
00:61:45.418 --> 00:61:47.590
you can't ignore this stuff. I think you actually

1258
00:61:47.599 --> 00:61:51.378
have to go right at it straight at it.

1259
00:61:51.389 --> 00:61:54.280
Discuss it and then you can if you want per

1260
00:61:54.289 --> 00:61:58.619
it and go, let's actually look at the stuff

1261
00:61:58.628 --> 00:62:00.949
that is perhaps less visually sexy, right? Less

1262
00:62:00.958 --> 00:62:06.438
visually interesting to show which is going to be predictive

1263
00:62:06.449 --> 00:62:10.619
policing algorithms, facial recognition, technology discrimination. Um

1264
00:62:10.628 --> 00:62:14.269
banks using A I to decide if you can get

1265
00:62:14.280 --> 00:62:15.750
a mortgage or not. Right? Like that,

1266
00:62:15.860 --> 00:62:20.280
that is less sci-fi sexy. It's less scary,

1267
00:62:20.329 --> 00:62:24.918
but it's actually most people's experience of A I.

1268
00:62:25.429 --> 00:62:30.840
So that's fascinating. Most people don't realize how A

1269
00:62:30.849 --> 00:62:34.469
I is already being used on them, right?

1270
00:62:34.478 --> 00:62:37.219
Like I think they would be appalled if they did

1271
00:62:37.309 --> 00:62:40.168
. So that's, I think the media's challenge and

1272
00:62:40.179 --> 00:62:43.309
the challenge of writers and analysts and people are trying

1273
00:62:43.320 --> 00:62:45.949
to educate the public is like you're going to need

1274
00:62:45.958 --> 00:62:52.628
a visual iconography if you will a visual language and

1275
00:62:52.639 --> 00:62:54.409
you're going to need a narrative language for storytelling that

1276
00:62:54.418 --> 00:62:58.409
makes those real risks, risks that are right now

1277
00:62:59.280 --> 00:63:05.340
as compelling as the ones that are more hypothetical,

1278
00:63:05.349 --> 00:63:07.760
but that we've all been seeing in shows and movies

1279
00:63:07.769 --> 00:63:08.679
for decades now. Right? So it's a,

1280
00:63:08.688 --> 00:63:13.909
again, so many things with technology are actually about

1281
00:63:13.918 --> 00:63:16.000
culture, right? They're about the human relationship with

1282
00:63:16.010 --> 00:63:21.128
technology. So like getting people involved and caring about

1283
00:63:21.139 --> 00:63:22.668
something like A I which, you know, we're

1284
00:63:22.679 --> 00:63:23.679
in a cost of living crisis here in the UK

1285
00:63:23.688 --> 00:63:25.719
, good luck going out onto the streets of Brazil

1286
00:63:25.860 --> 00:63:29.059
. I guess the Portugal getting people to care,

1287
00:63:29.639 --> 00:63:32.110
I guess that across the entire room we're living through

1288
00:63:32.119 --> 00:63:35.989
a cost of living crisis. Yeah. Right.

1289
00:63:36.000 --> 00:63:36.989
So, if you're like, you know, do

1290
00:63:37.000 --> 00:63:37.369
you want to have this chat? People are like

1291
00:63:37.378 --> 00:63:38.898
, no, because I'm too busy, like,

1292
00:63:38.909 --> 00:63:42.849
dealing with massive inflation or, like very high interest

1293
00:63:42.860 --> 00:63:45.260
rates or unemployment or climate change, like, you

1294
00:63:45.269 --> 00:63:46.099
know, half of Europe as we were just discussing

1295
00:63:46.250 --> 00:63:51.458
under a massive heat dome and sweltering away. So

1296
00:63:51.699 --> 00:63:53.530
, getting them to think about A I is tricky

1297
00:63:53.539 --> 00:63:54.840
. So you have to help them, you have

1298
00:63:54.849 --> 00:63:58.260
to make that really easy for them to do.

1299
00:63:58.929 --> 00:64:00.829
And so that's where I really enjoy this kind of

1300
00:64:00.840 --> 00:64:02.590
work because I've noticed the effect that it has on

1301
00:64:02.599 --> 00:64:04.639
people when you take them through some of the concepts

1302
00:64:04.648 --> 00:64:06.570
that we've just been discussing is they're like, oh

1303
00:64:06.579 --> 00:64:09.860
my God, I see this everywhere. Now I

1304
00:64:09.869 --> 00:64:12.869
see those images everywhere. I see. The media

1305
00:64:12.878 --> 00:64:15.550
loves to go to some stories and then not to

1306
00:64:15.559 --> 00:64:17.099
others. Why is that? You have to look

1307
00:64:17.110 --> 00:64:20.110
at their incentive structure. What do they get measured

1308
00:64:20.119 --> 00:64:24.610
on clicks, viewing figures, et cetera. So

1309
00:64:24.619 --> 00:64:27.059
the scarier they can make the story. So why

1310
00:64:27.070 --> 00:64:29.809
any time Elon Musk does everything, the media loves

1311
00:64:29.820 --> 00:64:31.449
it because it's, he's there in some sort of

1312
00:64:31.458 --> 00:64:34.090
symbiotic relationship, right? He says something outrageous,

1313
00:64:34.099 --> 00:64:35.780
they cover it and go, isn't it outrageous?

1314
00:64:35.789 --> 00:64:38.250
He then is like, I hate the press,

1315
00:64:38.378 --> 00:64:42.648
you know, the world weirdest dysfunctional relationship ever.

1316
00:64:42.860 --> 00:64:45.168
But people who are doing like really important work on

1317
00:64:45.179 --> 00:64:48.570
A I are not getting that kind of media coverage

1318
00:64:49.090 --> 00:64:51.072
, right? And they maybe don't talk the way

1319
00:64:51.083 --> 00:64:54.731
that Elon Musk talks, they won't give examples or

1320
00:64:54.742 --> 00:64:57.211
say things that are really outrageous to get attention.

1321
00:64:57.242 --> 00:65:01.862
If you're a really measured, considered scientist or researcher

1322
00:65:02.032 --> 00:65:04.242
, you're not going to say something that's very Clickbait

1323
00:65:05.182 --> 00:65:08.211
. Yeah. And by the way, since you

1324
00:65:08.222 --> 00:65:10.541
mentioned that, let's talk a little bit more about

1325
00:65:10.552 --> 00:65:15.552
social media because it's not only the misinformation issue but

1326
00:65:15.561 --> 00:65:19.726
also in terms of these discussions surrounding the supposed neutrality

1327
00:65:19.735 --> 00:65:23.105
of technology. I mean, if you just look

1328
00:65:23.114 --> 00:65:26.956
at social media, it's ply obvious that there's no

1329
00:65:26.965 --> 00:65:30.135
neutrality there at all because I, I mean,

1330
00:65:30.144 --> 00:65:33.295
even what you get mostly exposed to, it's just

1331
00:65:33.456 --> 00:65:39.594
what they decide to boost to get more views,

1332
00:65:39.605 --> 00:65:43.965
clicks, likes whatever and usually it's the most outrageous

1333
00:65:43.976 --> 00:65:48.809
stuff out there, right? And lies. I

1334
00:65:48.820 --> 00:65:51.260
mean, there's fascinating research about how lies spread much

1335
00:65:51.269 --> 00:65:56.289
faster than facts on the internet and like, yeah

1336
00:65:56.340 --> 00:65:57.860
, now we're in this world where so much of

1337
00:65:57.869 --> 00:66:00.889
it can be faked. Um not just imagery and

1338
00:66:00.898 --> 00:66:03.070
video footage but sound audio. So you're going to

1339
00:66:03.079 --> 00:66:04.429
have this thing where people are going to find it

1340
00:66:04.438 --> 00:66:06.849
very, very difficult to know what is real and

1341
00:66:06.860 --> 00:66:11.280
not real. I don't know, I sometimes think

1342
00:66:11.289 --> 00:66:13.909
that we may be approaching if not the end of

1343
00:66:13.918 --> 00:66:16.860
social media, it definitely a new phase. Um

1344
00:66:17.898 --> 00:66:20.369
Are, you know, do people do people really

1345
00:66:20.378 --> 00:66:24.530
want to go online and see their friends talking about

1346
00:66:24.539 --> 00:66:27.590
holidays and babies and lunch, which was a lot

1347
00:66:27.599 --> 00:66:30.269
of how social media was from the mid two thousands

1348
00:66:30.280 --> 00:66:32.500
onward. And now it seems to be kind of

1349
00:66:32.510 --> 00:66:36.668
invaded by content creators, you know, influencers and

1350
00:66:36.679 --> 00:66:39.559
the like, and then if you start feeling like

1351
00:66:39.570 --> 00:66:40.550
, oh my God, if I go on,

1352
00:66:40.559 --> 00:66:43.539
it's actually manipulating me, that's not good either.

1353
00:66:43.550 --> 00:66:45.179
And there's all the mental health research of, you

1354
00:66:45.188 --> 00:66:45.829
know, lots of people who spend time on social

1355
00:66:45.840 --> 00:66:49.329
media end up feeling really depressed or anxious. Um

1356
00:66:49.449 --> 00:66:51.309
, and it can feel really toxic for many,

1357
00:66:51.320 --> 00:66:54.510
many people just to go on. It could be

1358
00:66:54.719 --> 00:66:57.789
awful. I just wonder, I don't know.

1359
00:66:57.800 --> 00:67:00.168
I'm, I'm thinking aloud here, but I do

1360
00:67:00.179 --> 00:67:01.269
wonder if there's just going to be a bunch of

1361
00:67:01.280 --> 00:67:04.639
people for whom this start to just feel really irrelevant

1362
00:67:04.648 --> 00:67:08.228
because it's kind of like, I don't know the

1363
00:67:08.239 --> 00:67:10.398
way that television, I just came back from the

1364
00:67:10.409 --> 00:67:13.510
US and I'm always just stunned by American television.

1365
00:67:13.519 --> 00:67:16.269
Now, the amount of advertising that you are just

1366
00:67:16.280 --> 00:67:18.159
bombarded with and it's, you know, if you're

1367
00:67:18.168 --> 00:67:19.829
not used to it, if you are in a

1368
00:67:19.840 --> 00:67:21.550
country where you don't have a lot of advertising in

1369
00:67:21.559 --> 00:67:24.489
your TV, you just kind of look at your

1370
00:67:24.500 --> 00:67:26.418
American family and friends and you're like, you're just

1371
00:67:26.429 --> 00:67:29.378
being like brainwashed with all of this all the time

1372
00:67:29.510 --> 00:67:31.054
and that's how social media feels like my Twitter feed

1373
00:67:31.063 --> 00:67:33.293
feed. Since Elon Musk took over, it's just

1374
00:67:33.375 --> 00:67:35.554
full of, no, but since you talk about

1375
00:67:35.563 --> 00:67:39.083
that, about American television, let me just tell

1376
00:67:39.094 --> 00:67:42.724
you that I'm a wrestling fan and so I watch

1377
00:67:42.735 --> 00:67:45.885
wrestling mostly from the US, of course, because

1378
00:67:45.894 --> 00:67:48.128
it's the, the biggest place for wrestling in the

1379
00:67:48.139 --> 00:67:49.570
world. But, uh, I mean, I

1380
00:67:49.579 --> 00:67:53.469
, I really notice that, uh, if you

1381
00:67:53.478 --> 00:67:57.489
watched wrestling, like, 20 years ago you would

1382
00:67:57.500 --> 00:68:00.878
have the matches and then a few breaks with advertisements

1383
00:68:00.889 --> 00:68:02.688
and all of that. But, but now you

1384
00:68:02.699 --> 00:68:06.668
get split screens where there's, uh, uh,

1385
00:68:06.679 --> 00:68:11.219
a tiny window with the match and then next,

1386
00:68:11.228 --> 00:68:14.760
with the advertisement. And I'm like, oh man

1387
00:68:14.769 --> 00:68:15.779
, I want to watch the match. I don't

1388
00:68:15.789 --> 00:68:19.208
care about pizzas and burgers and whatever. Let me

1389
00:68:19.220 --> 00:68:21.659
change. I thought when I go to the cinema

1390
00:68:21.668 --> 00:68:23.759
and it's like, I'm just here to see the

1391
00:68:23.770 --> 00:68:25.668
movie and ideally the previews and I feel like I

1392
00:68:25.680 --> 00:68:27.789
pay quite a lot to go to the cinema and

1393
00:68:27.798 --> 00:68:29.289
then you have to sit through, you know,

1394
00:68:29.298 --> 00:68:30.479
20 minutes of adverts, but then you work it

1395
00:68:30.489 --> 00:68:32.628
out and so you just show up later, right

1396
00:68:32.640 --> 00:68:33.699
? So if you want, there's ways, there's

1397
00:68:33.708 --> 00:68:35.899
always ways of hacking, there's probably some way of

1398
00:68:35.909 --> 00:68:40.509
like hacking your wrestling channel to only see the WS

1399
00:68:40.649 --> 00:68:43.028
about the ads. But I just, I guess

1400
00:68:43.038 --> 00:68:45.238
I'm just saying that I feel like these things evolve

1401
00:68:45.248 --> 00:68:46.837
and like social media for a while clearly had some

1402
00:68:46.849 --> 00:68:49.998
sort of utility. It helps people feel connected clearly

1403
00:68:50.429 --> 00:68:54.970
. But then it started to have, what would

1404
00:68:54.979 --> 00:68:58.918
you call it if it's not utility? I was

1405
00:68:58.930 --> 00:69:00.319
gonna say negative utility. But, you know,

1406
00:69:00.329 --> 00:69:02.759
again, like, it has a cost to it

1407
00:69:03.259 --> 00:69:05.319
and I guess you're constantly weighing up in life.

1408
00:69:05.329 --> 00:69:08.500
Is the pain worth the pleasure. Right. Like

1409
00:69:08.509 --> 00:69:09.930
, is it, is it full? And I

1410
00:69:09.939 --> 00:69:12.628
just think for a lot of people, I mean

1411
00:69:12.640 --> 00:69:14.890
, I've heard constantly is this the end of Twitter

1412
00:69:14.899 --> 00:69:15.338
? And like, I'm very mixed because I use

1413
00:69:15.350 --> 00:69:17.168
Twitter for instance, for my work quite a lot

1414
00:69:17.180 --> 00:69:18.418
. But part of me was like, maybe the

1415
00:69:18.430 --> 00:69:20.390
best thing that could happen to me is that Twitter

1416
00:69:20.399 --> 00:69:25.310
, like, failed and tried because I'm not on

1417
00:69:25.319 --> 00:69:27.548
other than linkedin, I'm not on any other social

1418
00:69:27.560 --> 00:69:29.789
media channel. I managed to like, break all

1419
00:69:29.798 --> 00:69:32.109
of those addictions and habits from my youth. Um

1420
00:69:32.119 --> 00:69:34.079
, Twitter is like the last holdout and in a

1421
00:69:34.088 --> 00:69:36.520
way it would just do me a huge favor if

1422
00:69:36.529 --> 00:69:39.457
it just wasn't even an option, which is a

1423
00:69:39.469 --> 00:69:42.038
really, that, that's a weird feeling to have

1424
00:69:42.047 --> 00:69:43.587
. On the one hand, I miss the old

1425
00:69:43.599 --> 00:69:44.979
days of Twitter because I had a lot of fun

1426
00:69:44.988 --> 00:69:45.828
. I made amazing contacts and friends on it and

1427
00:69:45.837 --> 00:69:47.559
it was really helpful to me for my work.

1428
00:69:47.729 --> 00:69:49.719
But I do feel that it's, it's just,

1429
00:69:49.729 --> 00:69:51.438
it's not a very nice place. It's like going

1430
00:69:51.448 --> 00:69:55.680
into, I was in Frankfurt airport a couple of

1431
00:69:55.689 --> 00:69:58.048
weeks ago and they have like an old fashioned smoking

1432
00:69:58.060 --> 00:70:00.930
lounge in the airport and it's like a glass cage

1433
00:70:00.939 --> 00:70:03.359
for smokers. And if you're a non smoker,

1434
00:70:03.369 --> 00:70:05.409
which I am you're walking by, you see all

1435
00:70:05.418 --> 00:70:09.020
these people in, you know what looks basically like

1436
00:70:09.029 --> 00:70:13.208
a cancer room. You know, they all smoking

1437
00:70:13.798 --> 00:70:15.359
and like, you just look at them and you're

1438
00:70:15.369 --> 00:70:18.979
like, my God, it's expensive. It's dangerous

1439
00:70:18.989 --> 00:70:20.640
. It's stinky. Like you, you're going to

1440
00:70:20.649 --> 00:70:24.509
come out of there. Absolutely reeking. It's a

1441
00:70:24.770 --> 00:70:26.869
, but the, but like the compassion kicks in

1442
00:70:26.878 --> 00:70:29.579
because it's one of the hardest addictions to kick.

1443
00:70:30.029 --> 00:70:32.149
But, but rarely do you see it that way

1444
00:70:32.159 --> 00:70:35.029
? And I kind of wonder if we're getting to

1445
00:70:35.039 --> 00:70:38.430
the point where, where some people can either see

1446
00:70:38.439 --> 00:70:42.109
themselves in the social media equivalent of the smoking lounge

1447
00:70:42.119 --> 00:70:44.668
in Frankfurt Airport and be like, why are you

1448
00:70:44.680 --> 00:70:46.588
doing this to yourself? Like if these things make

1449
00:70:46.600 --> 00:70:49.029
you feel so bad, why do you go on

1450
00:70:49.039 --> 00:70:51.439
them if you feel the news is unreliable or you

1451
00:70:51.449 --> 00:70:55.168
just get shouted out by crazy people you've never met

1452
00:70:55.180 --> 00:70:57.430
? Why are you signing up for an emotional beating

1453
00:70:57.439 --> 00:70:59.810
? Like there's other ways to get your news that

1454
00:70:59.819 --> 00:71:01.958
are probably more reliable and that don't involve that.

1455
00:71:02.310 --> 00:71:04.409
So, you know, all of us I think

1456
00:71:04.418 --> 00:71:06.509
are going to have a real and probably are already

1457
00:71:06.520 --> 00:71:10.350
having, um, a sort of reckoning with a

1458
00:71:10.359 --> 00:71:12.310
new relationship. And I think that could be a

1459
00:71:12.319 --> 00:71:15.220
real challenge for the social media companies is if you

1460
00:71:15.229 --> 00:71:15.789
just got a mass movement of people who were like

1461
00:71:15.798 --> 00:71:17.649
, you know what, this isn't worth it anymore

1462
00:71:18.430 --> 00:71:21.810
. Yeah, that's hard. But by the way

1463
00:71:21.819 --> 00:71:27.140
, uh related to that about collecting data online and

1464
00:71:27.149 --> 00:71:30.329
selling people's data because there are people out there that

1465
00:71:30.338 --> 00:71:33.878
are perhaps still not sold on this idea that they

1466
00:71:33.890 --> 00:71:38.000
should care about this because they're just like, oh

1467
00:71:38.009 --> 00:71:40.289
, come on, I go on the internet and

1468
00:71:40.298 --> 00:71:43.208
I go on Facebook and just, uh, see

1469
00:71:43.319 --> 00:71:46.189
some of the news and uh share a few silly

1470
00:71:46.199 --> 00:71:48.890
stuff. I mean, uh stuff related to my

1471
00:71:48.899 --> 00:71:51.859
vacation or something like that, my kids and perhaps

1472
00:71:51.869 --> 00:71:56.729
I watch some vanilla porn and go on Amazon and

1473
00:71:56.739 --> 00:71:59.259
buy some stuff. I mean, what, what's

1474
00:71:59.270 --> 00:72:01.878
the big deal with their collecting that, that date

1475
00:72:01.890 --> 00:72:04.409
, uh uh uh the, the, the update

1476
00:72:04.418 --> 00:72:08.918
and then selling it to other people? I mean

1477
00:72:08.930 --> 00:72:13.878
, I'm not doing anything bad than with the I

1478
00:72:13.890 --> 00:72:17.640
, I'm not overwhelmed on the internet with ads that

1479
00:72:17.649 --> 00:72:21.298
I don't really care about because they're also catering to

1480
00:72:21.529 --> 00:72:24.838
the things that, that I tend to like.

1481
00:72:24.850 --> 00:72:28.909
So what's the big deal there? So there's so

1482
00:72:28.918 --> 00:72:31.390
many ways we could tackle that. I guess one

1483
00:72:31.399 --> 00:72:33.069
that I would start out with is like, can

1484
00:72:33.079 --> 00:72:38.208
they imagine like, can they literally conceive of a

1485
00:72:38.229 --> 00:72:41.298
world in which they aren't having all of their data

1486
00:72:41.310 --> 00:72:43.720
gathered? Because like, that's an option, right

1487
00:72:43.729 --> 00:72:45.770
? That's a design choice. That we've all made

1488
00:72:45.779 --> 00:72:47.739
, we could have a world in which you can't

1489
00:72:47.789 --> 00:72:51.560
track me from site to site to site or which

1490
00:72:51.569 --> 00:72:54.680
third party brokers aren't, are like, just not

1491
00:72:54.689 --> 00:72:57.500
allowed to exist much less traffic in our data for

1492
00:72:57.509 --> 00:73:00.350
profit. Um And it's true like I struggle with

1493
00:73:00.359 --> 00:73:02.600
this because I think most people have just priced in

1494
00:73:02.750 --> 00:73:05.649
that they're going to have their data involved in a

1495
00:73:05.659 --> 00:73:11.569
data hack or leak at some point. And like

1496
00:73:11.579 --> 00:73:13.560
, what's the worst that happens to them is maybe

1497
00:73:13.569 --> 00:73:15.140
a little bit of casual identity theft, perhaps a

1498
00:73:15.149 --> 00:73:18.029
bit of fraud, uh which hopefully their banks will

1499
00:73:18.039 --> 00:73:19.949
cover, right? So if you look at where

1500
00:73:19.958 --> 00:73:24.220
the incentives are to care about this, I don't

1501
00:73:24.229 --> 00:73:26.829
know how much it is on the individual banks care

1502
00:73:26.838 --> 00:73:29.699
about it because they want to stop fraud. Um

1503
00:73:29.989 --> 00:73:31.369
Governments care about it because they also need to stop

1504
00:73:31.378 --> 00:73:34.548
identity fraud for all sorts of security reasons. But

1505
00:73:34.560 --> 00:73:38.930
like do individuals care and I I'm with you.

1506
00:73:38.939 --> 00:73:40.779
I think the example that you just gave of the

1507
00:73:40.789 --> 00:73:42.689
person who's like going through the journey of sharing their

1508
00:73:42.699 --> 00:73:45.409
data is kind of a personal preference. Um At

1509
00:73:45.418 --> 00:73:47.439
this point, some people really care about it.

1510
00:73:47.449 --> 00:73:49.168
Other people don't, I think you could make it

1511
00:73:49.180 --> 00:73:53.390
more of like a consumer protection competition issue to say

1512
00:73:53.399 --> 00:73:55.509
I don't even really have a choice so I might

1513
00:73:55.520 --> 00:73:58.520
care about it. But the regulators aren't doing a

1514
00:73:58.529 --> 00:74:00.699
good enough job because there's no way for me to

1515
00:74:00.708 --> 00:74:05.039
have options to choose to create an online experience for

1516
00:74:05.048 --> 00:74:09.430
myself because I have to be online that doesn't involve

1517
00:74:09.439 --> 00:74:12.970
this. But there's also the whole factor. The

1518
00:74:12.979 --> 00:74:15.958
whole question in mind of so much of how we've

1519
00:74:15.970 --> 00:74:18.259
allowed everything to work is for free, but it

1520
00:74:18.270 --> 00:74:20.180
isn't really for free because your data is the,

1521
00:74:20.189 --> 00:74:24.180
is the product that's being trafficked and traded for a

1522
00:74:24.189 --> 00:74:28.689
profit. If you remove that, do I have

1523
00:74:28.699 --> 00:74:30.720
to pay to compensate for it? Right. So

1524
00:74:30.729 --> 00:74:33.569
if I want to have ad free listening on my

1525
00:74:33.579 --> 00:74:36.600
favorite podcast, that option exists, but I have

1526
00:74:36.609 --> 00:74:40.390
to join the podcast and pay a subscription because fair

1527
00:74:40.399 --> 00:74:43.119
enough the podcast creators like have bills to pay as

1528
00:74:43.128 --> 00:74:44.739
well and they're like, listen, we either get

1529
00:74:44.750 --> 00:74:47.470
paid from ads or subscription, you decide. And

1530
00:74:47.479 --> 00:74:49.159
like, that's what was interesting with Twitter is I

1531
00:74:49.168 --> 00:74:51.500
think Elon Musk tried to go down that path by

1532
00:74:51.509 --> 00:74:54.628
getting people to pay, you know,£8 a

1533
00:74:54.640 --> 00:74:56.668
month to be verified because he was, he was

1534
00:74:56.680 --> 00:74:58.770
saying he wanted to do it that way, which

1535
00:74:58.779 --> 00:75:01.039
was slightly flawed because Twitter's revenue model was largely advertising

1536
00:75:01.048 --> 00:75:03.180
based as it is for indeed most of the platforms

1537
00:75:03.189 --> 00:75:05.069
. And the subscription model doesn't really seem to work

1538
00:75:05.079 --> 00:75:06.979
with any of those. And it's also really difficult

1539
00:75:06.989 --> 00:75:10.229
to get people to pay for something they've had for

1540
00:75:10.239 --> 00:75:12.939
free for a really long time. Howls of protest

1541
00:75:13.338 --> 00:75:15.048
. Uh People don't even want to pay for good

1542
00:75:15.060 --> 00:75:16.838
journalism. So you'll constantly see people bitching online going

1543
00:75:16.850 --> 00:75:19.759
. This article is behind a paywall. Not understanding

1544
00:75:19.770 --> 00:75:21.770
. I guess they don't understand the cost of good

1545
00:75:21.779 --> 00:75:25.390
journalism and not like reporters have to be paid.

1546
00:75:25.399 --> 00:75:27.878
Editors have to be paid. Uh, they just

1547
00:75:27.890 --> 00:75:29.350
, they just want it for free. So people

1548
00:75:29.359 --> 00:75:30.470
always want stuff for free and they won't pay for

1549
00:75:30.479 --> 00:75:32.479
it. So I think in that case for,

1550
00:75:32.489 --> 00:75:34.890
for the majority of people like that, they won't

1551
00:75:34.899 --> 00:75:36.739
care. And I'm not, to be honest,

1552
00:75:36.750 --> 00:75:40.100
I'm not even sure that they should care, which

1553
00:75:40.109 --> 00:75:42.109
is a controversial statement to make because they have almost

1554
00:75:42.119 --> 00:75:44.529
no power to get it fixed. I think the

1555
00:75:44.539 --> 00:75:46.588
people who do have power and who do care who

1556
00:75:46.600 --> 00:75:50.649
have like an incentive to care are the big companies

1557
00:75:50.659 --> 00:75:55.729
looking to bust fraud and they lobby like mad.

1558
00:75:55.859 --> 00:75:58.439
So they could actually lobby for a safer internet if

1559
00:75:58.449 --> 00:76:00.399
they wanted to. And in fact, instead what

1560
00:76:00.409 --> 00:76:02.720
they're doing is just upping the amount of, you

1561
00:76:02.729 --> 00:76:05.588
know, anti fraud protections that you would have to

1562
00:76:05.600 --> 00:76:08.628
use when you're doing online banking. For instance,

1563
00:76:08.878 --> 00:76:10.668
you might get like a, you know, you'll

1564
00:76:10.680 --> 00:76:12.829
buy something online and then you'll get a code to

1565
00:76:12.838 --> 00:76:15.180
your phone from your bank checking that you actually wanted

1566
00:76:15.189 --> 00:76:15.680
to make this purchase, right? Like that's a

1567
00:76:15.689 --> 00:76:18.750
new mechanism or getting people to have multi factor authentication

1568
00:76:18.759 --> 00:76:21.250
to check that it's really them doing something. So

1569
00:76:21.259 --> 00:76:25.869
we haven't, we haven't come up with, with

1570
00:76:25.878 --> 00:76:27.979
a way around this. And I think that's because

1571
00:76:27.989 --> 00:76:30.310
again, the ultimate extreme example of risk is you

1572
00:76:30.319 --> 00:76:35.560
build this massive surveillance capitalism model or the Chinese social

1573
00:76:35.569 --> 00:76:40.270
system, social credit system model of surveillance in the

1574
00:76:40.279 --> 00:76:45.369
liberal democratic world. We haven't yet had unfortunately a

1575
00:76:45.378 --> 00:76:48.470
pretty grim test run which would be a bad government

1576
00:76:48.479 --> 00:76:51.109
getting elected into power who then weaponizes all of the

1577
00:76:51.119 --> 00:76:54.859
information that's gathered on all of us. And because

1578
00:76:54.869 --> 00:76:57.819
humans seem to need to see risks before they can

1579
00:76:58.109 --> 00:76:59.458
decide to. Then, oh God, we better

1580
00:76:59.470 --> 00:77:00.048
fix that and make sure that doesn't happen again.

1581
00:77:00.060 --> 00:77:02.520
It's very difficult for them to think ahead and prevent

1582
00:77:02.779 --> 00:77:05.810
something from happening. I don't see that going away

1583
00:77:05.819 --> 00:77:08.829
anytime soon. It would be really nice if we

1584
00:77:08.838 --> 00:77:12.939
did because honestly, the cost to society of fraud

1585
00:77:12.958 --> 00:77:15.789
and identity theft is massive and we have a new

1586
00:77:15.798 --> 00:77:19.119
generation, new generation uh that's been coming on really

1587
00:77:19.128 --> 00:77:23.378
since the early two thousands, who all of their

1588
00:77:23.390 --> 00:77:26.048
life so much of their life, more than any

1589
00:77:26.060 --> 00:77:29.298
other human in history is online. So the,

1590
00:77:29.310 --> 00:77:31.180
the risk is not proportionate if you're a baby boomer

1591
00:77:31.189 --> 00:77:33.180
and the majority of your life is not online.

1592
00:77:34.319 --> 00:77:38.449
If your generation z almost all of it is or

1593
00:77:38.458 --> 00:77:39.668
not all of it. That's unfair. That's an

1594
00:77:39.680 --> 00:77:42.989
exaggeration. Um, let's just call it. Well

1595
00:77:43.000 --> 00:77:44.479
, I mean, I can tell you, I

1596
00:77:44.489 --> 00:77:45.680
can tell you that I have a little brother who

1597
00:77:45.689 --> 00:77:48.140
is 10 years, 10 years younger than me.

1598
00:77:48.149 --> 00:77:53.189
And he's basically lived with internet his entire life.

1599
00:77:53.199 --> 00:77:56.119
I mean, I started using internet when I was

1600
00:77:56.128 --> 00:77:59.338
9, 10 years old, but he lived with

1601
00:77:59.350 --> 00:78:02.319
internet, been posting pictures of them for years,

1602
00:78:02.640 --> 00:78:04.220
you know, that they have an internet presence that

1603
00:78:04.229 --> 00:78:05.918
they weren't even aware of. I mean, that

1604
00:78:05.930 --> 00:78:10.390
you can create all sorts of existential um, angst

1605
00:78:10.399 --> 00:78:13.699
and emotional problems about privacy and sharing and who's,

1606
00:78:13.708 --> 00:78:15.208
who has to share your image or your story or

1607
00:78:15.220 --> 00:78:18.649
your information. That's probably another reason that we haven't

1608
00:78:18.659 --> 00:78:21.509
really evolved yet is I think when as that generation

1609
00:78:21.520 --> 00:78:25.890
comes of age and they are coming of age now

1610
00:78:26.289 --> 00:78:28.489
, um and only will continue to do so,

1611
00:78:28.970 --> 00:78:30.430
they may have different views on this. Whereas I

1612
00:78:30.439 --> 00:78:34.088
think for the baby boomers and possibly generation X even

1613
00:78:34.100 --> 00:78:39.079
who are largely in positions of power, it hasn't

1614
00:78:39.088 --> 00:78:41.479
affected them as much. It'd be interesting like to

1615
00:78:41.489 --> 00:78:43.350
talk with your little brother or indeed anybody who's of

1616
00:78:43.359 --> 00:78:46.000
that younger generation to feel. I think they are

1617
00:78:46.009 --> 00:78:53.588
really different notions of privacy and culture around sharing and

1618
00:78:53.600 --> 00:78:55.560
consent. So on the one hand, they have

1619
00:78:55.569 --> 00:78:57.509
less privacy, but I think they're also much more

1620
00:78:57.520 --> 00:79:00.899
alive to this question of consent and what that means

1621
00:79:00.909 --> 00:79:02.548
and why the consent model doesn't even always work.

1622
00:79:03.079 --> 00:79:05.119
I still though I still come down to, I

1623
00:79:05.128 --> 00:79:08.060
think it's a very old school problem. I think

1624
00:79:08.069 --> 00:79:12.048
regulators have really failed on competition because if you don't

1625
00:79:12.060 --> 00:79:15.279
want to be tracked by Facebook, um, across

1626
00:79:15.289 --> 00:79:18.458
the internet. It just doesn't matter that the,

1627
00:79:18.470 --> 00:79:21.159
the regulatory fines, well, they can pay the

1628
00:79:21.168 --> 00:79:25.500
fines like that. That model has to be updated

1629
00:79:25.509 --> 00:79:28.208
to deal with giants who can afford to pay fines

1630
00:79:28.220 --> 00:79:29.899
and actually really happy to do that. As long

1631
00:79:29.909 --> 00:79:30.909
as you don't interfere with their operating model, what

1632
00:79:30.918 --> 00:79:32.979
we actually have to do is make it so that

1633
00:79:32.989 --> 00:79:34.819
it can't do that legally in the first place.

1634
00:79:35.140 --> 00:79:38.970
You know, if Mark Zuckerberg literally faced criminal charges

1635
00:79:38.979 --> 00:79:40.869
and could like do jail time for that, I'm

1636
00:79:40.878 --> 00:79:42.649
sure he would change his model, but since he

1637
00:79:42.659 --> 00:79:44.838
just has to write a check, yeah, I

1638
00:79:44.850 --> 00:79:46.520
mean, because those fines, they don't hurt their

1639
00:79:46.529 --> 00:79:49.819
profits at all. Let's be real completely. I

1640
00:79:49.829 --> 00:79:53.649
mean, in fact, I still remember with horror

1641
00:79:53.829 --> 00:79:56.279
, the FTC had issued what was then the biggest

1642
00:79:56.289 --> 00:79:59.720
fine against Facebook for privacy violations and Facebook share price

1643
00:79:59.729 --> 00:80:02.609
went up, didn't hurt them, it went up

1644
00:80:02.619 --> 00:80:04.390
. Why did it go up? It went up

1645
00:80:04.399 --> 00:80:09.039
because people had been worried that the FTC might actually

1646
00:80:09.048 --> 00:80:12.270
take action on their data gathering practices, but they

1647
00:80:12.279 --> 00:80:14.239
didn't. So they were like super, if you're

1648
00:80:14.250 --> 00:80:15.500
, if you're telling me that all you're going to

1649
00:80:15.509 --> 00:80:16.279
do is find me, then I can build that

1650
00:80:16.289 --> 00:80:19.869
into my financial modeling, call it, call it

1651
00:80:19.878 --> 00:80:25.529
a tax pay it and carry on which is what

1652
00:80:25.539 --> 00:80:27.359
they do. And so that's going to be,

1653
00:80:27.369 --> 00:80:29.878
the question is like, we were talking about threads

1654
00:80:29.890 --> 00:80:30.958
with, with meta coming up with this new social

1655
00:80:30.970 --> 00:80:34.628
media platform to rival Twitter and the like. And

1656
00:80:34.640 --> 00:80:38.119
I was fascinated by how many people signed up and

1657
00:80:38.128 --> 00:80:39.350
we're talking about it. It was like, have

1658
00:80:39.359 --> 00:80:42.619
you forgotten who is behind all of this? These

1659
00:80:42.628 --> 00:80:46.770
are the same people who were complaining when Francis Hagen

1660
00:80:46.779 --> 00:80:50.430
blew the whistle on mental health abuses by Facebook Instagram

1661
00:80:50.439 --> 00:80:54.569
on Children. And they're the same people who freaked

1662
00:80:54.579 --> 00:80:57.720
out when Facebook was involved with Cambridge Analytica in rigging

1663
00:80:57.729 --> 00:81:00.378
the US election in 2016. You know, all

1664
00:81:00.390 --> 00:81:01.250
thinking that Mark Zuckerberg is, is awful. But

1665
00:81:01.579 --> 00:81:03.600
as soon as he put this out because he's not

1666
00:81:03.649 --> 00:81:05.739
Elon Musk and it became the thing like they had

1667
00:81:05.939 --> 00:81:10.168
a total memory wipe and they, and they all

1668
00:81:10.180 --> 00:81:13.020
signed up not thinking, I wonder why this isn't

1669
00:81:13.029 --> 00:81:15.680
allowed to be released in the European Union yet,

1670
00:81:15.798 --> 00:81:16.588
right? So like we were just talking about the

1671
00:81:16.600 --> 00:81:19.579
fact that you can't get it there because the amount

1672
00:81:19.588 --> 00:81:25.500
of data that threads harvests is huge and we know

1673
00:81:25.509 --> 00:81:27.279
that these people are not going to be using it

1674
00:81:27.289 --> 00:81:30.979
for good, they're using it for profit and yet

1675
00:81:30.989 --> 00:81:32.029
people signed up. So like that was again,

1676
00:81:32.039 --> 00:81:34.199
as a a technology ethicist, I was fascinated because

1677
00:81:34.208 --> 00:81:38.949
I was like all that you can give people all

1678
00:81:38.958 --> 00:81:41.029
the information in the world and they will still make

1679
00:81:41.039 --> 00:81:44.409
bad choices. It's just not, it's not enough

1680
00:81:44.418 --> 00:81:45.588
to give them information and it's not enough to remind

1681
00:81:45.600 --> 00:81:48.520
them again and again and again, that need to

1682
00:81:48.529 --> 00:81:56.319
have a social media life, uh seems to be

1683
00:81:56.329 --> 00:81:58.319
really strong in a lot of people. We saw

1684
00:81:58.329 --> 00:82:00.439
it first with Mastodon, then we saw the blue

1685
00:82:00.449 --> 00:82:02.319
sky now its threads like it's, it's this thing

1686
00:82:02.329 --> 00:82:04.548
and it never seems to get the critical mass that

1687
00:82:04.560 --> 00:82:06.909
, that may have changed by the time this podcast

1688
00:82:06.918 --> 00:82:10.640
go out, um they'll have a spike in early

1689
00:82:10.649 --> 00:82:13.159
adoption and then it kind of falls off. And

1690
00:82:13.168 --> 00:82:14.789
that's what I mean about kind of looking to the

1691
00:82:14.798 --> 00:82:15.819
long term is like, are people actually going to

1692
00:82:15.829 --> 00:82:18.229
want this? Because what, what need does it

1693
00:82:18.239 --> 00:82:21.310
serve and is the price too high to pay?

1694
00:82:21.798 --> 00:82:24.588
Yeah, very fascinating. But I don't know.

1695
00:82:24.859 --> 00:82:27.270
But by the way, since uh earlier, you

1696
00:82:27.279 --> 00:82:30.180
mentioned that you wrote your book during the COVID-19 pandemic

1697
00:82:30.189 --> 00:82:32.180
, I would also like to ask you what,

1698
00:82:32.189 --> 00:82:35.548
what is your idea about uh some of the digi

1699
00:82:35.668 --> 00:82:41.378
digital health tools that were used during the COVID-19 pandemic

1700
00:82:41.390 --> 00:82:44.548
because of course, we were dealing with a major

1701
00:82:44.560 --> 00:82:49.064
health issue and perhaps even if there with some data

1702
00:82:49.074 --> 00:82:53.225
collection, uh I, I mean, it,

1703
00:82:53.234 --> 00:82:57.824
it would still be ethical to do that. The

1704
00:82:57.833 --> 00:83:00.784
pros would outweigh the cons because of the threat we

1705
00:83:00.793 --> 00:83:04.305
were dealing with. But what do you think about

1706
00:83:04.314 --> 00:83:10.384
uh some of the data that were potentially collected by

1707
00:83:10.395 --> 00:83:15.100
, I guess governments mostly during that period? It's

1708
00:83:15.109 --> 00:83:16.500
interesting, isn't it like we haven't really had all

1709
00:83:16.509 --> 00:83:19.229
of the different countries that built that kind of health

1710
00:83:19.239 --> 00:83:23.609
surveillance tech if you will um come out as a

1711
00:83:23.619 --> 00:83:26.539
group, I don't mean individually but as a group

1712
00:83:26.739 --> 00:83:30.029
or through the auspices of the, who the World

1713
00:83:30.039 --> 00:83:31.649
Health Organization to say, like if we have another

1714
00:83:31.659 --> 00:83:33.458
pandemic, God forbid in, you know, a

1715
00:83:33.470 --> 00:83:36.600
few years time, is this a tool that we

1716
00:83:36.609 --> 00:83:39.838
want to have in our toolbox Eg was it effective

1717
00:83:39.850 --> 00:83:41.878
or not? And not only was it effective?

1718
00:83:41.890 --> 00:83:43.979
Was it worth it? Which is a different question

1719
00:83:44.699 --> 00:83:47.039
? Um The UK has had some studies that came

1720
00:83:47.048 --> 00:83:54.720
out arguing that it reduced transmission. But II I

1721
00:83:54.729 --> 00:83:57.878
still question some of that because we can't really run

1722
00:83:59.060 --> 00:84:01.199
a couple of other sort of counterfactual experiments. Like

1723
00:84:01.208 --> 00:84:03.970
what, what would it be like if we hadn't

1724
00:84:03.979 --> 00:84:06.378
used it? There's a lot of problems still with

1725
00:84:06.390 --> 00:84:09.449
some of the things that I cook. And I

1726
00:84:09.458 --> 00:84:12.789
also just think I interviewed loads of doctors while I

1727
00:84:12.798 --> 00:84:15.430
was writing that chapter and none of them were asking

1728
00:84:15.439 --> 00:84:16.649
for this. Like this was not the tool,

1729
00:84:16.659 --> 00:84:18.729
this was not the mitigation that they need, that

1730
00:84:18.739 --> 00:84:23.430
they felt they needed. Um The most effective mitigations

1731
00:84:23.439 --> 00:84:26.789
were the lockdowns unfortunately. And then obviously the big

1732
00:84:26.798 --> 00:84:30.159
one was vaccines, but doctors weren't calling for this

1733
00:84:30.168 --> 00:84:32.020
. It really felt for me like a solution in

1734
00:84:32.029 --> 00:84:35.789
search of a problem in the sense that this massive

1735
00:84:35.798 --> 00:84:40.958
crisis happened. Technologists wanted to do something investors saw

1736
00:84:40.970 --> 00:84:43.850
a potential to make money from it and like,

1737
00:84:43.859 --> 00:84:45.029
Voila, let's go for it. And you saw

1738
00:84:45.039 --> 00:84:47.779
in the case of Singapore, um, they said

1739
00:84:47.789 --> 00:84:49.250
at first we, you know, we're making this

1740
00:84:49.259 --> 00:84:50.958
mandatory, but don't worry, we're going to collect

1741
00:84:50.970 --> 00:84:54.449
data that we would never use for like a criminal

1742
00:84:54.458 --> 00:84:57.759
policing aspect. We're only using it for public health

1743
00:84:57.770 --> 00:84:59.390
and of course they did use it for the criminal

1744
00:84:59.399 --> 00:85:01.329
policing aspect. So, like, not a surprise

1745
00:85:01.338 --> 00:85:03.430
, like, saw that one coming a mile away

1746
00:85:03.640 --> 00:85:05.750
. And absolutely, I think the UK would have

1747
00:85:05.759 --> 00:85:08.668
done it. I mean, we've seen, unfortunately

1748
00:85:08.680 --> 00:85:11.229
, we're going through our COVID inquiry now and it's

1749
00:85:11.239 --> 00:85:13.939
been pretty grim, the behavior of people in power

1750
00:85:14.259 --> 00:85:15.250
. Uh, certainly within our current government, a

1751
00:85:15.259 --> 00:85:17.159
lot of the ministers who were not following their own

1752
00:85:17.168 --> 00:85:18.458
laws or, you know, they were, the

1753
00:85:18.470 --> 00:85:20.668
police were really clamping down and there was like a

1754
00:85:20.680 --> 00:85:25.310
certain people were more heavily policed than others and there

1755
00:85:25.319 --> 00:85:27.970
was a racial, ethnic class component to that,

1756
00:85:28.039 --> 00:85:30.109
right. So you do that and then you put

1757
00:85:30.119 --> 00:85:33.100
technology solutions on top of that. I just think

1758
00:85:33.109 --> 00:85:36.430
you're going to create some really serious problems. The

1759
00:85:36.439 --> 00:85:41.548
parliament hadn't really created pandemic legislation in place to deal

1760
00:85:41.560 --> 00:85:43.789
with it. And part of the reason, um

1761
00:85:43.798 --> 00:85:46.029
, I put my book out in February of 2022

1762
00:85:46.270 --> 00:85:48.548
and that was because I was in my poor publishers

1763
00:85:48.560 --> 00:85:50.729
. I was like, we have to wait because

1764
00:85:51.409 --> 00:85:56.189
they started passing legislation I think it was to remember

1765
00:85:56.199 --> 00:85:59.048
now, the last order England was the last one

1766
00:85:59.060 --> 00:86:01.109
to create a legal framework to allow these, to

1767
00:86:01.119 --> 00:86:03.319
allow these apps which had already been in existence for

1768
00:86:03.329 --> 00:86:05.909
like a year at that point, maybe even more

1769
00:86:06.229 --> 00:86:10.000
. Um They didn't have a legal framework for it

1770
00:86:10.009 --> 00:86:12.509
though in the four nations of the United Kingdom until

1771
00:86:12.520 --> 00:86:15.279
starting in September of 2021. And then England was

1772
00:86:15.289 --> 00:86:17.609
the last one in December of 2021. So I

1773
00:86:17.619 --> 00:86:20.390
was typing against the clock because I wanted to capture

1774
00:86:20.399 --> 00:86:24.048
that before we went to press uh and put it

1775
00:86:24.060 --> 00:86:29.930
out to show really, the UK had, had

1776
00:86:29.939 --> 00:86:31.149
completely changed its position. We used to be a

1777
00:86:31.159 --> 00:86:33.989
country that was super proud of not having identity cards

1778
00:86:34.000 --> 00:86:35.418
and all of a sudden in this case, we

1779
00:86:35.430 --> 00:86:38.418
did and we've also put them in for voting now

1780
00:86:38.430 --> 00:86:41.930
, by the way, like massive cultural shift here

1781
00:86:42.199 --> 00:86:45.048
, not without protest. So they did that.

1782
00:86:45.770 --> 00:86:48.310
And then within like two months of England passing that

1783
00:86:48.319 --> 00:86:50.418
law, they basically were like, we're not using

1784
00:86:50.430 --> 00:86:53.609
the app anymore. Why? Because it wasn't like

1785
00:86:53.619 --> 00:86:56.369
it wasn't effective, it was not what, what

1786
00:86:56.378 --> 00:86:58.909
was needed. So we did all of this mass

1787
00:86:59.088 --> 00:87:00.500
, you know, they blew a huge amount of

1788
00:87:00.509 --> 00:87:03.708
political capital and wasted loads of time on something that

1789
00:87:03.720 --> 00:87:06.048
they in the end themselves decided it wasn't going to

1790
00:87:06.060 --> 00:87:09.890
be a requirement. And what was really awful in

1791
00:87:09.899 --> 00:87:11.619
that is they kept lying about it. So they

1792
00:87:11.628 --> 00:87:13.548
kept saying, hey, we're not building it when

1793
00:87:13.560 --> 00:87:15.458
they were secretly building it, then they were like

1794
00:87:15.470 --> 00:87:15.619
, well, we're building it but it's not going

1795
00:87:15.628 --> 00:87:17.069
to be mandatory and blah, blah, blah.

1796
00:87:17.079 --> 00:87:23.009
So each time they kind of destroyed public trust,

1797
00:87:24.100 --> 00:87:27.119
which is essential in something like a national crisis or

1798
00:87:27.128 --> 00:87:29.100
international crisis, like a pandemic. So, you

1799
00:87:29.109 --> 00:87:30.259
know, my takeaway for what it's worth and stuff

1800
00:87:30.270 --> 00:87:31.759
like that is, you know, a I'm not

1801
00:87:31.770 --> 00:87:35.529
convinced it was worth it scientifically and medically, it

1802
00:87:35.539 --> 00:87:40.759
wasn't what healthcare professionals certainly were calling for. Um

1803
00:87:41.128 --> 00:87:43.850
The risks are super high in terms of potential for

1804
00:87:43.859 --> 00:87:48.449
abuse and they blew so much political and social trust

1805
00:87:48.789 --> 00:87:50.909
and that matters in a democracy because if we,

1806
00:87:50.918 --> 00:87:53.500
you know, I guarantee you, if we go

1807
00:87:53.509 --> 00:87:55.560
again into another pandemic, a lot of people are

1808
00:87:55.569 --> 00:88:00.329
going to remember all the lying that government did trust

1809
00:88:00.338 --> 00:88:01.970
matters when you're handing over data, trust matters.

1810
00:88:01.979 --> 00:88:04.829
If you're doing surveillance and trust matters in terms of

1811
00:88:04.838 --> 00:88:06.619
health and because you, you're talking to people about

1812
00:88:06.628 --> 00:88:10.750
their bodies, ultimately, you know, you play

1813
00:88:10.759 --> 00:88:12.899
with that with your peril. So that for me

1814
00:88:12.909 --> 00:88:15.418
was the real learning point was like, how do

1815
00:88:15.430 --> 00:88:20.659
I create trust in the scientific method in health care

1816
00:88:20.668 --> 00:88:23.878
? You're asking people to make massive sacrifices, you

1817
00:88:23.890 --> 00:88:27.449
have to be even more trustworthy than normal because you're

1818
00:88:27.458 --> 00:88:29.729
, you're, you're making a bigger, ask a

1819
00:88:29.739 --> 00:88:32.338
bigger demand and for my two cents for what it's

1820
00:88:32.350 --> 00:88:34.600
worth in the UK. We blew that. We

1821
00:88:34.609 --> 00:88:38.970
absolutely blew it. Um So it wouldn't be great

1822
00:88:38.979 --> 00:88:40.109
to, to have to have, you know,

1823
00:88:40.119 --> 00:88:41.899
run that experiment again. If there's, you know

1824
00:88:41.909 --> 00:88:45.180
, pandemic version 2.0 I would have a lot of

1825
00:88:45.189 --> 00:88:46.279
confidence and I suspect the US would be the same

1826
00:88:46.289 --> 00:88:48.140
. I mean, that was another case, my

1827
00:88:48.149 --> 00:88:50.680
family and friends over in America, they were like

1828
00:88:50.878 --> 00:88:54.659
there was no case of requiring people to use that

1829
00:88:54.668 --> 00:88:57.520
kind of surveillance technology for health, for better or

1830
00:88:57.529 --> 00:88:58.949
for worse. And you can look at the outcomes

1831
00:88:58.958 --> 00:89:00.000
on that. But that's what I'm talking about.

1832
00:89:00.279 --> 00:89:02.319
The technology is just one part of it. There's

1833
00:89:02.329 --> 00:89:06.378
the cultural bit about adaptation. Why were certain European

1834
00:89:06.390 --> 00:89:10.458
countries were happy to do it? And others weren't

1835
00:89:10.470 --> 00:89:12.659
certain countries could afford to do it or have the

1836
00:89:12.668 --> 00:89:15.020
infrastructure, do it? Certain populations have an iphone

1837
00:89:15.029 --> 00:89:17.548
or an Android and others just don't. So it's

1838
00:89:17.560 --> 00:89:20.140
not even an option for them, right? Like

1839
00:89:20.939 --> 00:89:23.899
all of those things come into play. And if

1840
00:89:23.909 --> 00:89:26.458
you're looking at utilitarianism, if you're looking at like

1841
00:89:27.109 --> 00:89:29.069
the greatest number of happiness for the greatest numbers of

1842
00:89:29.079 --> 00:89:30.338
people, you might want to do. What I

1843
00:89:30.350 --> 00:89:32.539
was trying to do is go back to the original

1844
00:89:32.548 --> 00:89:35.838
problem set and go what is it that the healthcare

1845
00:89:35.850 --> 00:89:41.119
profession says it needs, it needs P pe they

1846
00:89:41.128 --> 00:89:44.180
thought they needed ventilators that later was dismissed because to

1847
00:89:44.189 --> 00:89:45.088
be honest, by the point, you're on a

1848
00:89:45.100 --> 00:89:46.729
ventilator. It's pretty bad. Um, they needed

1849
00:89:46.739 --> 00:89:49.479
people to stay home and they really needed a race

1850
00:89:49.489 --> 00:89:51.899
for a vaccine. That is where you want to

1851
00:89:51.909 --> 00:89:55.789
put, given that you have limited capital and limited

1852
00:89:55.798 --> 00:89:57.939
resources. That's where you want to go. But

1853
00:89:57.949 --> 00:90:00.048
people were super excited with this idea that this app

1854
00:90:00.060 --> 00:90:01.770
on our phone is going to allow us to open

1855
00:90:01.779 --> 00:90:04.270
up society again. Yeah. No, no,

1856
00:90:04.279 --> 00:90:06.220
I have to tell you here in Portugal, the

1857
00:90:06.229 --> 00:90:12.819
government also put out an app in 2021 if I'm

1858
00:90:12.829 --> 00:90:15.750
not mistaken. And back then they were moralizing people

1859
00:90:15.759 --> 00:90:17.750
a lot. Oh, you should install the app

1860
00:90:17.759 --> 00:90:19.039
, blah, blah, blah, blah, it's

1861
00:90:19.048 --> 00:90:23.279
a health measure, whatever. Uh And I,

1862
00:90:23.289 --> 00:90:24.930
and I was like, so first of all,

1863
00:90:24.939 --> 00:90:27.958
I never installed the app because it was not mandatory

1864
00:90:27.970 --> 00:90:30.298
. So I myself never installed the app at all

1865
00:90:30.400 --> 00:90:31.150
. Uh But, but first of all, I

1866
00:90:31.162 --> 00:90:34.532
was like, yeah, and if certain people do

1867
00:90:34.541 --> 00:90:38.952
not even have smartphones to begin with, I mean

1868
00:90:38.961 --> 00:90:42.261
, are you also going to moralize those people?

1869
00:90:42.270 --> 00:90:45.751
I mean, no one should be forced to have

1870
00:90:45.761 --> 00:90:47.742
a smartphone if they have one of those older,

1871
00:90:47.860 --> 00:90:51.311
uh, cell phones, I mean, who cares

1872
00:90:51.320 --> 00:90:53.801
? And, and then, and then I was

1873
00:90:53.811 --> 00:90:56.282
like, I was taking the pandemic very serious.

1874
00:90:56.363 --> 00:90:58.813
I was masking all the time. I was staying

1875
00:90:58.823 --> 00:91:02.382
at home as much as possible. Uh I was

1876
00:91:02.394 --> 00:91:06.403
distancing as much as possible. I got tested two

1877
00:91:06.413 --> 00:91:09.913
or three times during the pandemic. It always came

1878
00:91:09.922 --> 00:91:13.054
out negative. Fortunately, uh and I was like

1879
00:91:13.063 --> 00:91:15.542
, doing everything apart from the app and I was

1880
00:91:15.554 --> 00:91:17.453
like, ok, if I'm doing all of this

1881
00:91:17.462 --> 00:91:21.956
, let's say that I uh cross paths with someone

1882
00:91:21.965 --> 00:91:25.154
who also has the app installed and I get an

1883
00:91:25.166 --> 00:91:29.925
alert on my phone saying that I uh went by

1884
00:91:29.935 --> 00:91:33.465
uh for uh was less than 3 m or whatever

1885
00:91:33.475 --> 00:91:38.104
away from a person who got diagnosed with COVID.

1886
00:91:38.234 --> 00:91:41.706
Yeah. What am I going to do with that

1887
00:91:41.715 --> 00:91:44.654
? Because let's get real if I, even if

1888
00:91:44.666 --> 00:91:46.746
I get COVID, but I'm a symptomatic, I'm

1889
00:91:46.755 --> 00:91:49.567
not going to get tested. Let's get real.

1890
00:91:49.756 --> 00:91:54.948
So I, I mean, what, how uh

1891
00:91:55.317 --> 00:91:59.448
valuable is that information for me? And, and

1892
00:91:59.457 --> 00:92:02.006
I, and if I am COVID negative, no

1893
00:92:02.018 --> 00:92:05.768
, no uh no one out there who goes by

1894
00:92:05.777 --> 00:92:11.347
me will get any alert saying that they crossed paths

1895
00:92:11.356 --> 00:92:15.020
with someone who has COVID. So, I mean

1896
00:92:15.029 --> 00:92:18.489
, and I got vaccinated as soon as possible.

1897
00:92:18.500 --> 00:92:23.680
So what, what can I gain or anyone who

1898
00:92:23.689 --> 00:92:27.918
crosses perhaps with me can gain from this? And

1899
00:92:27.930 --> 00:92:30.979
I never though because like, like the, the

1900
00:92:30.989 --> 00:92:32.609
sort of wanna be scientist in me is like,

1901
00:92:32.619 --> 00:92:34.609
I'm glad that we tried it because like, I

1902
00:92:34.619 --> 00:92:38.680
understand in those pre vaccine days, like people were

1903
00:92:38.689 --> 00:92:40.208
like, we have to try whatever we can.

1904
00:92:40.680 --> 00:92:43.810
That's understandable. Um I'm glad we tried it in

1905
00:92:43.819 --> 00:92:45.829
a number of different countries with different political and cultural

1906
00:92:45.838 --> 00:92:47.909
flavors. So, that we could see like what

1907
00:92:47.918 --> 00:92:50.168
words or what might not work because we don't know

1908
00:92:50.180 --> 00:92:54.060
again, uh wherever the next pandemic will come from

1909
00:92:54.128 --> 00:92:55.930
, we don't know when that will happen and where

1910
00:92:55.939 --> 00:92:58.378
it will be with our technology. That's kind of

1911
00:92:58.390 --> 00:93:00.088
why I was really motivated to write the chapters.

1912
00:93:00.100 --> 00:93:01.708
Like I want to capture the UK case study to

1913
00:93:01.720 --> 00:93:03.970
the best of my ability now, not just the

1914
00:93:03.979 --> 00:93:10.060
tech part but the social cultural part. Because if

1915
00:93:10.069 --> 00:93:12.430
this happens again, you know, when it happened

1916
00:93:12.439 --> 00:93:14.600
for us in 2020 I was going back to books

1917
00:93:14.609 --> 00:93:16.338
on the Spanish flu. In 1918, I was

1918
00:93:16.350 --> 00:93:18.199
like, I need, you know, I need

1919
00:93:18.208 --> 00:93:19.970
, I need to skill up fast. What do

1920
00:93:19.979 --> 00:93:21.279
I need to know about this? And I'm sure

1921
00:93:21.289 --> 00:93:24.279
loads of people felt the same way just as ordinary

1922
00:93:24.289 --> 00:93:25.850
citizens. You don't have to be a researcher to

1923
00:93:25.859 --> 00:93:27.279
be interested in, you know, learning what had

1924
00:93:27.289 --> 00:93:30.189
happened in previous pandemics, but I wanted to create

1925
00:93:30.199 --> 00:93:32.909
something so that future future researchers could go back and

1926
00:93:32.918 --> 00:93:34.369
be like, well, what happened in the UK

1927
00:93:34.378 --> 00:93:35.579
? And you know, I'm sure loads of people

1928
00:93:35.588 --> 00:93:39.449
have written stuff on that um for what it's worth

1929
00:93:39.458 --> 00:93:41.659
, I will share this, the Ada Lovelace Institute

1930
00:93:41.668 --> 00:93:45.329
here in the United Kingdom is a wonderful research institution

1931
00:93:45.750 --> 00:93:48.500
and they've just come out with their assessment of pandemic

1932
00:93:48.509 --> 00:93:50.479
technology. I haven't had a chance to read it

1933
00:93:50.489 --> 00:93:53.180
yet because I just came back from holiday. But

1934
00:93:53.259 --> 00:93:55.359
it looks pretty interesting and they do great work.

1935
00:93:55.369 --> 00:93:59.181
So that might be something for your viewers to check

1936
00:93:59.190 --> 00:94:00.582
out if they want to. I feel like the

1937
00:94:00.591 --> 00:94:02.570
Turing Institute might have as well. Um And definitely

1938
00:94:02.582 --> 00:94:05.940
Oxford University has published a lot of stuff on it

1939
00:94:05.952 --> 00:94:10.770
, but I'm intrigued by the ada Lovelace view because

1940
00:94:10.782 --> 00:94:14.480
they often do an international comparison. So there is

1941
00:94:14.492 --> 00:94:16.372
cutting edge research that I am unfortunately behind on at

1942
00:94:16.381 --> 00:94:17.801
the moment. But you know, we know it's

1943
00:94:17.811 --> 00:94:19.511
there. So if anyone wants to take a look

1944
00:94:19.520 --> 00:94:20.601
at that, if you don't want to hear what

1945
00:94:20.610 --> 00:94:23.681
I have to say by all means, don't go

1946
00:94:23.690 --> 00:94:25.413
check out in a lovely, they got some good

1947
00:94:25.453 --> 00:94:28.113
stuff and I mean, just to be clear,

1948
00:94:28.123 --> 00:94:31.913
I'm not completely dismissing these apps. I'm not saying

1949
00:94:31.922 --> 00:94:35.172
100% that they didn't help at all that they weren't

1950
00:94:35.184 --> 00:94:39.344
good health measures. I'm just saying that first of

1951
00:94:39.354 --> 00:94:41.894
all, no one should be forced to have a

1952
00:94:41.903 --> 00:94:46.832
smartphone. That's the first point. Second of all

1953
00:94:46.844 --> 00:94:51.524
, you shouldn't moralize people for not having a smartphone

1954
00:94:51.536 --> 00:94:55.314
or install, really should moralize them when you're the

1955
00:94:55.326 --> 00:94:58.386
British ministers who were breaking all of their own rules

1956
00:94:58.595 --> 00:95:00.425
. Yeah, that's one thing to moralize if you

1957
00:95:00.444 --> 00:95:02.095
at least to walk the walk. But if you're

1958
00:95:02.104 --> 00:95:05.444
doing hypocrisy, like get out and, and then

1959
00:95:05.585 --> 00:95:10.555
my first and then the third point and that's why

1960
00:95:10.564 --> 00:95:14.996
I mentioned that I really follow all the guidelines and

1961
00:95:15.005 --> 00:95:18.369
all of that to prevent COVID transmission is that you

1962
00:95:18.378 --> 00:95:23.609
have to convince me that it's worth it because I'm

1963
00:95:23.619 --> 00:95:26.890
not dumb and people are not dumb. Don't,

1964
00:95:26.899 --> 00:95:29.529
don't treat us as dumb like, oh, you

1965
00:95:29.539 --> 00:95:32.199
should do this. Yeah. Why, why you

1966
00:95:32.270 --> 00:95:34.729
have with anything? If you're asking people to make

1967
00:95:34.739 --> 00:95:38.500
a change, you have to show them why it

1968
00:95:38.509 --> 00:95:40.479
is worth it. Listen, I'm just aware of

1969
00:95:40.489 --> 00:95:42.128
the fact that it's approaching 11. I'm going to

1970
00:95:42.140 --> 00:95:43.878
have to let you go if that's ok because I

1971
00:95:43.890 --> 00:95:45.759
unfortunately have to talk to one of my clients.

1972
00:95:45.798 --> 00:95:46.338
Oh, yeah. No, no, sorry.

1973
00:95:46.350 --> 00:95:48.369
I, I, I love this chat but I

1974
00:95:48.378 --> 00:95:49.850
was like, oh, no, the time has

1975
00:95:49.859 --> 00:95:53.088
flown. No, no, I'm sorry, I

1976
00:95:53.100 --> 00:95:56.378
wasn't aware that you had that time limit. So

1977
00:95:56.588 --> 00:95:59.140
, yeah. So just quickly before we go,

1978
00:95:59.149 --> 00:96:00.409
would you like to tell people where they can find

1979
00:96:00.418 --> 00:96:03.020
you and your work on the internet? Well,

1980
00:96:03.039 --> 00:96:06.449
I mean, I'm a Google search away. Uh

1981
00:96:06.548 --> 00:96:09.689
, probably the easiest is my website, which is

1982
00:96:10.500 --> 00:96:14.560
Habra, uh, Hare brain.co. So you can

1983
00:96:14.569 --> 00:96:17.069
find all my, uh, television and radio and

1984
00:96:17.079 --> 00:96:21.310
online writing. Um, and paper writing there.

1985
00:96:21.319 --> 00:96:25.270
My book is available at all good bookstores. You

1986
00:96:25.279 --> 00:96:28.069
can just order it through your local independent bookstore or

1987
00:96:28.079 --> 00:96:30.430
Pay Il Amazon. It's up to you your call

1988
00:96:30.439 --> 00:96:31.500
, not mine how you want to do it.

1989
00:96:31.619 --> 00:96:33.680
So it's there. It's an audio book too if

1990
00:96:33.689 --> 00:96:35.600
you prefer to listen to it rather than read it

1991
00:96:35.609 --> 00:96:38.390
. But then you'll miss the amazing date, this

1992
00:96:38.399 --> 00:96:40.259
, which is in the book. So it just

1993
00:96:40.270 --> 00:96:42.859
depends on what you want. Um And I'm on

1994
00:96:42.869 --> 00:96:45.378
Twitter and linkedin in case anybody has questions or wants

1995
00:96:45.390 --> 00:96:48.109
to follow up or share something that they think I've

1996
00:96:48.119 --> 00:96:49.458
missed or that I need to look at. I'm

1997
00:96:49.470 --> 00:96:53.409
really, really lucky for some reason, I have

1998
00:96:53.418 --> 00:96:56.759
an incredible group of people from the public who just

1999
00:96:56.770 --> 00:96:59.029
send me stuff randomly tips and things to look at

2000
00:96:59.039 --> 00:97:00.509
or articles that are actually really interesting or examples from

2001
00:97:00.520 --> 00:97:02.579
their country that I would never have heard about otherwise

2002
00:97:02.588 --> 00:97:04.168
. So I love to hear from people. If

2003
00:97:04.180 --> 00:97:05.770
somebody wants to get in touch, I would be

2004
00:97:05.779 --> 00:97:10.159
very welcome. As long as polite kind. No

2005
00:97:10.168 --> 00:97:15.029
romance stuff, please. But uh the marriage proposals

2006
00:97:15.039 --> 00:97:16.378
get a bit weird uh at the end. But

2007
00:97:16.390 --> 00:97:19.079
no, I would love to talk technology and ethics

2008
00:97:19.088 --> 00:97:21.850
with um any of your listeners or viewers and I'm

2009
00:97:21.859 --> 00:97:24.689
so grateful to you for the chance to have this

2010
00:97:24.699 --> 00:97:27.239
chat. No. Thank you so much for coming

2011
00:97:27.250 --> 00:97:29.270
on the show. Thank you for your time and

2012
00:97:29.279 --> 00:97:31.739
hopefully somewhere in the future we can have another conversation

2013
00:97:31.750 --> 00:97:33.865
. I really love this one. So I would

2014
00:97:33.875 --> 00:97:35.274
love that too. I will drop you a note

2015
00:97:35.286 --> 00:97:38.015
if I am ever in Portugal again, which I

2016
00:97:38.024 --> 00:97:41.886
hope I will be all be well and let me

2017
00:97:41.895 --> 00:97:43.185
know when it comes out. I'd love to see

2018
00:97:43.194 --> 00:97:45.895
it. Yeah. Sure. The marriage proposals get

2019
00:97:45.904 --> 00:97:48.345
a bit weird at the end. But no,

2020
00:97:48.354 --> 00:97:51.386
I would love to talk technology and ethics with um

2021
00:97:51.395 --> 00:97:54.576
, any of your listeners or viewers. And I'm

2022
00:97:54.585 --> 00:97:56.400
so grateful to you for the chance to have this

2023
00:97:56.412 --> 00:97:58.931
chat. No, thank you so much for coming

2024
00:97:58.940 --> 00:98:00.971
on the show. Thank you for your time and

2025
00:98:00.980 --> 00:98:03.461
hopefully somewhere in the future we can have another conversation

2026
00:98:03.471 --> 00:98:05.561
. I really love this one. So I would

2027
00:98:05.570 --> 00:98:06.971
love that too. I will drop you a note

2028
00:98:06.980 --> 00:98:09.702
if I am ever in Portugal again, which I

2029
00:98:09.711 --> 00:98:13.351
hope I will be all right, be well and

2030
00:98:13.360 --> 00:98:14.601
let me know when it comes out. I'd love

2031
00:98:14.610 --> 00:98:16.798
to see it. Yeah, sure. Hi guys

2032
00:98:16.810 --> 00:98:18.958
. Thank you for watching this interview. Until the

2033
00:98:18.970 --> 00:98:21.369
end. If you liked it, please do not

2034
00:98:21.378 --> 00:98:27.279
forget to like it, share, comment and subscribe

2035
00:98:27.319 --> 00:98:29.628
. And if you like more generally, what I'm

2036
00:98:29.640 --> 00:98:33.329
doing, please consider support the show on Patreon or

2037
00:98:33.338 --> 00:98:36.329
paypal. You have all of the links in the

2038
00:98:36.338 --> 00:98:40.649
description of this interview. The show is brought to

2039
00:98:40.659 --> 00:98:44.588
you by En Lights learning and development. Done differently

2040
00:98:44.600 --> 00:98:47.338
. Check their website at alights.com. I would also

2041
00:98:47.350 --> 00:98:49.489
like to give a huge thank you to my main

2042
00:98:49.500 --> 00:98:55.720
patrons and paypal supporters per Larson Jerry Mueller and Frederick

2043
00:98:55.729 --> 00:98:59.319
Sunda Bernards, all of election and Weser, Adam

2044
00:98:59.329 --> 00:99:01.810
Castle Matthew Whitting Whitting bear. No wolf, Tim

2045
00:99:01.819 --> 00:99:04.588
Hollis, Eric, Alania, John Connors, Philip

2046
00:99:04.600 --> 00:99:08.479
Forrest, Connelly, Robert Winde Ruin, Nai Zoup

2047
00:99:08.489 --> 00:99:11.412
, Mark Nevs Colin Hall, Simon, Columbus,

2048
00:99:11.432 --> 00:99:15.021
Phil Cavanagh, Mikel, Stormer, Samuel Andrea Francis

2049
00:99:15.033 --> 00:99:17.421
for the Agd Alexander Dan Bauer, Fergal, Ken

2050
00:99:17.582 --> 00:99:21.582
Hall, Herzog Michel, Jonathan Libra Jars and the

2051
00:99:23.323 --> 00:99:28.412
Correa Eric Heine Marc Smith, Jan We Amal Franz

2052
00:99:28.421 --> 00:99:33.095
David Sloan Wilson Yasa, Des Roma Roach Jan Punter

2053
00:99:33.975 --> 00:99:38.734
Romani Charlotte. Bliss, Nicole Barbar and Pao Ay

2054
00:99:38.746 --> 00:99:42.314
Nele Guy Madison, Gary G Haman, Samo Zal

2055
00:99:42.595 --> 00:99:45.435
Arien Y Nick Golden Paul Talent in John Bar was

2056
00:99:45.545 --> 00:99:47.996
Julian Price Edward Hall, Eden Brown, Douglas Fry

2057
00:99:48.005 --> 00:99:53.024
Franca Beto Lotti Gabriel Pan Cortez, Lalit Scott Zachary

2058
00:99:53.036 --> 00:99:57.088
Fish, Tim Duffy, Sonny Smith, John Wiesman

2059
00:99:57.250 --> 00:100:00.699
, Martin Aland, Daniel Friedman, William Buckner,

2060
00:100:00.708 --> 00:100:04.600
Paul George Arnold Luke Lo A Georges off Chris Williamson

2061
00:100:04.609 --> 00:100:10.439
, Peter Lawson, David Williams Di Costa Anton Erickson

2062
00:100:10.449 --> 00:100:15.369
Charles Murray, Alex Shaw and Murray Martinez Le Chevalier

2063
00:100:15.729 --> 00:100:19.298
bangalore atheists, Larry Daley Junior Holt Eric B.

2064
00:100:19.458 --> 00:100:25.430
Starry Michael Bailey. Then Sperber, Robert Grassy Rough

2065
00:100:25.439 --> 00:100:30.088
the RP MD I Goran Jeff mcmahon, Jake Zul

2066
00:100:30.100 --> 00:100:34.189
Barnabas Radix, Mark Campbell, Richard Bowen Thomas the

2067
00:100:34.199 --> 00:100:39.909
Dubner Luke Ni Andre Story, Manuel Oliveira, Kimberly

2068
00:100:39.918 --> 00:100:44.298
Johnson and Benjamin Gilbert. A special thanks to my

2069
00:100:44.310 --> 00:100:46.539
producers is our web gem Frank Luca Stan, Tom

2070
00:100:46.548 --> 00:100:51.024
Weam Bernard Eni Ortiz Dixon Benedict Mueller, Vege Gli

2071
00:100:51.034 --> 00:100:57.484
Thomas Trumble Catherine and Patrick Tobin John Carlo Montenegro,

2072
00:100:57.494 --> 00:101:00.515
Robert Lewis and Al Nick Ortiz. And to my

2073
00:101:00.524 --> 00:101:03.463
executive producers, Matthew Lavender, Serge Adrian and Bogdan

2074
00:101:03.475 --> 00:101:05.244
Kut. Thank you for all.

