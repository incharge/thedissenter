WEBVTT

1
00:00:00.180 --> 00:00:02.960
Hello everybody. Welcome to a new episode of the

2
00:00:02.970 --> 00:00:05.769
Decent. I'm your host, Ricard Lobs. And today I'm

3
00:00:05.780 --> 00:00:09.840
joined by Doctor Mazria Shima. She is a senior

4
00:00:09.850 --> 00:00:12.939
lecturer in Philosophy in the School of Philosophy, Psychology

5
00:00:12.949 --> 00:00:16.670
and Language Sciences at the University of Edinburgh. And

6
00:00:16.680 --> 00:00:20.500
today we're focusing on her second book, the most

7
00:00:20.510 --> 00:00:24.040
recent when The Brain Abstracted Simplification in the History

8
00:00:24.049 --> 00:00:27.739
and Philosophy of Neuroscience. And she has another book

9
00:00:27.750 --> 00:00:32.330
also uh titled Outside Color Perceptual Science and The

10
00:00:32.340 --> 00:00:36.590
Puzzle of Color in Philosophy. So Dr Chim Muta,

11
00:00:36.599 --> 00:00:38.860
welcome to the show. It's a pleasure to everyone.

12
00:00:39.150 --> 00:00:39.310
Yeah.

13
00:00:39.319 --> 00:00:41.979
Thank, thank you, Ricardo. Thanks for inviting me. Nice

14
00:00:41.990 --> 00:00:42.580
to be here.

15
00:00:43.380 --> 00:00:47.619
So, what is the main argument that you put

16
00:00:47.630 --> 00:00:50.939
forth in your book? And what exactly is this

17
00:00:50.950 --> 00:00:56.200
idea of simplification in science and more specifically in

18
00:00:56.209 --> 00:00:57.680
neuro science?

19
00:00:57.979 --> 00:01:00.490
Yeah. Well, the main, the main argument in the

20
00:01:00.500 --> 00:01:04.500
book I I'll talk about that first. Um There's

21
00:01:04.510 --> 00:01:08.500
an overarching narrative of the book which I think

22
00:01:08.510 --> 00:01:11.120
in the context of Philosophy of neuroscience. It makes

23
00:01:11.129 --> 00:01:13.319
sense to think a bit about where philosophy of

24
00:01:13.330 --> 00:01:17.199
neuroscience originated in a, as a academic field. So

25
00:01:17.209 --> 00:01:20.440
it started in the 19 eighties through work of

26
00:01:20.449 --> 00:01:24.120
people like Paul and Patricia Churchland who developed this

27
00:01:24.129 --> 00:01:27.440
research program called Neuro Philosophy. I believe you've had

28
00:01:27.449 --> 00:01:31.959
Patricia Churchland on your own. Yeah. Yeah. Um So

29
00:01:31.970 --> 00:01:34.870
the, the aim of neuro philosophy was to look

30
00:01:34.879 --> 00:01:38.559
at all of these exciting new results in neuroscience

31
00:01:38.720 --> 00:01:41.839
and see if they could be applied to long

32
00:01:41.849 --> 00:01:44.690
standing questions within the philosophy of mind. Say about

33
00:01:44.699 --> 00:01:48.620
the nature of consciousness. What is perception, what is

34
00:01:48.629 --> 00:01:51.910
decision making? Do we have free will? Um So

35
00:01:51.919 --> 00:01:54.730
the idea was that the results of neuroscience would

36
00:01:54.739 --> 00:02:01.059
be telling us something significant and um quite readily

37
00:02:01.379 --> 00:02:05.529
interpretable to philosophers concerning the nature of cognition, the

38
00:02:05.540 --> 00:02:09.350
nature of uh the brain states which give rise

39
00:02:09.360 --> 00:02:16.250
to mental states. Um My overarching argument in the

40
00:02:16.259 --> 00:02:19.500
book is that there's a problem inherent in your

41
00:02:19.509 --> 00:02:24.809
philosophy given that um it's in it's typical and

42
00:02:24.820 --> 00:02:29.990
unavoidable in scientific practice um to simplify the subject

43
00:02:30.000 --> 00:02:33.460
matter that they're investigating. Uh So we can, we'll

44
00:02:33.470 --> 00:02:35.979
talk more about simplification as we go on in

45
00:02:35.990 --> 00:02:39.779
this interview with um uh examples and so forth.

46
00:02:40.119 --> 00:02:42.720
But the point is that the slogan, if you

47
00:02:42.729 --> 00:02:46.080
like is the brain is far more complex than

48
00:02:46.089 --> 00:02:49.964
can be represented in any one particular scientific model

49
00:02:49.975 --> 00:02:53.455
or theory. So when neuroscientists give us a model

50
00:02:53.464 --> 00:02:56.455
or a account of what decision making is what

51
00:02:56.464 --> 00:03:00.005
free will might be, what perception is, this is

52
00:03:00.014 --> 00:03:02.645
always going to be a drastic simplification of the

53
00:03:02.654 --> 00:03:05.785
actual complexity of the brain states which give rise

54
00:03:05.794 --> 00:03:10.169
to cognition. So given this mismatch between the actual

55
00:03:10.179 --> 00:03:14.460
complexity of the brain and the simplified scientific representations,

56
00:03:14.759 --> 00:03:17.979
um we can't just take neuroscience and say this

57
00:03:17.990 --> 00:03:20.610
is directly applicable to the questions that we have

58
00:03:20.619 --> 00:03:22.339
in philosophy of mind, to the things that we

59
00:03:22.350 --> 00:03:24.830
want to ask about how the brain gives rise

60
00:03:24.839 --> 00:03:29.380
to cognition and therefore what cognition um essentially is.

61
00:03:30.710 --> 00:03:34.970
So I have a very interesting quote here from

62
00:03:34.979 --> 00:03:37.929
the book. Uh AT a certain point, you say,

63
00:03:38.350 --> 00:03:43.490
as a religious and self avowedly naturalistic science and

64
00:03:43.500 --> 00:03:47.000
philosophy of science were in the century after Nietzsche,

65
00:03:47.639 --> 00:03:51.289
the basics of the belief system were not updated.

66
00:03:51.300 --> 00:03:55.979
Beauty truth and parsimony were left high on pal.

67
00:03:56.520 --> 00:03:59.860
So could you explain this particularly the second bit

68
00:03:59.869 --> 00:04:03.559
about beauty truth and parsimony? I I found really

69
00:04:03.570 --> 00:04:05.039
interesting. Yeah.

70
00:04:05.080 --> 00:04:06.770
Yeah. So this is this is from the preface

71
00:04:06.779 --> 00:04:08.160
of the book. So I was, I was being

72
00:04:08.169 --> 00:04:12.119
a little bit condensed and not exactly explaining everything

73
00:04:12.130 --> 00:04:18.100
going on the background with those ideas. Um So

74
00:04:18.108 --> 00:04:20.440
I do argue in the introduction to the book

75
00:04:20.450 --> 00:04:24.239
that one of the reasons for um the conviction

76
00:04:24.250 --> 00:04:28.149
that many scientists have that when they discover when

77
00:04:28.160 --> 00:04:31.279
they develop a simplified theory model, that this is

78
00:04:31.489 --> 00:04:36.040
discovering something inherently simple about the natural world. I

79
00:04:36.049 --> 00:04:39.140
argue that this is has some roots in um

80
00:04:39.149 --> 00:04:42.570
the theo theological background of science. So as many

81
00:04:42.790 --> 00:04:46.859
um historians of science have noticed um science didn't

82
00:04:46.869 --> 00:04:50.739
just spring up independently in a cultural vacuum. Um

83
00:04:50.750 --> 00:04:54.059
The original scientists were what's known as natural philosophers,

84
00:04:54.070 --> 00:04:58.470
people like Newton. Um um AND Galileo, of course,

85
00:04:58.480 --> 00:05:00.450
even though he's always presented as having this big

86
00:05:00.459 --> 00:05:02.929
dispute with the church, he was interested in um

87
00:05:02.940 --> 00:05:06.600
natural philosophy and ultimately theology as well. So people

88
00:05:06.609 --> 00:05:10.489
were motivated to study the natural world in order

89
00:05:10.500 --> 00:05:14.970
to find out about God through God's work. So

90
00:05:14.980 --> 00:05:21.239
natural philosophy and natural theology were interconnected disciplines. And

91
00:05:21.790 --> 00:05:25.440
one of the reasons people had the conviction and

92
00:05:25.450 --> 00:05:28.720
early on in the development of science that by

93
00:05:28.730 --> 00:05:34.040
finding simplicity um in nature, that you would learn

94
00:05:34.049 --> 00:05:37.869
something about God's mind was coming from this idea

95
00:05:37.880 --> 00:05:40.975
that God worked in a way that was rationally

96
00:05:40.984 --> 00:05:46.394
intelligible. Simple e God has a simple, eternal and

97
00:05:46.404 --> 00:05:49.255
changeable nature. All of these sort of notions that

98
00:05:49.265 --> 00:05:53.195
come quite directly from monotheism found their way as

99
00:05:53.204 --> 00:05:57.209
part of the motivation for scientists um to seek

100
00:05:57.220 --> 00:06:02.290
simplicity in nature. And um so, so um one

101
00:06:02.299 --> 00:06:05.100
of the, it's more specifically on that quotation, you

102
00:06:05.109 --> 00:06:07.790
just read out um the thing at the back

103
00:06:07.799 --> 00:06:11.700
of my mind was actually um Nietzsche's criticism of

104
00:06:11.709 --> 00:06:17.500
Plato. So, um Nietzsche um you know, obviously, uh

105
00:06:17.510 --> 00:06:20.269
thought a lot about the history of religion and

106
00:06:20.279 --> 00:06:23.559
how that connected with the history of science and

107
00:06:23.570 --> 00:06:26.980
a history of philosophy. Um He very much emphasized

108
00:06:26.989 --> 00:06:31.040
that Christianity was a version of Platonism, like a

109
00:06:31.049 --> 00:06:36.339
popularized version of Platonism. Um And a core tenet

110
00:06:36.350 --> 00:06:39.869
of the Platonic theory was that the world that

111
00:06:39.880 --> 00:06:41.769
we see around us in nature, the world of

112
00:06:41.779 --> 00:06:47.359
appearances is somehow illusory, but the underlying reality is

113
00:06:47.369 --> 00:06:50.809
simple, eternal unchanging. This is the world of the

114
00:06:50.820 --> 00:06:56.279
forms. So there's a way of thinking about platonism,

115
00:06:56.290 --> 00:06:59.679
which tells us even if nature seems complex, it's

116
00:06:59.690 --> 00:07:05.299
not complex, really underlying nature are these simple eternal

117
00:07:05.309 --> 00:07:07.559
forms and laws of nature. And you can see

118
00:07:07.570 --> 00:07:09.559
how that connects with how scientists have tried to

119
00:07:09.570 --> 00:07:14.470
investigate natures, sort of breaking down the data sets

120
00:07:14.480 --> 00:07:17.440
which seem to be really messy and complicated and,

121
00:07:17.459 --> 00:07:21.440
and looking for underlying patterns which are very intelligible

122
00:07:21.450 --> 00:07:27.940
and, and fixed. Um So Nietzsche's, um if you

123
00:07:27.950 --> 00:07:30.559
like criticism of Plato was that there's something kind

124
00:07:30.570 --> 00:07:34.019
of self deceptive about that Platonic account of knowledge,

125
00:07:34.029 --> 00:07:37.329
which is to say that what Plato thought he

126
00:07:37.339 --> 00:07:40.480
was doing is saying, oh, knowledge is just this

127
00:07:40.899 --> 00:07:45.679
contemplation, this disinterested discovery about h how nature is

128
00:07:45.690 --> 00:07:50.149
that it's not con connected with our human purposes

129
00:07:50.160 --> 00:07:53.380
and like kind of low desires just to get

130
00:07:53.390 --> 00:07:56.019
stuff and change things to how that suit us.

131
00:07:56.040 --> 00:07:58.549
And he said that was self deceptive because ultimately,

132
00:07:58.559 --> 00:08:01.720
what knowledge is directed to is will to power

133
00:08:01.730 --> 00:08:04.459
is getting more stuff that we want is furthering

134
00:08:04.470 --> 00:08:09.540
our own, like almost selfish desires. And um what

135
00:08:09.549 --> 00:08:12.790
I'm saying in that little snippet is that actually,

136
00:08:12.799 --> 00:08:15.899
if we look at science, when we think that

137
00:08:15.910 --> 00:08:19.220
science is just telling us about how nature operates

138
00:08:19.230 --> 00:08:22.859
in this kind of disinterested way. We should actually

139
00:08:22.869 --> 00:08:25.929
remember that what science is doing in the world

140
00:08:25.940 --> 00:08:28.299
today. It's very much connected with technology. It's very

141
00:08:28.309 --> 00:08:32.770
much connected with how people want to um you

142
00:08:32.780 --> 00:08:34.940
know, could be in a good sense like cure

143
00:08:34.950 --> 00:08:37.659
diseases or it could be just purely economic gain,

144
00:08:37.669 --> 00:08:40.640
but it's connected with if you like human desires

145
00:08:40.650 --> 00:08:44.359
and ambitions. So when we think of science as

146
00:08:44.369 --> 00:08:49.570
just like idealistically trying to um achieve a view

147
00:08:49.580 --> 00:08:53.380
of the world, which combines beauty, truth and parsimony,

148
00:08:53.390 --> 00:08:56.969
simplicity instead of goodness, we should remember. Actually, there's

149
00:08:56.979 --> 00:08:59.890
some more like low level ambitions there,

150
00:09:01.030 --> 00:09:03.510
right? No, II I, to be honest, I really

151
00:09:03.520 --> 00:09:06.900
had to include this quote here in our conversation

152
00:09:06.909 --> 00:09:10.030
because I'm quite fond of Nietzsche's philosophy and I've

153
00:09:10.039 --> 00:09:13.869
interviewed many niches scholars for the show. So I

154
00:09:13.880 --> 00:09:16.659
I thought that it would make for uh I

155
00:09:16.669 --> 00:09:19.929
mean, uh for, for some good observations here about

156
00:09:19.940 --> 00:09:22.130
science and related topics. So,

157
00:09:22.580 --> 00:09:25.320
yeah, I mean, certainly I think he's um he's

158
00:09:25.330 --> 00:09:28.400
right to like look at him like with heidegger

159
00:09:28.409 --> 00:09:31.409
as this prophet for the technological age, whether you

160
00:09:31.419 --> 00:09:33.809
have a positive or negative view on that. And

161
00:09:33.820 --> 00:09:35.359
I think there's a lot of insights into our

162
00:09:35.369 --> 00:09:39.309
current technological situation that we can get from um

163
00:09:39.320 --> 00:09:41.960
reading Nietzsche. And I think it's he's not so

164
00:09:41.969 --> 00:09:44.729
distant from a lot of other ideas and current

165
00:09:44.739 --> 00:09:47.169
analytic philosophy of science because there's been this big

166
00:09:47.179 --> 00:09:51.549
pragmatist turn. Um PEOPLE are not just me, plenty

167
00:09:51.559 --> 00:09:54.299
of philosophers of science are looking at how science

168
00:09:54.309 --> 00:09:58.659
is connected with technology. And and um and you

169
00:09:58.669 --> 00:10:02.039
can see parallels between what Nietzsche said and then

170
00:10:02.049 --> 00:10:06.690
late slightly um following him the American pregnancy. So

171
00:10:06.700 --> 00:10:10.750
really criticizing this view of knowledge is purely disinterested,

172
00:10:11.340 --> 00:10:15.559
right? So nowadays, we hear a lot about big

173
00:10:15.570 --> 00:10:19.210
data, data science, stuff like that. And in the

174
00:10:19.219 --> 00:10:22.349
book, you also talk at a certain point about

175
00:10:22.359 --> 00:10:26.210
the contention between what do you call a classical

176
00:10:26.219 --> 00:10:31.080
scientific approach and a data driven engineering approach. Uh

177
00:10:31.090 --> 00:10:32.599
Could you tell us about that?

178
00:10:33.260 --> 00:10:36.219
Yeah. So the classical scientific approach, you can think

179
00:10:36.229 --> 00:10:39.650
of that as a manifestation of this this Platonic

180
00:10:39.659 --> 00:10:46.150
ideal which says that a scientific theory should be

181
00:10:46.159 --> 00:10:49.500
intelligible to the person that develops it. It should

182
00:10:49.510 --> 00:10:54.400
take um a subset of the data that it's

183
00:10:54.409 --> 00:10:58.330
possible to um uh arrive at relevant to a

184
00:10:58.340 --> 00:11:02.460
particular um phenomenon and gets if you like to

185
00:11:02.469 --> 00:11:05.760
the core essential heart of what is underlying that

186
00:11:05.770 --> 00:11:09.369
data set. Uh For example, a law of nature

187
00:11:09.380 --> 00:11:12.380
which can be used to predict the data set.

188
00:11:12.760 --> 00:11:15.130
And when you have that, if you like essential

189
00:11:15.659 --> 00:11:19.380
um uh set of principles which underlie your data

190
00:11:19.390 --> 00:11:23.210
set. The idea is that this is for all

191
00:11:23.219 --> 00:11:26.330
time and space going to be the same principle

192
00:11:26.340 --> 00:11:28.760
that will explain any kind of data set anywhere

193
00:11:28.770 --> 00:11:32.010
else in the natural world relevant to this particular

194
00:11:32.159 --> 00:11:35.830
philosophy. So you have this combination of like the

195
00:11:35.840 --> 00:11:39.250
intelligibility of these principles to the scientist and the

196
00:11:39.260 --> 00:11:44.090
conviction that these principles will extrapolate, extend anywhere else

197
00:11:44.099 --> 00:11:47.330
that the scientists might want to apply them. So

198
00:11:47.340 --> 00:11:50.340
that's I think essential to this classical approach. But

199
00:11:50.349 --> 00:11:52.780
what you see in data driven science is that

200
00:11:52.789 --> 00:11:57.440
you really dial down your ambition for the intelligibility

201
00:11:57.450 --> 00:12:01.719
of um the model um that you're gonna generate

202
00:12:01.729 --> 00:12:04.219
um on the basis of your data set, you're

203
00:12:04.280 --> 00:12:08.690
ending up with mathematically much more complex models using

204
00:12:08.700 --> 00:12:13.559
machine learning, which um you can use to predict

205
00:12:13.570 --> 00:12:18.440
um items in your distribution. But you're not gonna

206
00:12:18.640 --> 00:12:20.979
have a clear cut set of principles or laws

207
00:12:20.989 --> 00:12:24.640
of nature which um help you give that, help

208
00:12:24.650 --> 00:12:26.859
you have that sense of really understanding what's going

209
00:12:26.869 --> 00:12:29.119
on in the world. So that, that, you know,

210
00:12:29.130 --> 00:12:33.510
that nice subjective feeling of, I really figured out

211
00:12:33.520 --> 00:12:37.150
how this phenomenon works. You'd you have less um

212
00:12:37.159 --> 00:12:42.770
of that. Um And your, and you're kind of

213
00:12:42.780 --> 00:12:48.929
reliant on your data set being based on uh

214
00:12:49.280 --> 00:12:51.390
when you have a novel data set, you're reliant

215
00:12:51.400 --> 00:12:53.869
on the new data being within the same distribution

216
00:12:53.880 --> 00:12:57.090
of your original data set that that model um

217
00:12:57.099 --> 00:12:59.739
was originally based on. So you kind of give

218
00:12:59.750 --> 00:13:02.849
up on that conviction that you can extrapolate for

219
00:13:02.859 --> 00:13:04.119
time and place.

220
00:13:05.630 --> 00:13:09.179
So we're going to get back to simplicity in

221
00:13:09.190 --> 00:13:12.809
a second. But since your book is focused on

222
00:13:12.820 --> 00:13:16.609
neuroscience specifically, uh what would you say are some

223
00:13:16.619 --> 00:13:20.020
of the biggest challenges with the study of the

224
00:13:20.030 --> 00:13:24.250
brain? And why is the brain, at least apparently

225
00:13:24.260 --> 00:13:25.609
so complex?

226
00:13:26.909 --> 00:13:30.929
And so with uh when we're talking about the

227
00:13:30.940 --> 00:13:34.929
complexity of an object, and I'm, I'm not a

228
00:13:34.940 --> 00:13:38.140
complexity scientist myself, um I talk a bit of

229
00:13:38.150 --> 00:13:41.090
in the introduction about, of the book about definitions

230
00:13:41.099 --> 00:13:44.289
of complexity that come from complexity science and how

231
00:13:44.299 --> 00:13:46.570
they relate a bit to what I'm doing. But

232
00:13:46.580 --> 00:13:49.830
this is just a sort of layman's two complexity

233
00:13:49.840 --> 00:13:53.010
science um take here and some ideas that are

234
00:13:53.020 --> 00:13:55.530
relevant is that when you have a complex system,

235
00:13:55.539 --> 00:13:57.500
you have a lot of heterogeneity of the parts.

236
00:13:57.510 --> 00:14:00.309
So there's if you break the system down into

237
00:14:00.320 --> 00:14:03.719
parts and look what the different individual components are,

238
00:14:03.929 --> 00:14:06.890
they'll be very different among themselves and they'll also

239
00:14:06.900 --> 00:14:10.549
tend not to be um stable or fixed in

240
00:14:10.559 --> 00:14:14.020
their um in their properties. So the parts could

241
00:14:14.030 --> 00:14:17.479
not only be various, but they can also be

242
00:14:17.489 --> 00:14:23.510
variable across time and um they'll be densely interacting

243
00:14:23.520 --> 00:14:27.140
with one another. So it's not. So it means

244
00:14:27.150 --> 00:14:30.039
that what happens over here in one part of

245
00:14:30.049 --> 00:14:33.239
the system can affect in many different ways what's

246
00:14:33.250 --> 00:14:35.679
going over here in another part of the system.

247
00:14:36.109 --> 00:14:38.049
So if you look at the brain, you see

248
00:14:38.059 --> 00:14:40.289
all of those things uh to a high degree.

249
00:14:40.299 --> 00:14:43.039
So there are very many different neuronal types within

250
00:14:43.049 --> 00:14:47.219
the brain and strict, I mean, neuro anatomists classify

251
00:14:47.229 --> 00:14:49.530
neuron types into different sorts. Like you have pedal

252
00:14:49.929 --> 00:14:52.570
cells or pinia cells and they have a like

253
00:14:52.580 --> 00:14:57.179
overall morphology which is recognizable. But if you look

254
00:14:57.190 --> 00:14:59.960
in the details, even one individual neuron looks a

255
00:14:59.969 --> 00:15:02.049
bit different from another, it's like trees in a

256
00:15:02.059 --> 00:15:06.119
forest with a branching structure means that each neuron

257
00:15:06.130 --> 00:15:09.760
has a, a little bit like people, individual characteristics.

258
00:15:09.929 --> 00:15:12.309
And these are thought to be uh functionally relevant

259
00:15:12.320 --> 00:15:16.289
as well because the different branching structures as connectivity

260
00:15:16.299 --> 00:15:20.320
within the neurons around them neurons are interconnected with

261
00:15:20.330 --> 00:15:23.640
one another to a high degree. Um That's there's

262
00:15:23.650 --> 00:15:27.479
this very, you know, trillions of synapses like the

263
00:15:27.489 --> 00:15:31.229
connecting junctions within the brain. We should, we should

264
00:15:31.239 --> 00:15:33.640
also not forget that neurons aren't the only type

265
00:15:33.650 --> 00:15:35.419
of the brain. You also have these other cells

266
00:15:35.429 --> 00:15:38.450
called glial cells, which used to be thought of

267
00:15:38.460 --> 00:15:42.159
as just like they're supporting the neurons. But actually,

268
00:15:42.169 --> 00:15:44.320
they seem to have a role in cognition except

269
00:15:44.330 --> 00:15:47.039
most people don't study them. So we know relatively

270
00:15:47.049 --> 00:15:50.859
little about them. And if we talk about the

271
00:15:50.869 --> 00:15:56.049
variability across time from um one day or month

272
00:15:56.059 --> 00:15:58.039
to the next, the brain is also changing all

273
00:15:58.049 --> 00:16:01.340
the time. So when we form memories, um what's

274
00:16:01.349 --> 00:16:03.750
happening is the brain is plastic, it's altering the

275
00:16:03.760 --> 00:16:07.780
connections between the neurons, it's altering things about the

276
00:16:07.789 --> 00:16:10.500
physiology of those neurons as well. So what you

277
00:16:10.849 --> 00:16:14.780
um so this inherent changeability is this um challenge

278
00:16:14.789 --> 00:16:18.590
for the scientific ambition in the classical sense of

279
00:16:18.599 --> 00:16:21.760
just finding fixed properties of a system which will

280
00:16:21.770 --> 00:16:23.909
always allow you to predict what will happen.

281
00:16:25.320 --> 00:16:28.909
And on the topic of simplification, you talk about

282
00:16:28.919 --> 00:16:35.010
mainly three different simplification or simplifying strategies in neuroscience.

283
00:16:35.020 --> 00:16:39.919
One of them is mathematic, another is reduction. And

284
00:16:39.929 --> 00:16:42.919
the third one is the formation of analogies between

285
00:16:42.929 --> 00:16:46.989
the complicated and familiar neural system and the simpler

286
00:16:47.000 --> 00:16:51.419
and more familiar artifact artifact. Uh Could you explain

287
00:16:51.429 --> 00:16:53.479
them? I mean, a reduction, I guess that I've

288
00:16:53.489 --> 00:16:56.030
already talked about on the show. It's a, a

289
00:16:56.039 --> 00:16:59.919
quite common topic but the uh particularly the other

290
00:16:59.929 --> 00:17:01.669
two, if you could explain them.

291
00:17:02.469 --> 00:17:06.969
Yeah, mathematic. Um So the, the quite basic thought

292
00:17:06.979 --> 00:17:09.810
here is that when you take an object in

293
00:17:09.819 --> 00:17:14.108
the natural world and describe it in mathematical terms

294
00:17:14.118 --> 00:17:17.858
with numbers and the relationships between those numbers, what

295
00:17:17.868 --> 00:17:20.750
you're doing is you're abstract away from most of

296
00:17:20.760 --> 00:17:22.839
the properties of an object. So if I look

297
00:17:22.848 --> 00:17:25.089
at the things around me, I can, it's not

298
00:17:25.098 --> 00:17:27.848
on camera, but I've got some plants around me.

299
00:17:27.858 --> 00:17:31.469
It has a whole bunch of qualitative properties. Like

300
00:17:31.479 --> 00:17:33.530
it's got the color of the leaves, the different

301
00:17:33.540 --> 00:17:36.380
different leaves have different shapes to them. But if

302
00:17:36.390 --> 00:17:39.739
you're representing mathematically, you might just say, I'm gonna

303
00:17:39.750 --> 00:17:41.719
count the number of leaves, I'm just gonna measure

304
00:17:41.729 --> 00:17:44.979
the leaves. So you're sort of rig you're converting

305
00:17:44.989 --> 00:17:47.510
all of those sort of rich kind of unique

306
00:17:47.520 --> 00:17:50.219
set of properties that I might find in as

307
00:17:50.229 --> 00:17:52.969
I look at the thing and saying, OK, what

308
00:17:52.979 --> 00:17:58.099
matters is just a few numerical variables. Um So

309
00:17:58.109 --> 00:18:02.160
that's leaving behind um a lot of the complexity

310
00:18:02.170 --> 00:18:05.770
is that is there in the natural world. So

311
00:18:07.119 --> 00:18:10.800
in, in the history of science and the current

312
00:18:10.810 --> 00:18:13.739
day um sort of background, philosophy of a lot

313
00:18:13.750 --> 00:18:16.140
of scientists, there's this idea that all of those

314
00:18:16.150 --> 00:18:19.770
qualitative details of what's there and in an object

315
00:18:19.780 --> 00:18:22.339
in the natural world are somehow irrelevant to how

316
00:18:22.349 --> 00:18:25.660
it's operating fundamentally. And I think this again goes

317
00:18:25.670 --> 00:18:27.760
back to this Platonic tradition. So if you think

318
00:18:27.770 --> 00:18:32.359
about what Plato said about um the world, he,

319
00:18:32.369 --> 00:18:35.260
he was almost uh there's things that approach, this

320
00:18:35.270 --> 00:18:40.180
idea that the maths um geometry is more real

321
00:18:40.209 --> 00:18:42.680
than what we experience of the world through our

322
00:18:42.689 --> 00:18:48.949
senses. So, underlying this imperfect um messy, not hard

323
00:18:48.959 --> 00:18:52.510
to define sensory world of appearances. There is a

324
00:18:52.520 --> 00:18:57.810
geometric structure underlying everything. Um So when scientists mathematic,

325
00:18:57.819 --> 00:19:00.430
I think they often think to themselves, well, we're

326
00:19:00.439 --> 00:19:03.619
just to the essences with the essential properties of

327
00:19:03.630 --> 00:19:06.719
what's there. But what I'm saying is that actually

328
00:19:06.859 --> 00:19:11.199
they're using a simplifying strategy. All of those details

329
00:19:11.209 --> 00:19:14.229
are there in the real object in the natural

330
00:19:14.239 --> 00:19:17.489
world, whether it's a plant or someone's brain. And

331
00:19:17.500 --> 00:19:21.339
maybe those details do matter to what that um

332
00:19:21.449 --> 00:19:24.609
object essentially is as a, as a living thing.

333
00:19:25.290 --> 00:19:28.250
Um You mentioned that reduction is uh often talk

334
00:19:28.260 --> 00:19:31.380
about because uh reductionism is one of those uh

335
00:19:31.400 --> 00:19:33.729
words that has a bad name almost in, in

336
00:19:33.739 --> 00:19:36.439
biology. It's, it's been a very useful strategy. I

337
00:19:36.449 --> 00:19:38.829
mean, all it means is instead of trying to

338
00:19:38.839 --> 00:19:41.689
take a whole organism or a whole organ organ

339
00:19:41.699 --> 00:19:44.890
by itself as a whole system, you begin with

340
00:19:44.900 --> 00:19:48.260
analyzing the parts, the building blocks with a hope

341
00:19:48.270 --> 00:19:51.109
or expectation that by studying those parts, you'll get

342
00:19:51.119 --> 00:19:54.619
some insights into the whole. Now it has limitations

343
00:19:54.630 --> 00:19:58.219
because um if you study parts in isolation, when

344
00:19:58.229 --> 00:20:02.089
you're dealing with a complex system, the parts behavior

345
00:20:02.099 --> 00:20:05.750
will be context dependent, which means that you'll be

346
00:20:05.760 --> 00:20:08.670
limited in what you can discover about even about

347
00:20:08.680 --> 00:20:11.229
the parts by looking at them independently of the

348
00:20:11.239 --> 00:20:14.560
whole system. So it has, it has certainly has

349
00:20:14.569 --> 00:20:19.650
its place certainly with um technological ambitions. Um But

350
00:20:19.660 --> 00:20:21.469
yeah, it's, it can't be the whole story about

351
00:20:21.479 --> 00:20:26.540
how living organisms work. Um But yeah, forming analogies

352
00:20:26.550 --> 00:20:28.729
though, I write a lot about that in the

353
00:20:28.739 --> 00:20:34.000
book because um the notion of the computer as

354
00:20:34.010 --> 00:20:37.869
an analogy for what brains are, um I'm saying

355
00:20:37.880 --> 00:20:42.229
has been hugely influential and dominant in the recent

356
00:20:42.239 --> 00:20:46.270
history of neuroscience. So a nice way of thinking

357
00:20:46.280 --> 00:20:49.869
about why analogies are important in science is that

358
00:20:49.880 --> 00:20:52.910
if we look at the world around us, of

359
00:20:52.920 --> 00:20:57.670
living objects, um they're complex and it's kind of

360
00:20:57.680 --> 00:21:01.079
opaque what's going on inside them. Um Going back

361
00:21:01.089 --> 00:21:05.369
to Aristotle people who looked at living objects like

362
00:21:05.719 --> 00:21:10.099
um uh and, and thought about them. In terms

363
00:21:10.109 --> 00:21:12.459
of all the parts of a living object have

364
00:21:12.469 --> 00:21:15.660
um functions. They're a bit tool like so hand

365
00:21:15.829 --> 00:21:17.270
you might think of it. Well, it's like a

366
00:21:17.280 --> 00:21:20.489
pining tool. It's like a grasping tool. There's all

367
00:21:20.500 --> 00:21:23.199
of this, if you like seeming goal directed in

368
00:21:23.209 --> 00:21:29.530
living objects and when you um make comparisons between

369
00:21:29.540 --> 00:21:33.689
living objects or the organs, organ literally means tool.

370
00:21:33.699 --> 00:21:35.770
By the way, that's where the world is thrive

371
00:21:35.780 --> 00:21:37.969
for a living organ. And you make a comparison

372
00:21:38.060 --> 00:21:41.050
with a tool that someone has made then that

373
00:21:41.060 --> 00:21:43.719
gives you like a clue. And maybe I understand

374
00:21:43.939 --> 00:21:49.030
how this um living organ works. If I know

375
00:21:49.040 --> 00:21:53.170
the principles of how this um artifact, how this

376
00:21:53.180 --> 00:21:55.910
tool that someone has made according to their own

377
00:21:55.920 --> 00:22:00.949
um understanding of physical um relationships, then I think,

378
00:22:00.959 --> 00:22:04.869
well, maybe in nature, this is um how, how,

379
00:22:04.880 --> 00:22:08.189
what the principles of operation are behind this organ.

380
00:22:08.729 --> 00:22:11.339
So what I'm saying, I mean, analogies don't only

381
00:22:11.349 --> 00:22:13.099
figure in biology, but I think they have a

382
00:22:13.109 --> 00:22:17.170
very particular role in the biological sciences because of

383
00:22:17.180 --> 00:22:22.000
this comparison between like the um the tool, like

384
00:22:22.010 --> 00:22:26.189
nature of many living things and the way that

385
00:22:26.199 --> 00:22:29.349
people have built so many different tools and then

386
00:22:29.829 --> 00:22:31.989
have ideas about how those work, which then get

387
00:22:32.000 --> 00:22:35.140
imported into their understanding of biological items.

388
00:22:36.260 --> 00:22:39.369
Yes, we're going to get back to the computer

389
00:22:39.380 --> 00:22:42.469
metaphor of the brain in a bit. Uh But

390
00:22:42.479 --> 00:22:48.229
before that, why do scientists seek simplicity? I mean,

391
00:22:48.239 --> 00:22:53.189
is this something that is just unavoidable? And what

392
00:22:53.199 --> 00:22:56.959
are the goals that they have in mind with

393
00:22:56.969 --> 00:22:58.010
simplicity?

394
00:22:58.369 --> 00:23:01.310
Yeah. So, so this this goes back to that

395
00:23:01.319 --> 00:23:04.650
divide between Plato and Nietzsche ultimately. So if you

396
00:23:04.660 --> 00:23:10.160
ask AAA Platonist broadly speaking in, in that broad

397
00:23:10.170 --> 00:23:14.449
tradition, why scientists would seek um simplicity, they would

398
00:23:14.459 --> 00:23:18.770
say well, because nature inherently is simple. So when

399
00:23:18.780 --> 00:23:22.550
you, when you find some simple laws or principles

400
00:23:22.560 --> 00:23:25.420
in nature, you have discovered the truth about reality

401
00:23:25.430 --> 00:23:30.060
that was hidden before you did your investigation. If

402
00:23:30.069 --> 00:23:32.400
you ask a Nietzsche and this is the camp

403
00:23:32.410 --> 00:23:33.949
that I'm in. This is the argument that I'm

404
00:23:33.959 --> 00:23:38.949
presenting in this book, I'm saying, scientists seek simplicity

405
00:23:38.959 --> 00:23:42.829
because they want to control the natural world, humans

406
00:23:42.839 --> 00:23:45.949
are limited in their cognitive capacities. If we try

407
00:23:45.959 --> 00:23:49.900
to just take in all of the complexity that's

408
00:23:49.910 --> 00:23:51.800
there in nature, like you have to keep track

409
00:23:51.810 --> 00:23:55.199
of all of the different individual items and how

410
00:23:55.209 --> 00:23:57.540
they change from day to day and how they

411
00:23:57.550 --> 00:24:00.959
interact with one another. And we'd just be hopelessly

412
00:24:00.969 --> 00:24:02.699
confused. We wouldn't be able to keep track of

413
00:24:02.709 --> 00:24:07.750
anything. Um Human language is itself a simplifying scheme

414
00:24:07.760 --> 00:24:10.109
because when I talk about leaves on this plant

415
00:24:10.119 --> 00:24:12.550
next to me, I'm using that one word leaf

416
00:24:12.560 --> 00:24:15.709
to apply to all of those items which by

417
00:24:15.719 --> 00:24:19.400
themselves actually have these differences. So I'm saying science

418
00:24:19.410 --> 00:24:23.880
kind of exaggerates that it, it imposes simplifying schemes

419
00:24:23.890 --> 00:24:27.229
on natural objects so that we're not cognitively overloaded

420
00:24:27.540 --> 00:24:31.579
and we can focus on certain relationships of dependencies,

421
00:24:31.589 --> 00:24:34.920
certain causal relationships that people will want to control

422
00:24:34.930 --> 00:24:37.619
and manipulate in order to get the results that

423
00:24:37.630 --> 00:24:39.439
they want in the world around them.

424
00:24:40.819 --> 00:24:43.699
But I, I mean, just to clarify one point

425
00:24:43.709 --> 00:24:46.329
here, uh how do you look at that? I

426
00:24:46.339 --> 00:24:48.829
mean, do you think about it as a simply

427
00:24:48.839 --> 00:24:53.359
a limitation but a sort of unavoidable limitation of

428
00:24:53.369 --> 00:24:58.739
our even our cognition itself? So there's no problem

429
00:24:58.750 --> 00:25:01.680
with that. It's just a matter of scientists being

430
00:25:01.689 --> 00:25:05.189
aware of that and in the way that it

431
00:25:05.199 --> 00:25:09.260
should weigh on their interpretations of the data and

432
00:25:09.270 --> 00:25:14.089
so on or is it actually something problematic that

433
00:25:14.099 --> 00:25:18.160
we should try to overcome in specific ways?

434
00:25:18.270 --> 00:25:22.229
Yeah. So I think it's more the form, there

435
00:25:22.239 --> 00:25:24.949
is an inherent limitation on how much a human

436
00:25:24.959 --> 00:25:27.709
being can understand in terms of how many variables

437
00:25:27.719 --> 00:25:28.989
in a model that are going to be able

438
00:25:29.000 --> 00:25:32.390
to make sense of. Like we can't think in

439
00:25:32.660 --> 00:25:36.099
much more than three dimensions because you know how

440
00:25:36.109 --> 00:25:39.160
our sensory experience of the world is. We live

441
00:25:39.170 --> 00:25:41.839
in this 3d space and we have intuitions about

442
00:25:41.849 --> 00:25:44.150
three dimensions can kind of stretch it to four

443
00:25:44.160 --> 00:25:46.439
and five when you have a 10 or more

444
00:25:46.469 --> 00:25:49.939
dimensional data set, your intuitions about what goes on

445
00:25:49.949 --> 00:25:51.619
is going to break down. So I think that

446
00:25:51.630 --> 00:25:54.160
that is an inherent limitation, but I think that

447
00:25:54.170 --> 00:25:57.359
there are some schemers or way of thinking that

448
00:25:57.369 --> 00:26:00.300
people use, that could be more or less drastically

449
00:26:00.310 --> 00:26:04.560
simplified. I actually think that when people use metaphors

450
00:26:04.569 --> 00:26:08.099
to understand the world in literature, the part of

451
00:26:08.109 --> 00:26:11.109
the value of metaphorical language can actually be that

452
00:26:11.119 --> 00:26:13.050
it, it kind of encompasses a bit more of

453
00:26:13.060 --> 00:26:20.140
the complexity and the inherent almost vagueness or changeability

454
00:26:20.150 --> 00:26:23.859
of things in nature. So I think as um

455
00:26:24.479 --> 00:26:27.000
science has become more and more dominant as a

456
00:26:27.010 --> 00:26:29.540
way of thinking of the world, it's maybe tempted

457
00:26:29.550 --> 00:26:34.530
people to underestimate um how much of things in

458
00:26:34.540 --> 00:26:37.589
the world around them are complex and interdependent. And

459
00:26:37.599 --> 00:26:40.719
there are other um ways of thinking and you

460
00:26:40.729 --> 00:26:43.430
can think historically and also cross culturally that maybe

461
00:26:43.439 --> 00:26:45.250
are more sensitive to that. So I think it's

462
00:26:45.260 --> 00:26:49.000
important to be pluralistic. So given that science has

463
00:26:49.010 --> 00:26:51.930
to simplify it, we should also say that it's

464
00:26:51.939 --> 00:26:55.760
worth also um paying value to even within sciences,

465
00:26:55.770 --> 00:26:59.339
different approaches that maybe simplify less drastically and also

466
00:26:59.349 --> 00:27:01.969
outside of science um ways that we can be

467
00:27:01.979 --> 00:27:04.989
more sensitive to complexity, even if we can't fully

468
00:27:05.000 --> 00:27:06.949
grasp it in all of its details.

469
00:27:07.319 --> 00:27:10.939
You mentioned pluralism there. I want to ask you

470
00:27:10.949 --> 00:27:13.790
a, a specific question about that. So in the

471
00:27:13.800 --> 00:27:17.569
book, you take preference for a more pluralist and

472
00:27:17.579 --> 00:27:22.180
perspective is approach to neuroscience in this case over

473
00:27:22.219 --> 00:27:27.459
a sort of standard scientific realism and empiricism approach.

474
00:27:27.719 --> 00:27:32.349
Uh WHY? And uh what does that mean? Exactly.

475
00:27:32.780 --> 00:27:36.010
Yeah. So, so to use our sort of platonic

476
00:27:36.020 --> 00:27:38.160
figurehead again and again, I don't want to say

477
00:27:38.170 --> 00:27:41.000
this is all like stemming from Plato's dialogues down

478
00:27:41.010 --> 00:27:43.300
today. But just like following this idea that there

479
00:27:43.310 --> 00:27:47.010
is a consistent lineage here. So that I'm saying

480
00:27:47.150 --> 00:27:50.719
essentially that if you take scientific realism today, there's

481
00:27:50.729 --> 00:27:54.459
something platonic about it. So the mainstream scientific realists,

482
00:27:54.469 --> 00:27:59.160
they say our best scientific theories are giving us

483
00:27:59.170 --> 00:28:04.229
a representation of how things are um in nature,

484
00:28:04.239 --> 00:28:07.369
which are not observable to our senses. So um

485
00:28:07.380 --> 00:28:10.810
a classic example for scientific realism would be to

486
00:28:10.819 --> 00:28:14.819
say when a the theory in physics posits electrons

487
00:28:14.829 --> 00:28:17.569
in order to explain certain phenomena, you know, you

488
00:28:17.579 --> 00:28:21.339
might observe electric shocks and things like that, you

489
00:28:21.349 --> 00:28:23.949
have good reason to say that those particles electrons

490
00:28:23.959 --> 00:28:30.439
exist. Um So they're saying that there is if

491
00:28:30.449 --> 00:28:33.170
you like a world behind the senses and that

492
00:28:33.180 --> 00:28:36.130
is what the scientists are allowing us to know

493
00:28:36.140 --> 00:28:41.199
about. So empiricists, they actually were very uh resistant

494
00:28:41.209 --> 00:28:45.000
to this metaphysical um interpretation of science. And they,

495
00:28:45.290 --> 00:28:48.229
they're actually almost um a bit Nietzsche in here

496
00:28:48.329 --> 00:28:51.180
and in posts like Ernst mark, actually, people made

497
00:28:51.189 --> 00:28:53.719
the connection between him and Nietzsche, which is interesting.

498
00:28:54.079 --> 00:28:56.959
Uh So he's another 19th century uh scientist and

499
00:28:56.969 --> 00:29:00.619
philosopher and he said actually all we have is

500
00:29:00.630 --> 00:29:03.390
the world of appearances, we have lots of sensory

501
00:29:03.400 --> 00:29:06.750
data. What science is doing is just finding connections

502
00:29:06.760 --> 00:29:10.300
between this data and representing them in an economical

503
00:29:10.310 --> 00:29:15.079
way. Um So in this sort of um divide

504
00:29:15.089 --> 00:29:20.510
between uh classical scientific realism and empiricism, I'm sort

505
00:29:20.520 --> 00:29:25.400
of fairly sympathetic to this empiricist um tradition. So

506
00:29:25.410 --> 00:29:28.609
in saying that like with, as Mark said, we

507
00:29:28.619 --> 00:29:31.770
shouldn't interpret our scientific theories as like telling us

508
00:29:31.780 --> 00:29:34.910
simple laws and principles which exist behind the century

509
00:29:34.920 --> 00:29:39.449
data. Um For me, this debate about the existence

510
00:29:39.459 --> 00:29:43.390
of particles is not relevant because I'm not talking

511
00:29:43.400 --> 00:29:46.459
about physics. I'm talking about objects in biology, which

512
00:29:46.469 --> 00:29:49.989
everyone can observe. But the question is, should we

513
00:29:50.000 --> 00:29:52.780
be realist in our interpretation of the theories and

514
00:29:52.790 --> 00:29:55.609
models that scientists develop? And what I'm saying is

515
00:29:55.619 --> 00:29:59.780
that when those theories and models um impose simplifications

516
00:29:59.790 --> 00:30:04.060
on the observable data that we can encounter regarding

517
00:30:04.069 --> 00:30:08.540
those systems, we shouldn't believe that the simplification is

518
00:30:08.550 --> 00:30:12.199
more real than the actual observable data and saying

519
00:30:12.209 --> 00:30:18.810
that actually um nature is irreducibly complex. And for

520
00:30:18.819 --> 00:30:26.069
this reason, multiple um theoretical approaches are all needed

521
00:30:26.079 --> 00:30:29.010
because if you think of it as a mountain

522
00:30:29.020 --> 00:30:31.660
with needing lots of viewpoints on it there, um

523
00:30:31.810 --> 00:30:34.949
You, you can, you can't take in in one

524
00:30:34.959 --> 00:30:39.074
view all of the complexity, all of the operations

525
00:30:39.084 --> 00:30:41.045
that are there in that one system. So you

526
00:30:41.055 --> 00:30:44.204
need multiple viewpoints in order for each of them

527
00:30:44.214 --> 00:30:46.604
to sort of grasp something about what's going on.

528
00:30:46.694 --> 00:30:49.175
So this is what motivates the pluralism. It actually

529
00:30:49.185 --> 00:30:52.500
is founded on this idea that underlying everything is

530
00:30:52.510 --> 00:30:55.869
just this irreducible complexity. And we can only grasp

531
00:30:55.880 --> 00:31:00.319
it in, in these small um piecemeal approaches. If

532
00:31:00.329 --> 00:31:02.369
you can think of each approach as like one

533
00:31:02.380 --> 00:31:04.920
viewpoint, one perspective on a thing I know you've

534
00:31:04.930 --> 00:31:07.439
had on your uh podcast, Mia mastery who at

535
00:31:07.949 --> 00:31:12.520
length on perspective. So I'll let your listeners go

536
00:31:12.530 --> 00:31:15.489
to that episode to him or specifically what this

537
00:31:15.500 --> 00:31:17.069
notion of perspective is, is.

538
00:31:17.479 --> 00:31:20.670
Yeah. Yeah. It, it was a great episode and

539
00:31:20.680 --> 00:31:22.959
I will link to it in the description of

540
00:31:22.969 --> 00:31:26.089
this one. So uh in the book, you go

541
00:31:26.099 --> 00:31:30.300
through an example, I guess an illustrative example of

542
00:31:30.310 --> 00:31:35.800
an early theory in neuroscience reflects a theory that

543
00:31:35.979 --> 00:31:40.060
got very popular theory about the organization of the

544
00:31:40.069 --> 00:31:44.609
brain and the nervous system that then uh later

545
00:31:44.619 --> 00:31:48.280
was dis discarded. Could you tell us about it?

546
00:31:48.479 --> 00:31:52.280
Uh WHAT reflects the theory was and how and

547
00:31:52.290 --> 00:31:55.839
why it fell and perhaps then we can get

548
00:31:55.849 --> 00:31:58.880
a better understanding of why it might be lust

549
00:31:58.900 --> 00:32:01.719
of some of the issues you're pointing to in

550
00:32:01.729 --> 00:32:01.880
the

551
00:32:01.890 --> 00:32:06.160
book. Yeah. Yeah. So the um reflex theory, it

552
00:32:06.170 --> 00:32:09.869
was it was dominant. So just before the start

553
00:32:09.880 --> 00:32:12.849
of the 20th century going into the 19 thirties,

554
00:32:12.859 --> 00:32:15.329
so that's the time period we're talking about. So

555
00:32:15.339 --> 00:32:20.140
it rose um following some really important discoveries about

556
00:32:20.150 --> 00:32:25.810
um neurophysiology that happened um mid 19th century. Um

557
00:32:25.819 --> 00:32:29.729
So people had like theorized about reflex action since

558
00:32:29.739 --> 00:32:31.949
the 17th century, since dear. But what happened in

559
00:32:31.959 --> 00:32:35.209
the 19th century with more detailed um probing of

560
00:32:35.219 --> 00:32:38.150
the nervous system was that um this is Charles

561
00:32:38.160 --> 00:32:40.890
Bell. Um There one figure that found this is

562
00:32:40.900 --> 00:32:45.839
that people um found that there was different nerves

563
00:32:45.890 --> 00:32:49.270
um that were responsible for uh sensory input into

564
00:32:49.280 --> 00:32:51.430
the spine. And then another set of nerves which

565
00:32:51.439 --> 00:32:55.150
sort of linked um in an arc connected to

566
00:32:55.160 --> 00:32:58.719
that responsible for the motor response, the movement that

567
00:32:58.729 --> 00:33:02.349
was um uh ha would happen in response to

568
00:33:02.359 --> 00:33:04.530
the sensory input. So if you think about what

569
00:33:04.540 --> 00:33:08.359
reflexes are like the kneecap reflex that the doctor

570
00:33:08.369 --> 00:33:12.270
might do, that's giving you a particular sensory input.

571
00:33:12.280 --> 00:33:15.050
And you have this very predictable motor response and

572
00:33:15.060 --> 00:33:18.530
reaction to that or if someone uh throws an

573
00:33:18.540 --> 00:33:21.130
object towards your eye, you immediately blink. So there's

574
00:33:21.140 --> 00:33:25.530
this quick um sensory response um elicited in the

575
00:33:25.540 --> 00:33:29.859
quick motor output. Um So this idea of sort

576
00:33:29.869 --> 00:33:34.199
of decomposing the nervous system into the sensory input

577
00:33:34.209 --> 00:33:38.010
side and the motor output side, um they would

578
00:33:38.020 --> 00:33:42.310
be linked at the spinal cord. Um This served

579
00:33:42.319 --> 00:33:46.489
to explain many behaviors and responses like the eye

580
00:33:46.500 --> 00:33:51.349
blink and the various um other um reflexes with

581
00:33:51.359 --> 00:33:55.099
the limbs. So these were like success stories for

582
00:33:55.109 --> 00:33:58.119
neurophysiology at the time. And then what people did

583
00:33:58.130 --> 00:34:02.599
is kind of extrapolate from that and say, well,

584
00:34:02.609 --> 00:34:05.449
what if everything that the brain and nervous system

585
00:34:05.459 --> 00:34:10.280
is doing is actually a kind of reflex response.

586
00:34:10.530 --> 00:34:12.860
So what if, what's going on in the brain

587
00:34:13.000 --> 00:34:17.379
is actually more reflexes coming in being connected with

588
00:34:17.389 --> 00:34:21.350
another set of motor outputs and then everything that

589
00:34:21.360 --> 00:34:26.739
someone says and does might ultimately be decomposable into

590
00:34:26.750 --> 00:34:31.148
a set of um reflex responses. So what I

591
00:34:31.158 --> 00:34:34.089
say in um um in the book or explain

592
00:34:34.099 --> 00:34:36.039
in the book is that it's a kind of

593
00:34:36.049 --> 00:34:40.197
reductionism. So looking at the parts of the nervous

594
00:34:40.208 --> 00:34:42.849
system as reflexes. So if you like it's a

595
00:34:42.858 --> 00:34:48.947
physiological part, these isolated sensory motor responses are what

596
00:34:48.958 --> 00:34:51.529
the building blocks of the nervous system are. So

597
00:34:51.539 --> 00:34:56.178
the thought is if we just study reflexes, then

598
00:34:56.188 --> 00:34:59.349
ultimately, we're going to be able to explain more

599
00:34:59.358 --> 00:35:04.678
complex um behaviors and um neural responses. So, some

600
00:35:04.688 --> 00:35:08.539
of the very major uh early 20th century uh

601
00:35:08.549 --> 00:35:12.878
neurophysiologist like Charles Sherrington spent a lot of their

602
00:35:12.888 --> 00:35:17.719
career um studying reflex responses in dogs and cats

603
00:35:17.729 --> 00:35:21.600
um under certain experimental preparations, which were used to

604
00:35:21.610 --> 00:35:27.520
kind of generate more predictive, predictable reflex uh like

605
00:35:27.530 --> 00:35:35.280
responses. Um But ultimately, um this um approach fell

606
00:35:35.290 --> 00:35:38.810
out of favor because um there were just too

607
00:35:38.820 --> 00:35:44.100
many um anomalies, too many um cases where it

608
00:35:44.110 --> 00:35:47.469
just became clear that the um the reflex theory

609
00:35:47.479 --> 00:35:51.399
was not able to explain this universally in neuroscience

610
00:35:51.409 --> 00:35:53.689
in the way that people had thought. But I

611
00:35:53.699 --> 00:35:55.899
should also mention that there was a lot of

612
00:35:55.909 --> 00:35:59.719
overlap in the twenties and thirties that developed between

613
00:35:59.729 --> 00:36:03.719
this reflex theory and behavioral psychology. So the notion

614
00:36:03.729 --> 00:36:08.520
that ultimately, what we're doing when we behave is

615
00:36:08.530 --> 00:36:14.719
sort of um forming um predictable responses to these

616
00:36:14.729 --> 00:36:17.500
um sensory inputs. You can see how there's a

617
00:36:17.510 --> 00:36:21.389
psychology version of that. So as Pavlov described, you

618
00:36:21.399 --> 00:36:24.020
know, the dog that salivates to food and then

619
00:36:24.030 --> 00:36:26.560
you condition it and it salivates to the bell

620
00:36:26.570 --> 00:36:29.239
as well. What you're looking for is this very

621
00:36:29.250 --> 00:36:32.489
tight connection between a sensory input and a behavioral

622
00:36:32.500 --> 00:36:35.770
output. So that behavioral level is in psychology is

623
00:36:35.780 --> 00:36:40.520
being paralleled with this um neural level within the

624
00:36:40.530 --> 00:36:41.320
physiology.

625
00:36:42.469 --> 00:36:45.889
So in the context of the thesis you present

626
00:36:45.899 --> 00:36:48.800
in the book, what would you say reflects a

627
00:36:48.810 --> 00:36:52.149
theory is illustrative of? Exactly.

628
00:36:52.770 --> 00:36:54.969
Yeah. So I'm using it if you like as

629
00:36:54.979 --> 00:36:59.409
a cautionary tale to say that if if you

630
00:36:59.419 --> 00:37:03.350
want to explain why scientists were so attracted to

631
00:37:03.360 --> 00:37:06.889
this theory, even though looking at it in retrospect,

632
00:37:06.899 --> 00:37:10.479
it seems so vastly oversimplified that how you you

633
00:37:10.489 --> 00:37:13.310
ask yourself, how could anyone have been convinced that

634
00:37:13.320 --> 00:37:15.280
this could be true? How could anyone think that

635
00:37:15.469 --> 00:37:17.429
everything that's going on within the brain will just

636
00:37:17.439 --> 00:37:20.929
boil down to sensory motor reflexes? What I'm saying

637
00:37:20.939 --> 00:37:25.939
is it illustrates how alluring how compelling the goal

638
00:37:25.949 --> 00:37:30.229
of simplicity can be. So once scientists are just

639
00:37:30.239 --> 00:37:33.020
trying to find the simplest theory, they can be

640
00:37:33.030 --> 00:37:38.169
misled into believing in a theory that in retrospect

641
00:37:38.179 --> 00:37:40.929
is must be completely wrong. And so then you

642
00:37:40.939 --> 00:37:44.090
have to ask, well, what in science today might

643
00:37:44.100 --> 00:37:47.360
people be convinced by? Because they're so want to

644
00:37:47.370 --> 00:37:50.459
believe in the simplicity that they ignore all of

645
00:37:50.469 --> 00:37:52.580
the reasons for thinking. Well, this couldn't possibly be

646
00:37:52.590 --> 00:37:52.989
true.

647
00:37:54.340 --> 00:38:00.020
So after reflex theory of course, uh came the

648
00:38:00.030 --> 00:38:04.520
rise of uh the idea that neural processes that

649
00:38:04.530 --> 00:38:10.300
give rise to cognition are essentially computational. So what

650
00:38:10.310 --> 00:38:15.000
does it mean for something to be computational? Specifically

651
00:38:15.090 --> 00:38:20.120
the brain or neural processes? Uh WHAT does computational

652
00:38:20.129 --> 00:38:21.600
mean exactly?

653
00:38:21.989 --> 00:38:25.169
Yeah, I mean computational theory is a branch of

654
00:38:25.179 --> 00:38:28.080
mathematics which is to do with uh what functions

655
00:38:28.090 --> 00:38:30.929
are. So a function in mathematics is a fixed

656
00:38:30.939 --> 00:38:34.570
relationship between an input and an output. Um So

657
00:38:34.580 --> 00:38:37.129
addition, the function if you for any two numbers

658
00:38:37.139 --> 00:38:41.750
or any or more numbers, um um the addition

659
00:38:41.760 --> 00:38:44.820
function maps that onto a specific answer, which is

660
00:38:44.830 --> 00:38:46.790
the sum of those numbers. So you can think

661
00:38:46.800 --> 00:38:50.870
of a computation as describing this process that gets

662
00:38:50.879 --> 00:38:53.709
you from the input to the output um as

663
00:38:53.719 --> 00:38:58.280
described by the mathematical function. So in the context

664
00:38:58.290 --> 00:39:02.360
of neuroscience, um saying that the brain or an

665
00:39:02.370 --> 00:39:06.219
individual neuron even is a co is computational is

666
00:39:06.229 --> 00:39:08.889
saying that what it's doing is it's taking inputs

667
00:39:09.149 --> 00:39:13.280
and converting them uh in a well governed way

668
00:39:13.290 --> 00:39:15.570
to an output. The rule governed way uh defined

669
00:39:15.580 --> 00:39:20.820
by the function. And so this idea of transferring

670
00:39:20.830 --> 00:39:25.159
computational ideas to neuroscience very happened very early in

671
00:39:25.169 --> 00:39:29.010
the history of um the invention of computers. So,

672
00:39:29.020 --> 00:39:32.679
you know, if you think of uh yeah, the

673
00:39:32.689 --> 00:39:36.000
digital computer based on Alan Turing's ideas, they were

674
00:39:36.010 --> 00:39:39.649
developed during the war, uh second World War and

675
00:39:39.659 --> 00:39:42.590
it was actually in 1943 with mcculloch and Pitts.

676
00:39:42.600 --> 00:39:46.969
Um This notion that individual neurons could be computational

677
00:39:46.979 --> 00:39:51.689
devices was 1st 1st proposed. So they thought that

678
00:39:51.699 --> 00:39:54.850
the dendrites of the neurons, the parts of the

679
00:39:54.860 --> 00:39:59.219
neurons which um standardly taken just to receive like

680
00:39:59.229 --> 00:40:03.209
inputs from another neuron around them. Phys. What this

681
00:40:03.219 --> 00:40:05.669
actually means in the concrete world is just that

682
00:40:06.000 --> 00:40:10.300
the um dendrites of the neurons are sensitive to

683
00:40:10.310 --> 00:40:14.469
neurotransmitters that are coming from previous neurons. And this

684
00:40:14.479 --> 00:40:17.739
modulates the electrical excitability of this neuron that is

685
00:40:17.750 --> 00:40:21.540
receiving that neurotransmitter. Um But the thought was OK

686
00:40:21.550 --> 00:40:23.649
is that you have these dendron. So the input

687
00:40:23.659 --> 00:40:27.290
and the body of the neuron performs a computation

688
00:40:27.500 --> 00:40:30.689
and this converts the signal on the output end

689
00:40:31.020 --> 00:40:34.229
which will then go and um affect other neurons

690
00:40:34.239 --> 00:40:38.409
in the network. Um So saying that that's how

691
00:40:38.419 --> 00:40:41.250
you can say that an individual neuron is um

692
00:40:41.600 --> 00:40:45.290
computational. If you just take those notions of input

693
00:40:45.300 --> 00:40:48.850
output and function um connecting them and sort of

694
00:40:48.860 --> 00:40:53.610
impose that template onto neurophysiology. And if you're thinking

695
00:40:53.620 --> 00:40:55.939
of the brain as a whole being computational, people

696
00:40:55.949 --> 00:40:58.179
would think in terms of like the whole, all

697
00:40:58.189 --> 00:41:01.000
of our sensory systems being the inputs, we're taking

698
00:41:01.010 --> 00:41:03.969
data from the world in the center of our

699
00:41:03.979 --> 00:41:10.320
brains, we're performing this operation that converts those inputs

700
00:41:10.330 --> 00:41:14.459
into a certain output. So the output would be

701
00:41:14.580 --> 00:41:17.739
uh motor signals which shows what behavior is so

702
00:41:17.750 --> 00:41:21.209
when I'm talking, um that's possible because my brain

703
00:41:21.219 --> 00:41:23.500
is sending signals to my voice box. And so

704
00:41:23.510 --> 00:41:26.110
if you like all behavior that ultimately is this

705
00:41:26.120 --> 00:41:27.679
motor output.

706
00:41:28.830 --> 00:41:31.770
So in the case of computational models of the

707
00:41:31.780 --> 00:41:36.959
brain, are we working with an analogy here or

708
00:41:36.969 --> 00:41:37.330
not?

709
00:41:38.169 --> 00:41:42.709
Yeah. So I'm arguing that it's an analogy. Um

710
00:41:43.560 --> 00:41:47.219
I, I point out though that the dominant view

711
00:41:47.229 --> 00:41:50.000
I'd say amongst neuroscientists themselves and many people that

712
00:41:50.010 --> 00:41:54.350
do philosophy of neuroscience says that the brain literally

713
00:41:54.360 --> 00:41:57.709
is a computer. It's not just an analogy or,

714
00:41:58.409 --> 00:42:00.580
or a comparison that one could make, but they're

715
00:42:00.590 --> 00:42:04.270
saying that inherently the brain uh is a computational

716
00:42:04.280 --> 00:42:08.810
device. Um What I'm arguing instead is that no,

717
00:42:08.820 --> 00:42:11.189
for reasons to do with what I talked about

718
00:42:11.199 --> 00:42:15.310
before that it's useful um for scientists to think

719
00:42:15.320 --> 00:42:18.620
about biological organs in terms of tools that people

720
00:42:18.629 --> 00:42:21.625
have made. Um THAT gives them a if you

721
00:42:21.635 --> 00:42:24.044
like a way to try and thinking about how

722
00:42:24.054 --> 00:42:26.985
the biological organ might work. So, and so for

723
00:42:26.995 --> 00:42:29.425
that reason, people have been very attracted to the

724
00:42:29.435 --> 00:42:33.504
comparison between brains and computers, not least because um

725
00:42:33.514 --> 00:42:39.024
computers were designed in order to do tasks which

726
00:42:39.034 --> 00:42:42.215
people um use their brains for to do cognitive

727
00:42:42.225 --> 00:42:44.905
tasks. So the turing's vision of what the computer

728
00:42:44.915 --> 00:42:49.350
was originally was to replace um the human computer.

729
00:42:49.360 --> 00:42:52.169
So the digital computer was simply performing the tasks

730
00:42:52.179 --> 00:42:55.229
done by a human computer and what the human

731
00:42:55.239 --> 00:42:58.030
computer did. This is a job that was taken

732
00:42:58.040 --> 00:43:00.360
over by A I back in the day, all

733
00:43:00.370 --> 00:43:03.219
computers are a kind of artificial intelligence. It was

734
00:43:03.229 --> 00:43:06.280
just doing sums all day. So we have people

735
00:43:06.290 --> 00:43:07.750
used to be the only kinds of things that

736
00:43:07.760 --> 00:43:09.360
could do sums all day. And now we have

737
00:43:09.370 --> 00:43:12.270
uh, machines doing that. So the thought was, well,

738
00:43:12.280 --> 00:43:15.409
there's a similarity in what computers and brains can

739
00:43:15.419 --> 00:43:18.719
do. Let's see if we can understand the brains

740
00:43:18.729 --> 00:43:23.669
as biological computers. Um And so I'm saying, well,

741
00:43:23.739 --> 00:43:27.530
given the functional similarity in some respects between brains

742
00:43:27.540 --> 00:43:29.969
and computers, it's a natural thing to do. There's

743
00:43:29.979 --> 00:43:32.979
nothing wrong with this strategy in itself, but we

744
00:43:32.989 --> 00:43:37.479
shouldn't just literally think that what, um, brains essentially

745
00:43:37.489 --> 00:43:40.399
do is just the same thing as what computers,

746
00:43:40.409 --> 00:43:42.189
digital computers essentially do.

747
00:43:43.280 --> 00:43:46.300
But do you think there are still ways by

748
00:43:46.310 --> 00:43:51.620
which the analogy can be scientifically useful or not?

749
00:43:52.409 --> 00:43:57.409
Yeah. So I think all, uh all most analogies

750
00:43:57.419 --> 00:44:00.919
and science, um, can be shown to have their

751
00:44:00.929 --> 00:44:05.080
uses. Um, WHAT I mean, one way to think

752
00:44:05.090 --> 00:44:08.870
about why it's useful. I like this, Mary Hesse's

753
00:44:08.879 --> 00:44:10.929
um, notion of domestication. So if you think of

754
00:44:10.939 --> 00:44:14.090
the things in nature, they're kind of wild and

755
00:44:14.389 --> 00:44:18.030
not obvious in how they work. A tool is

756
00:44:18.040 --> 00:44:21.129
something very domestic to people in the sense that

757
00:44:21.139 --> 00:44:23.709
people have made it and makes sense to them.

758
00:44:23.719 --> 00:44:26.699
So, what these analogies are doing is looking at

759
00:44:26.709 --> 00:44:30.149
what's unfamiliar through the lens of something that is

760
00:44:30.159 --> 00:44:36.100
familiar and makes sense. Um So that certainly gives

761
00:44:36.110 --> 00:44:40.429
scientists a way to like not be overwhelmed by

762
00:44:40.439 --> 00:44:45.350
just the opacity, the um the just the alien

763
00:44:45.360 --> 00:44:49.179
nature of what they're trying to investigate. Um I

764
00:44:49.239 --> 00:44:51.429
in the chapter in the book, I look at

765
00:44:51.439 --> 00:44:54.260
this sort of historically about this early research that

766
00:44:54.270 --> 00:44:57.610
was done on that interface between computer science and

767
00:44:57.620 --> 00:45:02.459
neuroscience and that whole cybernetics movement. And um the

768
00:45:02.469 --> 00:45:04.939
thought was that OK, we look at the nervous

769
00:45:04.949 --> 00:45:08.260
system, we've got no idea how motor control happens.

770
00:45:08.270 --> 00:45:11.050
But what if we build a robot that does

771
00:45:11.060 --> 00:45:14.270
some of the things that I like what a

772
00:45:14.280 --> 00:45:17.669
person does when they are behaving with motor control.

773
00:45:17.969 --> 00:45:19.760
At least we've got a clue or like the

774
00:45:19.770 --> 00:45:23.030
beginnings of a theory about what might be happening.

775
00:45:23.040 --> 00:45:27.830
Neurophysiological, of course, analogies can be misleading because every

776
00:45:27.840 --> 00:45:31.409
analogy is based on a partial similarity but not

777
00:45:31.419 --> 00:45:35.439
identity. So two objects related by analogy will be

778
00:45:35.530 --> 00:45:38.489
similar in some ways but also different in many

779
00:45:38.500 --> 00:45:42.270
ways. And my criticism of the computational framework, um

780
00:45:42.280 --> 00:45:46.370
when people interpret it literally is that it tempts

781
00:45:46.379 --> 00:45:49.719
them just to ignore the differences between um biological

782
00:45:49.729 --> 00:45:52.679
brains and um artificial computing machines.

783
00:45:53.729 --> 00:45:57.030
And of course, since we're talking about simplification in

784
00:45:57.040 --> 00:46:00.070
science here, we also have to talk a little

785
00:46:00.080 --> 00:46:03.989
bit about modeling because that's also something that scientists

786
00:46:04.000 --> 00:46:08.129
do something that is I guess fundamental in science.

787
00:46:08.139 --> 00:46:13.649
So in the case of cognitive neuroscience specifically. Um

788
00:46:13.669 --> 00:46:16.790
How do you look at the relationship between modeling

789
00:46:16.800 --> 00:46:21.189
techniques and experimental practice, for example.

790
00:46:21.379 --> 00:46:24.060
Yeah. So, so there's a chapter in the book

791
00:46:24.070 --> 00:46:28.340
which focuses specifically on this theme and it's um

792
00:46:29.580 --> 00:46:34.540
and it's um making the argument that models um

793
00:46:34.550 --> 00:46:38.280
all models simplify and that famous slogan by George

794
00:46:38.290 --> 00:46:42.020
Mark Bots. Um All models are false but some

795
00:46:42.030 --> 00:46:45.840
are useful um still models uh he says are

796
00:46:45.850 --> 00:46:49.560
false because they all simplify, right. Um They no

797
00:46:49.570 --> 00:46:52.399
model can just take in all of the um

798
00:46:52.810 --> 00:46:59.550
complexity that's there observably. Um But I'm saying the

799
00:46:59.560 --> 00:47:04.379
most effective modeling strategies um don't just begin at

800
00:47:04.389 --> 00:47:07.629
the modeling stage. It's really important how you generate

801
00:47:07.639 --> 00:47:10.949
the data in order to um get a nice

802
00:47:10.959 --> 00:47:13.429
tractable model out of it. So I'm talking a

803
00:47:13.439 --> 00:47:17.219
lot about the um experimental techniques that have been

804
00:47:17.229 --> 00:47:21.510
used in uh phy neurophysiology of the visual system.

805
00:47:21.520 --> 00:47:24.860
So this is work on um primary visual cortex

806
00:47:24.870 --> 00:47:29.830
going through the 19 fifties onwards, how scientists were

807
00:47:29.840 --> 00:47:34.959
really um careful about how they prepared their animals,

808
00:47:34.969 --> 00:47:39.300
the use of different behavioral restraints, something mostly as

809
00:47:39.310 --> 00:47:43.590
drastic as anesthesia in the early stages, really careful

810
00:47:43.600 --> 00:47:46.830
about how they chose their stimuli. A lot of

811
00:47:46.840 --> 00:47:51.580
these um techniques had the precise effect of making

812
00:47:51.590 --> 00:47:54.620
data sets which had less variants than they would

813
00:47:54.629 --> 00:47:58.330
do if you just um recorded from the activity

814
00:47:58.340 --> 00:48:01.330
of neurons just in uncontrolled viewing conditions. So when

815
00:48:01.340 --> 00:48:06.010
a cat is roaming around the park jumping around

816
00:48:06.370 --> 00:48:09.649
hunting, doing all kinds of things. It's very hard,

817
00:48:09.659 --> 00:48:11.570
you're gonna get a data set, which is very

818
00:48:11.580 --> 00:48:15.239
hard to, um, model because there'll be very little

819
00:48:15.250 --> 00:48:18.239
repeatability of responses from one time to the next.

820
00:48:18.530 --> 00:48:21.300
If you anesthetize the cat put it in a

821
00:48:21.310 --> 00:48:24.760
harness, basically, stop it, having any kind of, uh,

822
00:48:24.770 --> 00:48:29.479
cognitive activity pretty much other than the precise stimulus

823
00:48:29.489 --> 00:48:33.169
that you've chose to, um, make it few, then

824
00:48:33.179 --> 00:48:36.129
you're gonna get neurophysiological responses which are kind of

825
00:48:36.139 --> 00:48:41.770
consistent with um mapping um from particular stimulus to

826
00:48:41.780 --> 00:48:45.639
particular um activity profile. There's still actually a lot

827
00:48:45.649 --> 00:48:47.729
of variants, but it's gonna be way less than

828
00:48:47.739 --> 00:48:50.899
if you just um approach things in the world.

829
00:48:51.449 --> 00:48:57.429
Um So just the variability of neuroscientists to have

830
00:48:57.439 --> 00:49:00.610
data sets which then they could uh build models

831
00:49:00.620 --> 00:49:04.010
of was dependent on all of this experimental methodology.

832
00:49:04.020 --> 00:49:06.250
Um That happened in the first place though we

833
00:49:06.260 --> 00:49:10.060
talk about how with current technologies um using machine

834
00:49:10.070 --> 00:49:14.570
learning and very, very wide sampling um of neurons

835
00:49:14.580 --> 00:49:17.260
when they're recorded in the brain, people are actually

836
00:49:17.270 --> 00:49:21.040
trying to develop data sets which are more naturalistic.

837
00:49:21.050 --> 00:49:24.959
So more like what how the primary visual cortex

838
00:49:24.969 --> 00:49:26.810
would work if the cat is jumping around the

839
00:49:26.820 --> 00:49:31.439
park as opposed to anesthetized in the lab. And

840
00:49:32.179 --> 00:49:36.830
that is um that is leading to, you know,

841
00:49:36.840 --> 00:49:41.129
in interesting classes of new models which kind of

842
00:49:41.139 --> 00:49:44.149
fall down, I suppose on this question of intelligibility

843
00:49:44.159 --> 00:49:47.370
of the model because you can like find mathematical

844
00:49:47.570 --> 00:49:50.899
relationships in these very, very high dimensional data sets.

845
00:49:51.290 --> 00:49:55.419
But that ability for the scientists to actually say,

846
00:49:55.429 --> 00:49:59.020
aha, I've figured out the operating principles of this

847
00:49:59.030 --> 00:50:01.659
system that that gets reduced once you're dealing with

848
00:50:01.669 --> 00:50:03.580
data sets of such complexity.

849
00:50:04.760 --> 00:50:07.979
So another very important topic here has to do

850
00:50:07.989 --> 00:50:11.979
with representation. And uh I've already had on the

851
00:50:11.989 --> 00:50:15.550
show, people like doctors, Randall Beer and Luis Wave.

852
00:50:16.040 --> 00:50:19.139
And we did the entire interviews, almost two hour

853
00:50:19.149 --> 00:50:24.739
interviews just on the topic of computational representational approaches

854
00:50:24.850 --> 00:50:28.510
to neuroscience and dynamical systems theory. We're also going

855
00:50:28.520 --> 00:50:31.629
to get into that in a second. But uh

856
00:50:31.639 --> 00:50:35.669
how do you approach the topic of representations? I

857
00:50:35.679 --> 00:50:39.879
mean, what are representations and where exactly is the

858
00:50:39.889 --> 00:50:44.270
role that you see they play in brain research?

859
00:50:45.219 --> 00:50:48.120
Yeah. So the question, what are representations? I mean,

860
00:50:48.129 --> 00:50:51.659
there's philosophers that spend their whole career on that

861
00:50:51.669 --> 00:50:54.389
question. Uh So it's, it's not actually my area

862
00:50:54.399 --> 00:50:55.820
of ecstasy. So I'm not going to go into

863
00:50:55.830 --> 00:50:58.840
like a technical definition. I give you uh the

864
00:50:58.850 --> 00:51:01.219
different views on that in terms of a debate

865
00:51:01.409 --> 00:51:03.600
and how I like to think about it as

866
00:51:03.610 --> 00:51:06.639
a philosopher of science here is to think about

867
00:51:06.649 --> 00:51:10.320
what, how are scientists using this notion of representation

868
00:51:10.620 --> 00:51:13.800
clearly? What they're doing is sort of drawing from

869
00:51:14.100 --> 00:51:17.840
uncontroversial cases of representation that are familiar from everyday

870
00:51:17.850 --> 00:51:19.949
life. So if you think about, you know what

871
00:51:19.959 --> 00:51:22.530
a map is, it's a kind of representation. It's

872
00:51:22.540 --> 00:51:27.669
um standing in for the territory which is out

873
00:51:27.679 --> 00:51:30.050
there in a city and just taking some of

874
00:51:30.060 --> 00:51:33.820
the structural features of that territory and depicting them

875
00:51:34.290 --> 00:51:36.320
in the map so that the person has a,

876
00:51:36.330 --> 00:51:39.229
if you like a substitute for the experience of

877
00:51:39.239 --> 00:51:41.360
walking around the whole city, you can see a

878
00:51:41.479 --> 00:51:44.899
subset of those relationships there in the map. Um

879
00:51:44.909 --> 00:51:47.110
And it allows you to do certain tasks like

880
00:51:47.120 --> 00:51:50.439
plan a route through a, through a town. Um

881
00:51:50.449 --> 00:51:53.719
All, all language is representational. When I talk about

882
00:51:53.729 --> 00:51:55.389
a dog or a cat, there's no dog or

883
00:51:55.399 --> 00:51:58.070
cat in the room. Um But if I say

884
00:51:58.080 --> 00:52:01.429
those words, then you're able to like uh refer

885
00:52:01.439 --> 00:52:06.370
to the same item um as me um uh

886
00:52:06.560 --> 00:52:10.219
paintings and all kinds of things can be representations

887
00:52:10.229 --> 00:52:17.530
in everyday life. Um A core um philosophical term

888
00:52:17.540 --> 00:52:20.149
that goes with the study of representations is this

889
00:52:20.159 --> 00:52:23.620
notion of intentionality. It's this idea that a representation

890
00:52:23.629 --> 00:52:27.060
is a physical object which uh this notion of

891
00:52:27.070 --> 00:52:29.969
intentionality um literally comes from the idea of it

892
00:52:29.979 --> 00:52:32.639
reaching out to the world around it to some

893
00:52:32.649 --> 00:52:37.489
object that it's aiming to depict. Um So this

894
00:52:37.500 --> 00:52:41.350
is the um feature of representations that I I'm

895
00:52:41.360 --> 00:52:45.169
arguing is particularly important with the use of this

896
00:52:45.179 --> 00:52:48.350
notion of neural representation. So what I'm saying is

897
00:52:48.360 --> 00:52:52.770
that when neuroscientists say that activity in parts of

898
00:52:52.780 --> 00:52:56.639
the visual cortex represents certain things like it might

899
00:52:56.649 --> 00:53:00.879
represent a face. What the neuroscientist is drawing on

900
00:53:00.889 --> 00:53:04.800
is this comparison between say um a picture which

901
00:53:04.810 --> 00:53:09.100
might represent a face. Um Not because through, well,

902
00:53:09.110 --> 00:53:10.959
maybe that's not such a good example because a

903
00:53:10.969 --> 00:53:13.159
picture, how's this kind of structural similarity with a

904
00:53:13.169 --> 00:53:14.969
face? So it would be better to say it's

905
00:53:14.979 --> 00:53:18.060
like a word which might be used to represent

906
00:53:18.070 --> 00:53:19.939
a face or a sentence which might represent a

907
00:53:19.949 --> 00:53:23.250
face. So even though the sentence is not similar

908
00:53:23.260 --> 00:53:27.189
to um a face, if you know um the

909
00:53:27.199 --> 00:53:30.320
language you'll be able to decode the sentence and

910
00:53:30.330 --> 00:53:34.850
like have conveyed in front of you um information

911
00:53:34.860 --> 00:53:38.270
about the face. So if I say um oh,

912
00:53:38.300 --> 00:53:41.689
the Mona Lisa had a face with an enigmatic

913
00:53:41.699 --> 00:53:44.360
smile and she had long brown hair, you'll be

914
00:53:44.370 --> 00:53:48.469
decoding this sentence, you'll um know something about that

915
00:53:48.479 --> 00:53:51.250
face. So the idea would be so uh uh

916
00:53:51.469 --> 00:53:56.479
neural activation and part of the fusiform face area

917
00:53:56.489 --> 00:53:58.669
is representing a face because there is a neural

918
00:53:58.679 --> 00:54:02.610
code which describes properties of that face. It sort

919
00:54:02.620 --> 00:54:06.790
of reaches out in, in into the world around

920
00:54:06.800 --> 00:54:10.419
it instead of just being about electrical activity, it's

921
00:54:10.429 --> 00:54:14.669
actually about that face in the world. That notion

922
00:54:14.679 --> 00:54:19.560
of intentionality comes in. This is all an account

923
00:54:19.570 --> 00:54:24.280
of why neuroscientists think about neural activations in terms

924
00:54:24.290 --> 00:54:30.389
of representation. Um uh An obvious point to make

925
00:54:30.399 --> 00:54:34.800
here is that uh representations are central to how

926
00:54:34.810 --> 00:54:38.600
people cognize it's a central explanatory notion in cognitive

927
00:54:38.610 --> 00:54:41.100
science. So if you say that there are representations

928
00:54:41.110 --> 00:54:43.760
in the brain, then you have this bridge from

929
00:54:43.770 --> 00:54:47.540
neurophysiology to cognition. Because you're saying like how the

930
00:54:47.550 --> 00:54:50.040
brain allows us to cognize the world is that

931
00:54:50.050 --> 00:54:53.699
the brain already forms representations. Therefore, we can start

932
00:54:53.790 --> 00:54:57.129
explaining how cognition is possible on that psychological level.

933
00:54:57.189 --> 00:55:00.979
So that's something that many people have said about

934
00:55:00.989 --> 00:55:04.969
why neuroscientists talk about representation. I say furthermore that

935
00:55:04.979 --> 00:55:09.090
it's also a simplifying strategy because it permits scientists

936
00:55:09.100 --> 00:55:14.159
to really focus on the relationship between an activation

937
00:55:14.169 --> 00:55:18.250
in particular brain area and objects in the world

938
00:55:18.260 --> 00:55:21.889
that those neurons are sensitive to and ignoring lots

939
00:55:21.899 --> 00:55:26.629
of biological details about how those activations get caused.

940
00:55:27.510 --> 00:55:31.610
Mhm So getting into the topic of a computational

941
00:55:31.620 --> 00:55:37.120
slash representational approaches to neuroscience and then dynamical systems

942
00:55:37.129 --> 00:55:40.520
theory approaches in the book, you take the example

943
00:55:40.530 --> 00:55:45.179
of the motor cortex uh and how it functions

944
00:55:45.245 --> 00:55:48.274
and its nature and the different ways people have

945
00:55:48.284 --> 00:55:52.645
approached it. So um what would be then the

946
00:55:52.774 --> 00:55:57.135
uh the more the common computational representational approach to

947
00:55:57.145 --> 00:56:00.895
it and then the dynamical systems approach to the

948
00:56:00.905 --> 00:56:02.094
motor cortex.

949
00:56:02.550 --> 00:56:07.340
Yeah. So the um the uh computational representational approach,

950
00:56:07.350 --> 00:56:10.179
it was is a bit earlier in its origins.

951
00:56:10.449 --> 00:56:12.530
And what that says is that uh for motor

952
00:56:12.570 --> 00:56:14.879
cortex is just like strip it around the top

953
00:56:14.889 --> 00:56:20.629
of your head. Um Its role is to direct

954
00:56:20.639 --> 00:56:23.320
um movement. So sending signals to the spinal cord

955
00:56:23.330 --> 00:56:26.479
which ultimately cause your muscles to move And so

956
00:56:26.550 --> 00:56:29.610
the theory about it being representational was to say

957
00:56:29.620 --> 00:56:33.750
that neural activations in this motor cortex are representing

958
00:56:33.760 --> 00:56:36.629
movements that you intend to make. So there is

959
00:56:36.639 --> 00:56:39.229
as if like 1 to 1 correspondence between an

960
00:56:39.239 --> 00:56:42.350
activation here and a particular movement like raising your

961
00:56:42.360 --> 00:56:46.409
arm. Um And so that was a theory put

962
00:56:46.419 --> 00:56:51.010
forward for the explanation of how motor cortex supports

963
00:56:51.020 --> 00:56:56.120
um uh motor control because you simply represent your

964
00:56:56.129 --> 00:56:58.790
motor intentions in the brain and then that signals

965
00:56:58.800 --> 00:57:02.320
to your body to move in certain ways. Um

966
00:57:02.330 --> 00:57:05.489
A bit of an obstacle for that theory um

967
00:57:05.860 --> 00:57:08.669
came about through finding is of of like relative

968
00:57:08.679 --> 00:57:13.620
instability of uh the relationship between these neural activations

969
00:57:13.629 --> 00:57:16.600
and movements. So people sort of trying hard and

970
00:57:16.610 --> 00:57:21.179
under controlled experimental situations to see. OK, what particular

971
00:57:21.189 --> 00:57:26.530
movement does this neuron um serve? Is it um

972
00:57:26.540 --> 00:57:30.239
what is it exactly representing even? Is it representing

973
00:57:30.250 --> 00:57:33.219
like whole arm moves? Is it representing the velocity

974
00:57:33.229 --> 00:57:36.110
of the arm movement? Is it representing the activation

975
00:57:36.120 --> 00:57:40.080
of certain muscles? Um Is it doing that consistently

976
00:57:40.090 --> 00:57:43.239
from one trial to another? It was very hard

977
00:57:43.250 --> 00:57:46.100
to pin anything down on this? It everything did

978
00:57:46.110 --> 00:57:48.479
seem to be a bit jelly like, yeah, there's

979
00:57:48.489 --> 00:57:53.300
a clear relationship between motor cortex activity and muscle

980
00:57:53.550 --> 00:57:57.000
um movements, but actually being precise in what that

981
00:57:57.010 --> 00:58:03.520
relationship was became quite hard to theorize. Um So

982
00:58:03.530 --> 00:58:08.459
in the purist um version, the dynamical systems approach

983
00:58:08.469 --> 00:58:12.459
and this is um there's an influential paper by

984
00:58:12.469 --> 00:58:15.340
um Krishna Shenoy and Mark Churchill and some other

985
00:58:15.350 --> 00:58:19.419
authors, they describe a dynamical systems approach which should

986
00:58:19.429 --> 00:58:22.989
have doesn't say that what the motor cortex is

987
00:58:23.000 --> 00:58:26.719
doing is representing, representing any movement para parameters. They're

988
00:58:26.729 --> 00:58:30.479
just saying this is a dynamical system which if

989
00:58:30.489 --> 00:58:34.860
you like causally drives motor outputs. So they have

990
00:58:34.870 --> 00:58:37.830
a, a different theory about the relationship between the

991
00:58:37.840 --> 00:58:41.899
activity and the and the um the movement outputs.

992
00:58:41.909 --> 00:58:44.770
They say uh it's a kind of a pattern

993
00:58:44.780 --> 00:58:48.100
generator. They say this kind of cyclical rhythmic um

994
00:58:48.620 --> 00:58:52.409
uh activity in motor cortex, which you can describe

995
00:58:52.419 --> 00:58:55.679
using dynamical equations. This is if you like giving

996
00:58:55.689 --> 00:58:59.320
lots of movement templates to the rest of the

997
00:58:59.330 --> 00:59:02.820
body which is just coarsely driven by these activity

998
00:59:02.830 --> 00:59:09.840
patterns. So in that paper, um they are um

999
00:59:10.280 --> 00:59:14.229
describing the dynamical systems approach in the consultation or

1000
00:59:14.239 --> 00:59:18.040
representational one as being incompatible. But there's other theorists

1001
00:59:18.050 --> 00:59:20.929
and uh Randy Beer has written some interesting stuff

1002
00:59:20.939 --> 00:59:23.389
relevant to this that actually say no, these are

1003
00:59:23.399 --> 00:59:26.669
just two different perspectives on the same thing for

1004
00:59:26.679 --> 00:59:30.310
any object in the world. You can in certainly

1005
00:59:30.320 --> 00:59:34.060
in any object in cognitive science, you can um

1006
00:59:34.189 --> 00:59:39.139
describe it as computational representation or dynamical systems theory

1007
00:59:39.310 --> 00:59:44.209
or as a dynamical system and um they're not

1008
00:59:44.219 --> 00:59:48.580
ultimately incompatible. Um So there's people uh I think

1009
00:59:48.590 --> 00:59:51.169
John Krakow has argued this uh with respect to

1010
00:59:51.179 --> 00:59:55.620
hot field networks. So artificial neural networks can also

1011
00:59:55.629 --> 00:59:59.060
be described as dynamical systems. And you can sort

1012
00:59:59.070 --> 01:00:02.620
of think of these as doing computations and also

1013
01:00:02.629 --> 01:00:08.149
doing this whole um dynamical causal causally driving uh

1014
01:00:08.159 --> 01:00:08.979
thing as well.

1015
01:00:09.780 --> 01:00:13.560
That's very interesting. And I, I've noticed in my

1016
01:00:13.570 --> 01:00:18.080
interviews also that there are different views on how

1017
01:00:18.250 --> 01:00:22.020
compatible these two different sets of approaches are, some

1018
01:00:22.030 --> 01:00:25.729
people think that they, they are really incompatible, others,

1019
01:00:25.739 --> 01:00:29.159
others are more on the side of compatibility. But

1020
01:00:29.389 --> 01:00:33.870
uh if they are compatible, what does that tell

1021
01:00:33.879 --> 01:00:37.500
us about um how we understand and study the

1022
01:00:37.510 --> 01:00:39.709
brain? Because I, I mean, the question here is

1023
01:00:39.719 --> 01:00:43.800
if we can have a correct uh or uh

1024
01:00:43.810 --> 01:00:47.870
an approximation to an understanding of the brain through

1025
01:00:47.879 --> 01:00:51.860
two different sets of theories, I mean, what does

1026
01:00:51.870 --> 01:00:54.580
that tell us? I mean, because uh shouldn't it

1027
01:00:54.590 --> 01:00:58.840
be just one theory that would be correct here

1028
01:00:58.850 --> 01:00:59.550
or? Yeah.

1029
01:01:00.770 --> 01:01:03.479
Yeah. So this goes back to this question of

1030
01:01:03.489 --> 01:01:10.110
pluralism. Um So the, if you insist on incompatibility,

1031
01:01:10.120 --> 01:01:12.020
one of the things you're assuming in the background

1032
01:01:12.030 --> 01:01:17.709
is that one of these theories is getting essentially

1033
01:01:17.719 --> 01:01:20.439
at the truth of how the brain operates. And

1034
01:01:20.449 --> 01:01:25.879
the other theory is false. Um I'm saying that

1035
01:01:25.889 --> 01:01:29.689
both of these theories make simplifications in their own

1036
01:01:29.699 --> 01:01:33.340
way, which depart from ultimately the truth, the ground

1037
01:01:33.350 --> 01:01:35.820
truth of how the brain operates. So if you

1038
01:01:35.830 --> 01:01:39.360
think of a classical computational representational one, it's making

1039
01:01:39.370 --> 01:01:45.270
assumptions about the consistency of the neuronal um act

1040
01:01:45.280 --> 01:01:49.090
the neuronal, what the neuro what the neurons are

1041
01:01:49.550 --> 01:01:55.459
intending to represent. Um That's not true, that kind

1042
01:01:55.469 --> 01:01:57.530
of stability is not true of the actual brain.

1043
01:01:57.540 --> 01:01:59.909
If you take the dynamical systems approach is making

1044
01:02:00.669 --> 01:02:03.739
assumptions about, there's ultimately some sort of fixed laws

1045
01:02:03.750 --> 01:02:06.080
of way of behavior that might not be true.

1046
01:02:06.590 --> 01:02:10.280
But that's fine if you're saying with me that

1047
01:02:10.290 --> 01:02:13.639
all scientific theories are simplified in some ways. Um

1048
01:02:13.649 --> 01:02:16.040
And like all models, they have to depart from

1049
01:02:16.050 --> 01:02:19.010
the inherent complexity of the system. So it's sort

1050
01:02:19.020 --> 01:02:22.120
of an option for me to say, well, they're

1051
01:02:22.129 --> 01:02:26.199
compatible because they are both perspectives on this one

1052
01:02:26.209 --> 01:02:34.689
thing. Um They um simplify in different ways. Um

1053
01:02:34.850 --> 01:02:38.889
None of them are take, allowing you to discover

1054
01:02:38.899 --> 01:02:41.760
like the whole truth of how the motor cortex

1055
01:02:41.770 --> 01:02:45.139
works. Um So what I say in the end

1056
01:02:45.149 --> 01:02:47.679
of that chapter one on the motor cortex research

1057
01:02:47.689 --> 01:02:50.080
is that ultimately, we have to have this sort

1058
01:02:50.090 --> 01:02:54.449
of intellectual humility, this can humility um which says

1059
01:02:54.459 --> 01:02:56.850
that the thing in itself or the brain in

1060
01:02:56.860 --> 01:03:01.379
itself because of its inherent and irreducible complexity is

1061
01:03:01.389 --> 01:03:05.830
to some extent, um cognitively or epistemic inaccessible to

1062
01:03:05.840 --> 01:03:08.840
us, we can't have that ideal of full and

1063
01:03:08.850 --> 01:03:13.780
complete absolute once and forever theory of motor cortex,

1064
01:03:13.790 --> 01:03:16.070
which will just tell us everything that there is

1065
01:03:16.080 --> 01:03:18.300
to know about it have to accept that all

1066
01:03:18.310 --> 01:03:21.379
of our theoretical approaches will be limited in different

1067
01:03:21.389 --> 01:03:26.290
and perhaps complementary ways. Um But yeah, the, the

1068
01:03:26.300 --> 01:03:29.810
final complete theory of the brain in itself is

1069
01:03:29.820 --> 01:03:31.110
not going to be available.

1070
01:03:32.850 --> 01:03:36.520
And of course, nowadays, we also have uh ma

1071
01:03:36.679 --> 01:03:41.590
machine learning as a way of uh modeling and

1072
01:03:41.600 --> 01:03:46.570
studying different and not just neural processes, neural systems

1073
01:03:46.580 --> 01:03:50.120
but other aspects of reality. What would you say

1074
01:03:50.129 --> 01:03:53.649
are the pros and cons of using uh this

1075
01:03:53.659 --> 01:03:54.739
kind of methods?

1076
01:03:55.639 --> 01:03:58.989
Yeah. So, so I I got interested in machine

1077
01:03:59.000 --> 01:04:02.850
learning methods and neuroscience just because I began to

1078
01:04:02.860 --> 01:04:06.669
see how much um of neuroscience was changing because

1079
01:04:06.679 --> 01:04:10.360
of the developments in machine learning. So my home

1080
01:04:10.370 --> 01:04:13.580
area of neuroscience is actually uh vision science. And

1081
01:04:13.590 --> 01:04:18.209
um I grew up with learning and modeling um

1082
01:04:18.219 --> 01:04:23.330
visual responses with these mathematically very almost truly simple

1083
01:04:24.110 --> 01:04:30.159
equations. And there were limitations in um what kinds

1084
01:04:30.169 --> 01:04:33.030
of responses could be predicted with these um quite

1085
01:04:33.040 --> 01:04:37.850
simple models. So um my own research modeling, um

1086
01:04:37.860 --> 01:04:41.469
we could predict the responses of how people um

1087
01:04:41.479 --> 01:04:45.310
sensitivity would change to contrast of um black and

1088
01:04:45.320 --> 01:04:48.570
white stripy patterns. But if you took uh black

1089
01:04:48.580 --> 01:04:51.959
and white photographs, our models would have less predictive

1090
01:04:51.969 --> 01:04:56.830
value. Um So what happened with the machine learning

1091
01:04:56.840 --> 01:05:00.489
revolution? And this was kind of um kind of

1092
01:05:00.520 --> 01:05:04.879
following on like big advances in machine vision, you

1093
01:05:04.889 --> 01:05:08.370
know, object recognition, face recognition at the start of

1094
01:05:08.379 --> 01:05:11.889
this century sudden suddenly started to be achieved. Uh

1095
01:05:11.899 --> 01:05:14.840
WHAT happened is that like vision researchers and neuroscience

1096
01:05:14.850 --> 01:05:19.290
were looking at deep learning and saying, aha these

1097
01:05:19.300 --> 01:05:23.570
computers are doing vision. What can we learn about

1098
01:05:23.580 --> 01:05:26.250
the visual system from studying uh these kinds of

1099
01:05:26.260 --> 01:05:28.780
devices? And it turns out what you can do

1100
01:05:28.790 --> 01:05:34.149
is you can build very, very vast like million

1101
01:05:34.159 --> 01:05:38.760
parameter models of visual cortex, which allow you to

1102
01:05:38.770 --> 01:05:42.050
predict the responses of neurons to look at almost

1103
01:05:42.060 --> 01:05:45.649
a complete array of different stimulus types. But then

1104
01:05:45.659 --> 01:05:49.120
what you find is that the theoretical pre off

1105
01:05:49.129 --> 01:05:52.870
in terms of understanding how visual cortex is working

1106
01:05:53.439 --> 01:05:56.639
is more limited, at least in the mathematical details

1107
01:05:56.649 --> 01:06:00.360
of what you're studying. Because in the old theories,

1108
01:06:00.370 --> 01:06:03.790
um the old strategies, you had a few equations

1109
01:06:03.800 --> 01:06:06.360
and you could tell a story about OK, this

1110
01:06:06.370 --> 01:06:09.739
kind of function is an edge detector and this

1111
01:06:09.750 --> 01:06:14.459
feeds into this um other thing, right? Whereas when

1112
01:06:14.469 --> 01:06:18.530
you have a vast um deep convolutional neural network,

1113
01:06:18.540 --> 01:06:21.520
which you're using to model visual cortex, you can

1114
01:06:21.530 --> 01:06:24.280
say a few things like there's X number of

1115
01:06:24.290 --> 01:06:28.060
layers and there's certain connectivity types between the two

1116
01:06:28.070 --> 01:06:30.149
and this may or may not correspond to what

1117
01:06:30.159 --> 01:06:33.469
you see in the actual brain. But mathematically, it

1118
01:06:33.479 --> 01:06:36.000
tells you, I would say less about what's going

1119
01:06:36.010 --> 01:06:38.080
on. Other people might disagree with this. I mean,

1120
01:06:38.090 --> 01:06:40.530
this is something this is I'm just stating my

1121
01:06:40.540 --> 01:06:45.090
own position. There are people like um um people

1122
01:06:45.100 --> 01:06:49.379
that have argued that there's much more theoretically and

1123
01:06:49.389 --> 01:06:54.550
explanatory available with using deep learning methods and science.

1124
01:06:54.560 --> 01:06:56.330
Anyway, it's an ongoing debate

1125
01:06:57.330 --> 01:07:00.860
since, since we're on the topic of A I,

1126
01:07:00.929 --> 01:07:03.979
um how do you think we should deal with

1127
01:07:03.989 --> 01:07:10.139
the claims regarding the potential of A I systems

1128
01:07:10.149 --> 01:07:14.879
developing? Or, I mean, perhaps programming them even with

1129
01:07:15.010 --> 01:07:20.080
things like consciousness, general intelligence and perhaps this would

1130
01:07:20.090 --> 01:07:23.699
be a way of also connecting the discussion to

1131
01:07:23.899 --> 01:07:28.909
the idea of multiple realizable of cognition here, right?

1132
01:07:28.919 --> 01:07:33.179
So in your view, what do, what should we

1133
01:07:33.189 --> 01:07:34.729
make of those types of

1134
01:07:34.739 --> 01:07:38.629
claims? Yeah. So th this is going back to

1135
01:07:38.639 --> 01:07:41.489
um an argument that springs out of what we

1136
01:07:41.500 --> 01:07:44.469
were talking about before with the computer brain analogy.

1137
01:07:44.959 --> 01:07:47.709
Uh So I said before that the um we

1138
01:07:47.719 --> 01:07:50.590
need to pay as much attention to the differences

1139
01:07:50.600 --> 01:07:54.229
between computing machines and brains as to the similarities,

1140
01:07:54.239 --> 01:07:59.770
which this analogy points us towards um people who

1141
01:08:00.149 --> 01:08:02.250
sort of sort of lit are literal about the

1142
01:08:02.260 --> 01:08:05.790
brain being a kind of computer. What they're claiming

1143
01:08:05.800 --> 01:08:10.199
is that the similarity of like the overlapping properties

1144
01:08:10.209 --> 01:08:14.639
between brains and computers is what's essential to how

1145
01:08:14.649 --> 01:08:18.950
the brain serves cognition. So anything cognitively going on

1146
01:08:18.959 --> 01:08:22.580
in the brain and this includes consciousness will ultimately

1147
01:08:22.709 --> 01:08:25.890
have a computational explanation if you like, there ultimately

1148
01:08:25.899 --> 01:08:28.759
is an algorithm that we run in our brains,

1149
01:08:28.790 --> 01:08:32.288
which is what makes us conscious. So if you

1150
01:08:32.298 --> 01:08:36.618
think like that, um given that um digital compu

1151
01:08:36.679 --> 01:08:40.229
computation is medium independent, so you can in principle

1152
01:08:40.238 --> 01:08:45.028
run any algorithm on any physical hardware and practice,

1153
01:08:45.038 --> 01:08:47.127
you might not be able to but in principle,

1154
01:08:47.358 --> 01:08:50.749
the, the, the material that a computer is made

1155
01:08:50.758 --> 01:08:54.448
of is irrelevant to its ability to perform a

1156
01:08:54.457 --> 01:08:59.089
computation. Um THAT gives you uh if you're, if

1157
01:08:59.100 --> 01:09:01.629
you buy into this view, then you're going to

1158
01:09:01.640 --> 01:09:04.270
think. Well, if consciousness is just the product of

1159
01:09:04.279 --> 01:09:07.259
an algorithm running a machine could be built, that

1160
01:09:07.270 --> 01:09:09.529
is consciousness in the same way that I have.

1161
01:09:09.540 --> 01:09:12.009
So you see this in people that talk about

1162
01:09:12.020 --> 01:09:15.009
uploading, they say if we record it from enough

1163
01:09:15.020 --> 01:09:18.850
neurons in our brain, and if you mathematically model

1164
01:09:18.859 --> 01:09:22.345
the their responses, then in principle, my mind could

1165
01:09:22.354 --> 01:09:24.955
be uploaded onto the cloud because it's just an

1166
01:09:24.964 --> 01:09:27.404
algorithm and I just need to discover the algorithm

1167
01:09:27.524 --> 01:09:30.174
and then I could be have my own conscious

1168
01:09:30.185 --> 01:09:33.245
mind after my body has died but a bit,

1169
01:09:33.254 --> 01:09:36.165
but my mind will still be operating in this

1170
01:09:36.174 --> 01:09:40.209
cloud based platform so that um unit use the

1171
01:09:40.220 --> 01:09:42.819
term multiple realization. That's another way of talking about

1172
01:09:42.830 --> 01:09:46.390
medium independence. It's saying that any algorithm can be

1173
01:09:46.399 --> 01:09:50.189
realized or implemented in a wide array of material

1174
01:09:50.200 --> 01:09:56.169
substrates. Um But my conjecture is that people have

1175
01:09:56.180 --> 01:09:59.899
been misled into these kinds of views because they

1176
01:09:59.910 --> 01:10:03.180
haven't paid enough attention to what's different between brains

1177
01:10:03.189 --> 01:10:08.129
and computers. There's good evidence coming from um the

1178
01:10:08.140 --> 01:10:12.410
biological side of neuroscience which looks at cell physiology

1179
01:10:12.419 --> 01:10:15.180
in its details neuro chemistry, in its details, all

1180
01:10:15.189 --> 01:10:18.379
these things going on with glial cells and um

1181
01:10:18.390 --> 01:10:22.490
genetic and immunological responses that I could also mention

1182
01:10:22.500 --> 01:10:26.020
here that says that what's going on in the

1183
01:10:26.029 --> 01:10:30.799
brain making cognition possible is inherently connected with a

1184
01:10:30.810 --> 01:10:34.680
whole bunch of other biological processes which are happening,

1185
01:10:34.850 --> 01:10:38.080
which are in no way shared with computing machines.

1186
01:10:38.089 --> 01:10:41.950
So computers like this one we're using now, uh

1187
01:10:41.959 --> 01:10:44.459
obviously not living things, they don't have any of

1188
01:10:44.470 --> 01:10:49.419
the metabolic immunological other features that brains have. So

1189
01:10:49.430 --> 01:10:53.330
if cognition is inherently depending on the dependent on

1190
01:10:53.339 --> 01:10:56.839
this sub consciousness is possible because we have all

1191
01:10:56.850 --> 01:11:02.149
of these biological uh features, then we shouldn't expect

1192
01:11:02.200 --> 01:11:05.990
a nonliving machine to run consciousness.

1193
01:11:07.160 --> 01:11:11.279
Um I mean about the physiology of the brain,

1194
01:11:11.290 --> 01:11:14.640
the metabolism and uh immunology and all of that,

1195
01:11:14.870 --> 01:11:19.669
would you also add here perhaps some aspects coming

1196
01:11:19.680 --> 01:11:23.629
from embodied cognition and the fact that the nervous

1197
01:11:23.640 --> 01:11:29.214
system, at least in biological systems also operates within

1198
01:11:29.274 --> 01:11:31.714
a body. And so we also have to consider

1199
01:11:31.725 --> 01:11:33.555
the rest of the body. I mean, would that

1200
01:11:33.564 --> 01:11:38.975
also play a role here in why probably uh

1201
01:11:38.984 --> 01:11:43.024
artificial systems wouldn't be able to develop the same

1202
01:11:43.035 --> 01:11:45.415
kinds of uh capacities?

1203
01:11:46.040 --> 01:11:49.439
Yeah. Yeah. So that that's an important way of

1204
01:11:49.450 --> 01:11:55.709
thinking about it. So, by embodied cognition, um what

1205
01:11:55.720 --> 01:11:59.890
we're led to pay attention to is the, the

1206
01:11:59.899 --> 01:12:03.959
way that neuroscience specializes and treats the brain and

1207
01:12:03.970 --> 01:12:07.439
nervous system independently of the rest of uh the

1208
01:12:07.450 --> 01:12:10.810
body is itself an idealization. It's a simplifying strategy.

1209
01:12:10.819 --> 01:12:15.140
It's like carving out one system to examine independently

1210
01:12:15.149 --> 01:12:17.799
of its context and for reasons we talked about

1211
01:12:17.810 --> 01:12:20.959
before, like there's too much complexity in the world

1212
01:12:20.970 --> 01:12:23.250
to try and take in everything at once. So

1213
01:12:23.520 --> 01:12:27.209
you know, standard practice in the biological sciences is

1214
01:12:27.220 --> 01:12:29.970
to research one organ at a time, if not

1215
01:12:29.979 --> 01:12:34.000
one cell type at a time, but we know

1216
01:12:34.009 --> 01:12:39.649
through other observations. Um AND and more and more

1217
01:12:39.660 --> 01:12:42.580
of this research is happening often prompted by uh

1218
01:12:42.589 --> 01:12:46.000
medical research is that the operation of the nervous

1219
01:12:46.009 --> 01:12:49.200
system is deeply interconnected with uh operations from the

1220
01:12:49.209 --> 01:12:52.680
rest of the body. So, this gut brain connection

1221
01:12:52.779 --> 01:12:56.899
is being focused on intensively in research now, because

1222
01:12:56.910 --> 01:13:02.450
of the connection between um the brain and metabolism

1223
01:13:02.459 --> 01:13:04.680
and appetite and all those these things. So people

1224
01:13:04.689 --> 01:13:06.979
are realizing that if you want to develop a

1225
01:13:06.990 --> 01:13:09.509
drug which will help people lose weight, you have

1226
01:13:09.520 --> 01:13:13.509
to uh pay attention to that gut brain connection.

1227
01:13:13.819 --> 01:13:17.200
Um The gut itself is huge innovated. There's lots

1228
01:13:17.209 --> 01:13:19.569
and lots of neurons uh around the gut. And

1229
01:13:19.580 --> 01:13:23.479
they're obviously um in contact with the, the brain,

1230
01:13:23.490 --> 01:13:25.979
the same for the heart, the whole uh uh

1231
01:13:25.990 --> 01:13:30.009
nervous system around the heart, really important to operations

1232
01:13:30.020 --> 01:13:33.549
there. And then conversely, um all of the ways

1233
01:13:33.560 --> 01:13:36.830
that the immune system and other bodily systems affect

1234
01:13:36.839 --> 01:13:41.990
um how the brain operates. Um So, ultimately, the

1235
01:13:42.000 --> 01:13:47.740
philosophical position of embodied cognition says that it's, it's

1236
01:13:47.750 --> 01:13:49.910
a sort of, if you like an anti dualist

1237
01:13:49.919 --> 01:13:53.370
anti Cartesian way, it's a way of thinking it

1238
01:13:53.379 --> 01:13:57.629
says that there's been too much of this view

1239
01:13:57.640 --> 01:14:01.049
that cognition is this thing like kind of floats

1240
01:14:01.060 --> 01:14:04.350
above the rest of the body um like a

1241
01:14:04.359 --> 01:14:09.399
pure um immaterial soul. That's what dear said. Actually,

1242
01:14:09.560 --> 01:14:12.759
what cognition is, is something very inherent to what

1243
01:14:12.770 --> 01:14:14.899
is going on with the body and the body

1244
01:14:14.910 --> 01:14:17.299
being. As I just said, this living system that

1245
01:14:17.310 --> 01:14:21.379
we don't understand cognition properly unless we understand it

1246
01:14:21.390 --> 01:14:24.339
as being a capacity of a living body.

1247
01:14:25.589 --> 01:14:29.270
Would you also include the other three ease of

1248
01:14:29.279 --> 01:14:32.740
four e cognition here? I mean, also the embedded,

1249
01:14:32.750 --> 01:14:37.520
extended and inactive uh aspects of it. Yeah.

1250
01:14:37.529 --> 01:14:40.890
So yeah, these, these views are often taken as

1251
01:14:40.899 --> 01:14:43.859
a package and I'm I'm pretty sympathetic to um

1252
01:14:43.870 --> 01:14:45.850
to the other ones to talk more about the

1253
01:14:45.859 --> 01:14:53.049
embodied cognition. I'd say the um uh the inactive.

1254
01:14:53.060 --> 01:14:55.229
Um Yeah, I mean, there's details of the in

1255
01:14:55.240 --> 01:14:57.459
activism theory that I wouldn't sign up for in

1256
01:14:57.470 --> 01:15:00.569
terms of all um perception being to do with

1257
01:15:00.580 --> 01:15:04.270
sensory motor contingencies. I think that one of the

1258
01:15:04.279 --> 01:15:06.390
ease that I have an attachment to is the

1259
01:15:06.399 --> 01:15:08.950
ecological theory. So in my previous book on color,

1260
01:15:08.959 --> 01:15:11.649
I was developing an ecological theory of what it

1261
01:15:11.660 --> 01:15:16.830
is to have color perception. The extended e that

1262
01:15:16.839 --> 01:15:19.200
is um a tricky one because there's actually as

1263
01:15:19.209 --> 01:15:21.819
Andy Clark wrote about in this nice paper called

1264
01:15:21.830 --> 01:15:25.669
pressing the flesh. There's actually an incompatibility between um

1265
01:15:25.680 --> 01:15:30.509
the um most thorough versions of the embodied and

1266
01:15:30.520 --> 01:15:33.580
the extended cognition. So as I was just saying,

1267
01:15:33.589 --> 01:15:37.660
with embodied cognition, you're really emphasizing the medium dependence

1268
01:15:37.669 --> 01:15:40.319
of cognition that it really matters that it happens

1269
01:15:40.330 --> 01:15:43.160
in a living body. Whereas the extended mind says

1270
01:15:43.169 --> 01:15:49.100
that cognition can occur in these body tool hybrid

1271
01:15:49.109 --> 01:15:52.299
systems, these cyborgs or it could even like go

1272
01:15:52.310 --> 01:15:57.020
out into nonbiological territory. Um And that's pretty much

1273
01:15:57.029 --> 01:16:00.350
saying that the medium doesn't matter because it can

1274
01:16:00.359 --> 01:16:03.370
extend out into these non living system. So I

1275
01:16:03.379 --> 01:16:07.379
have to say, given that I'm quite um keen

1276
01:16:07.390 --> 01:16:10.180
on the embodied side, I'm less keen on the

1277
01:16:10.189 --> 01:16:10.899
extended, but

1278
01:16:11.720 --> 01:16:15.149
no, that's very interesting because in my conversation with

1279
01:16:15.160 --> 01:16:18.919
Dr Randall beer is more or less, the same

1280
01:16:18.930 --> 01:16:21.859
is not very fond of the extended bit of

1281
01:16:21.870 --> 01:16:25.430
the four e cognition framework. And by the way,

1282
01:16:25.439 --> 01:16:28.225
Doctor Louis Favela also, recently we put out a

1283
01:16:28.234 --> 01:16:31.785
book, The Ecological Brain ta talking about the logic,

1284
01:16:31.805 --> 01:16:34.645
the ecological bit that you mentioned there. So I

1285
01:16:34.654 --> 01:16:36.884
also have uh an interview on that on the

1286
01:16:36.895 --> 01:16:40.595
show if people are interested. Uh And so one

1287
01:16:40.604 --> 01:16:44.669
last question then and since you um are a

1288
01:16:44.680 --> 01:16:48.850
philosopher yourself, I mean, you approach things from the

1289
01:16:48.859 --> 01:16:52.850
perspective of a philosopher here keeping in mind uh

1290
01:16:52.859 --> 01:16:55.770
the main thesis that you develop in your book

1291
01:16:55.779 --> 01:17:00.640
about simplifying schemes in neuroscience. How do you look

1292
01:17:00.649 --> 01:17:05.620
at the relationship between science and philosophy and how

1293
01:17:05.629 --> 01:17:09.250
should they, what kinds of um I don't know

1294
01:17:09.259 --> 01:17:12.149
insights. Should they bring to the table when it

1295
01:17:12.160 --> 01:17:17.810
comes to dealing with these aspects of theorizing, modeling

1296
01:17:17.819 --> 01:17:20.979
and so on in science. And what do you

1297
01:17:20.990 --> 01:17:24.759
think are the roles that they can play here?

1298
01:17:25.029 --> 01:17:27.709
Um Yeah. So this goes back to the question

1299
01:17:27.720 --> 01:17:30.830
that we started out um on and I, I

1300
01:17:30.839 --> 01:17:34.200
said a few things about neurop physic neuro philosophy

1301
01:17:34.209 --> 01:17:37.439
there and how I, I think there's an unaddressed

1302
01:17:37.770 --> 01:17:43.089
problem um about the way that philosophers have tried

1303
01:17:43.100 --> 01:17:49.649
to draw on scientific results. Um So once we

1304
01:17:49.870 --> 01:17:51.939
have in mind, all of these different ways that

1305
01:17:51.950 --> 01:17:55.520
science is simplified, can it really answer the questions

1306
01:17:55.529 --> 01:18:00.379
that um naturalistically inclined philosophers, neuro philosophers have tried

1307
01:18:00.910 --> 01:18:03.580
to make it speak to in their own research?

1308
01:18:04.080 --> 01:18:07.290
Um So I'm sort of raising this as a

1309
01:18:07.299 --> 01:18:10.109
question that I hope other people working in this

1310
01:18:10.120 --> 01:18:12.370
area will address. It would be great if people

1311
01:18:12.379 --> 01:18:15.279
that are really committed to neurop philosophy, sort of

1312
01:18:15.290 --> 01:18:18.100
develop a response to this. Um WORRY that I'm

1313
01:18:18.109 --> 01:18:20.979
raising because I'm sure there are ways to address

1314
01:18:20.990 --> 01:18:23.359
it and respond to this. It's just, it's not

1315
01:18:23.370 --> 01:18:25.490
a conversation that I've seen happen yet and I

1316
01:18:25.500 --> 01:18:30.189
want to start that conversation. Um The position that

1317
01:18:30.200 --> 01:18:34.000
I end up advocating is one that says, um

1318
01:18:34.009 --> 01:18:37.930
there are reasons for philosophy of mind to carry

1319
01:18:37.939 --> 01:18:40.970
on as an autonomous discipline as well. So there's

1320
01:18:40.979 --> 01:18:43.669
been um and I think this is something that

1321
01:18:43.680 --> 01:18:47.029
I would accuse neuro philosophy of certainly a scientic

1322
01:18:47.040 --> 01:18:48.950
drift to the way people have approached this. So

1323
01:18:48.959 --> 01:18:52.790
by scientic, what I mean is just assuming that

1324
01:18:52.799 --> 01:18:57.290
the scientific methodology and approach is uniquely the one

1325
01:18:57.299 --> 01:19:00.410
that is gonna yield the answers that any of

1326
01:19:00.419 --> 01:19:02.770
the answers that you might have about the questions

1327
01:19:02.779 --> 01:19:04.120
that you have on a topic. So it sort

1328
01:19:04.129 --> 01:19:08.660
of gives a pre eminence to those methodologies. Um

1329
01:19:09.359 --> 01:19:12.129
And that's the reason why neurop philosophers have said

1330
01:19:12.140 --> 01:19:14.799
to uh other philosophers of mine, you need to

1331
01:19:14.810 --> 01:19:17.899
give up your old armchair way of doing philosophy

1332
01:19:17.910 --> 01:19:21.620
that ignores the science because that's obsolete now. Um

1333
01:19:21.629 --> 01:19:25.220
There's no room for those methodologies that are disconnected

1334
01:19:25.229 --> 01:19:28.060
from science. And that's the uh conclusion that I'm

1335
01:19:28.069 --> 01:19:30.740
pushing back against because I think if we take

1336
01:19:30.750 --> 01:19:35.459
seriously how much idealization there is in science, you

1337
01:19:35.470 --> 01:19:39.500
can, you have these worries about the scientists might

1338
01:19:39.509 --> 01:19:44.339
be assuming things about the subject matter of the

1339
01:19:44.350 --> 01:19:47.080
mind, just the human mind, its place in society

1340
01:19:47.600 --> 01:19:54.060
which are incompatible um with um the views that

1341
01:19:54.069 --> 01:19:58.089
you might be might be really important to you

1342
01:19:58.100 --> 01:20:03.700
as a philosopher. Um And you should operate autonomously

1343
01:20:03.709 --> 01:20:06.439
from the science when it is committed to an

1344
01:20:06.450 --> 01:20:10.129
idealization that you yourself as a philosopher, see, good

1345
01:20:10.140 --> 01:20:17.540
reason to reject. Um So 11 idealization um you

1346
01:20:17.549 --> 01:20:20.990
could think about here is um the lack of

1347
01:20:21.000 --> 01:20:25.490
normativity that is included in uh research on scientific

1348
01:20:25.500 --> 01:20:27.870
research on cognition, which I mean, by which I

1349
01:20:27.879 --> 01:20:33.149
mean, um research on cognition abstracts away from value

1350
01:20:33.160 --> 01:20:35.649
and normativity. It doesn't see that as an inherent

1351
01:20:35.660 --> 01:20:39.169
part of its subject matter that it wants to

1352
01:20:39.180 --> 01:20:43.979
investigate. Whereas normativity and values, it's central to how

1353
01:20:43.990 --> 01:20:48.620
philosophers need to theorize um topics and philosophy of

1354
01:20:48.629 --> 01:20:51.919
mind related to decision making will all these kinds

1355
01:20:51.930 --> 01:20:54.560
of things where we have a human stake in

1356
01:20:54.569 --> 01:20:58.000
it, which means that value and normativity are important.

1357
01:20:58.509 --> 01:21:00.479
So if that's what you're interested in as a

1358
01:21:00.490 --> 01:21:02.399
philosopher, that's what you see is important to you,

1359
01:21:02.669 --> 01:21:06.129
then you've got good reason to be wary of

1360
01:21:06.140 --> 01:21:09.220
importing results from the science which has assumed at

1361
01:21:09.229 --> 01:21:11.890
the outset that value and normativity are not relevant.

1362
01:21:11.899 --> 01:21:14.169
And it's done that because if you include all

1363
01:21:14.180 --> 01:21:16.910
those variables to do with value and normativity, you

1364
01:21:16.919 --> 01:21:19.609
end up with too much um to deal with

1365
01:21:19.620 --> 01:21:24.189
scientifically. Um So that, so that's an argument for

1366
01:21:24.200 --> 01:21:29.379
the autonomy of philosophy from certain scientific um research

1367
01:21:29.390 --> 01:21:33.310
projects. Um But also sort of consistent with this

1368
01:21:33.319 --> 01:21:37.419
anti scientic conclusion, it does open the door to

1369
01:21:37.430 --> 01:21:41.049
philosophy, collaborating with other disciplines. Um So I said

1370
01:21:41.060 --> 01:21:45.569
before, well, literature, its use of metaphors, maybe that's

1371
01:21:45.580 --> 01:21:48.129
a way of thinking about the world that opens

1372
01:21:48.140 --> 01:21:52.629
the door to um to being aware of greater

1373
01:21:52.640 --> 01:21:57.259
complexity and interdependence. And maybe philosophers should be paying

1374
01:21:57.270 --> 01:22:00.330
attention to those other modes of thinking, those other

1375
01:22:00.339 --> 01:22:04.950
cultural discourses as much as they have been um

1376
01:22:04.959 --> 01:22:08.060
in recent years, paying attention to scientific results. So

1377
01:22:08.069 --> 01:22:12.629
ultimately, it's a very pluralist and um and open,

1378
01:22:12.640 --> 01:22:16.259
open position. But I think like given the importance

1379
01:22:16.270 --> 01:22:18.660
of neuro philosophy to our discipline, it might to,

1380
01:22:18.669 --> 01:22:21.939
some people seem a very controversial or a strange

1381
01:22:21.950 --> 01:22:22.660
view to take.

1382
01:22:23.459 --> 01:22:26.109
Uh I, I was also smiling when you were

1383
01:22:26.120 --> 01:22:30.279
mentioning uh scientism, I mean, using that word and

1384
01:22:30.290 --> 01:22:35.129
also how certain neuro philosophers talk about the armchair

1385
01:22:35.140 --> 01:22:37.689
philosophers and look a little bit down on them

1386
01:22:37.700 --> 01:22:41.620
because I was remembering my first interview with Doctor

1387
01:22:41.629 --> 01:22:46.709
Patricia Church, which I will probably also link in

1388
01:22:46.720 --> 01:22:50.390
the, in the description to have sort of uh

1389
01:22:50.410 --> 01:22:53.819
an opposing view on, on all of these kinds

1390
01:22:53.830 --> 01:22:57.790
of topics, which is also interesting. Uh And again,

1391
01:22:57.799 --> 01:23:02.620
the book is the Brain Abstracted Simplification and in

1392
01:23:02.629 --> 01:23:06.560
the history and philosophy of neuroscience. I'm living also

1393
01:23:06.569 --> 01:23:08.870
linked to it in the description of the interview.

1394
01:23:09.250 --> 01:23:12.870
And Doctor Shim Muta, uh apart from the book,

1395
01:23:12.879 --> 01:23:14.709
would you like to tell people where they can

1396
01:23:14.720 --> 01:23:17.069
find you and your work on the internet?

1397
01:23:17.720 --> 01:23:22.479
Uh Well, I'm kind of um an internet um

1398
01:23:22.509 --> 01:23:26.490
hm an internet decliner these days. I, so I'm

1399
01:23:26.500 --> 01:23:29.180
not on any social media. Um And that makes

1400
01:23:29.189 --> 01:23:31.220
it hard to sell books these days. So I'm

1401
01:23:31.229 --> 01:23:35.470
glad to have an interview like this. Um But

1402
01:23:35.479 --> 01:23:37.810
no, you, I do have a website, it's called

1403
01:23:37.819 --> 01:23:41.410
outside color.net. So all of my papers are linked

1404
01:23:41.419 --> 01:23:44.750
to that. Um So you can find a bunch

1405
01:23:44.759 --> 01:23:47.370
of papers that are related to this and there's

1406
01:23:47.379 --> 01:23:50.200
some more detailed stuff in the history of um

1407
01:23:50.319 --> 01:23:54.319
philosophy that I've done um as, as well, his

1408
01:23:54.330 --> 01:23:59.479
and history of neuroscience. Um There's various um lectures

1409
01:23:59.490 --> 01:24:01.740
that I've done, which are on youtube. So if

1410
01:24:01.750 --> 01:24:04.279
you search my name, you'll be able to find

1411
01:24:04.290 --> 01:24:05.950
a bunch of stuff there. I was talking about

1412
01:24:05.959 --> 01:24:11.560
various topics including the history of computation and, and

1413
01:24:11.569 --> 01:24:15.049
how that's related to social economic factors. That's one

1414
01:24:15.060 --> 01:24:18.200
of, I think one of my favorite ones there.

1415
01:24:18.540 --> 01:24:22.040
Um I think it's called contextualizing the computational mind.

1416
01:24:22.049 --> 01:24:27.000
Um And um yeah, and where else do I

1417
01:24:27.009 --> 01:24:30.689
exist on the web? Um Not much, but I

1418
01:24:30.700 --> 01:24:33.270
do, I do answer emails actually because I'm not

1419
01:24:33.279 --> 01:24:36.509
on social media. So people just email me with

1420
01:24:36.520 --> 01:24:39.390
a reasonable question out of the blue. I do,

1421
01:24:39.770 --> 01:24:43.259
I do make every effort to respond because I,

1422
01:24:43.270 --> 01:24:46.640
I just um actually like that old fashioned thing

1423
01:24:46.649 --> 01:24:50.680
of like communicating between um actual people as opposed

1424
01:24:50.689 --> 01:24:54.279
to just sort of broadcasting my ideas um on

1425
01:24:54.290 --> 01:24:56.430
social media. And also I don't like my own

1426
01:24:56.439 --> 01:25:00.359
thought process to be too much algorithmically driven. Um

1427
01:25:00.370 --> 01:25:03.029
And you can judge from the book itself whether

1428
01:25:03.040 --> 01:25:04.700
that is a good strategy or not.

1429
01:25:05.180 --> 01:25:07.939
No, for, for sure, for sure. And uh look,

1430
01:25:07.950 --> 01:25:10.669
I really love the book. It was a fantastic

1431
01:25:10.680 --> 01:25:12.950
read for me at least. And I really hope

1432
01:25:12.959 --> 01:25:16.049
that people in the audience uh uh also run

1433
01:25:16.060 --> 01:25:17.660
and buy it. It's a great,

1434
01:25:20.029 --> 01:25:21.649
yeah, I should also mention that there is an

1435
01:25:21.660 --> 01:25:25.200
open access version um that's been made available by

1436
01:25:25.209 --> 01:25:28.240
MIT Press. So the PDF is available to download

1437
01:25:28.250 --> 01:25:30.189
and maybe I shouldn't say that because that might

1438
01:25:30.200 --> 01:25:33.069
affect book sales. But yeah, for people that don't

1439
01:25:33.080 --> 01:25:35.270
want to buy the hard copy you can still

1440
01:25:35.279 --> 01:25:35.439
read.

1441
01:25:36.419 --> 01:25:39.640
Great. So thank you so much again for taking

1442
01:25:39.649 --> 01:25:41.520
the time to come on the show. It's been

1443
01:25:41.529 --> 01:25:42.890
great to talk with you.

1444
01:25:43.220 --> 01:25:44.270
Thank you, Ricardo.

1445
01:25:45.509 --> 01:25:48.240
Hi guys. Thank you for watching this interview. Until

1446
01:25:48.250 --> 01:25:50.410
the end. If you liked it, please share it.

1447
01:25:50.419 --> 01:25:53.220
Leave a like and hit the subscription button. The

1448
01:25:53.229 --> 01:25:55.310
show is brought to you by N Lights learning

1449
01:25:55.319 --> 01:25:58.350
and development. Then differently check the website at N

1450
01:25:58.359 --> 01:26:02.310
lights.com and also please consider supporting the show on

1451
01:26:02.319 --> 01:26:05.359
Patreon or paypal. I would also like to give

1452
01:26:05.370 --> 01:26:07.669
a huge thank you to my main patrons and

1453
01:26:07.680 --> 01:26:11.890
paypal supporters, Perego Larson, Jerry Muller and Frederick Suno

1454
01:26:11.939 --> 01:26:15.009
Bernard Seche O of Alex Adam Castle Matthew Whitting

1455
01:26:15.049 --> 01:26:18.290
bear. No wolf, Tim Ho Erica LJ Connors Philip

1456
01:26:18.299 --> 01:26:21.209
Forrest Connelly. Then the Met Robert Wine in NAI

1457
01:26:21.560 --> 01:26:25.200
Z Mar Nevs calling in Hobel Governor Mikel Stormer

1458
01:26:25.470 --> 01:26:28.759
Samuel Andre Francis for Agns Ferger Ken Hall. Her

1459
01:26:29.330 --> 01:26:32.169
ma J and Lain Jung Y and the Samuel

1460
01:26:32.779 --> 01:26:36.330
K Hes Mark Smith J. Tom Hummel s friends,

1461
01:26:36.370 --> 01:26:41.430
David Sloan Wilson, Yaar, Roman Roach Diego, Jan Punter,

1462
01:26:42.149 --> 01:26:45.169
Romani Charlotte bli Nicole Barba, Adam hunt Pavlo Stassi

1463
01:26:45.640 --> 01:26:48.790
na Me, Gary, G Alman, Samo, Zal Ari and

1464
01:26:48.830 --> 01:26:52.709
Y Polton John. Barboza Julian Price Edward Hall, Eden

1465
01:26:52.720 --> 01:26:58.459
Broder Douglas Fry Franka La Gilon Cortez or Scott

1466
01:26:58.709 --> 01:27:05.189
Zachary ftdw Daniel Friedman, William Buckner, Paul Giorgio, Luke

1467
01:27:05.200 --> 01:27:09.410
Loi Georgio Theophano, Chris Williams and Peter Wo David

1468
01:27:09.419 --> 01:27:13.529
Williams, the Ausa Anton Erickson Charles Murray, Alex Shaw,

1469
01:27:13.620 --> 01:27:18.970
Marie Martinez, Coralie Chevalier, Bangalore Larry Dey, Junior, Old

1470
01:27:19.520 --> 01:27:23.459
Ebon, Starry Michael Bailey then Spur by Robert Grassy

1471
01:27:23.529 --> 01:27:28.020
Zorn, Jeff mcmahon, Jake Zul Barnabas Radick Mark Temple,

1472
01:27:28.029 --> 01:27:32.439
Thomas Dvor Luke Neeson, Chris Tory Kimberley Johnson, Benjamin

1473
01:27:32.549 --> 01:27:35.689
Gilbert Jessica week in the B brand Nicholas Carlson

1474
01:27:35.700 --> 01:27:41.129
Ismael Bensley Man, George Katis, Valentine Steinman, Perlis, Kate

1475
01:27:41.140 --> 01:27:47.279
Van Goler, Alexander Abert Liam Dan Biar Masoud Ali

1476
01:27:47.330 --> 01:27:53.000
Mohammadi, Perpendicular Johnner Urla. Good enough Gregory Hastings David

1477
01:27:53.120 --> 01:27:57.174
Pins of Sean Nelson Mikela and Jos Net. A

1478
01:27:57.365 --> 01:28:00.174
special thanks to my producers, these our web, Jim

1479
01:28:00.185 --> 01:28:03.444
Frank Luca Stina, Tom Vig and Bernard N Cortes

1480
01:28:03.685 --> 01:28:07.444
Dixon Bendik Muller Thomas Trumble, Catherine and Patrick Tobin,

1481
01:28:07.455 --> 01:28:10.834
John Carlman, Negro, Nick Ortiz and Nick Golden. And

1482
01:28:10.845 --> 01:28:14.395
to my executive producers, Matthew lavender, Sergi, Adrian Bogdan

1483
01:28:15.015 --> 01:28:16.665
Knits and Rosie. Thank you for all

